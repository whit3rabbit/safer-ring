This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
advanced/
  buffer_group.rs
  config.rs
  feature_detection.rs
  mod.rs
  multi_shot.rs
backend/
  epoll.rs
  io_uring.rs
  mod.rs
buffer/
  allocation.rs
  generation.rs
  mod.rs
  numa.rs
future/
  io_futures/
    common.rs
    file_io.rs
    mod.rs
    network_io.rs
    vectored_io.rs
  batch_future.rs
  mod.rs
  operation_future.rs
  standalone_batch_future.rs
  tests.rs
  waker.rs
operation/
  building.rs
  completed.rs
  core.rs
  mod.rs
  states.rs
  submitted.rs
  tests.rs
  tracker.rs
  types.rs
pool/
  buffer_pool.rs
  mod.rs
  pooled_buffer.rs
  stats.rs
  tests.rs
registry/
  mod.rs
  tests.rs
ring/
  batch/
    config.rs
    core.rs
    mod.rs
    result.rs
    validation.rs
  completion/
    mod.rs
    result.rs
  core/
    batch_operations.rs
    configuration.rs
    fixed_operations.rs
    io_operations.rs
    mod.rs
    network_operations.rs
    safe_operations.rs
    utility.rs
  mod.rs
  tests.rs
compat.rs
config.rs
error.rs
lib.rs
logging.rs
ownership.rs
perf.rs
runtime.rs
safety.rs
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="advanced/buffer_group.rs">
//! Buffer group management for provided buffers.

use crate::error::{Result, SaferRingError};
use std::collections::VecDeque;

/// Buffer selection group for managing provided buffers.
///
/// Allows the kernel to select buffers from a pre-registered pool,
/// enabling zero-copy operations and reducing buffer management overhead.
#[derive(Debug)]
pub struct BufferGroup {
    /// Group ID for this buffer set
    pub group_id: u16,
    /// Number of buffers in the group
    pub buffer_count: u32,
    /// Size of each buffer in bytes
    pub buffer_size: u32,
    /// Pre-allocated buffer storage
    #[cfg(target_os = "linux")]
    #[allow(dead_code)] // Will be used when buffer selection is implemented
    buffers: Vec<Box<[u8]>>,
    /// Available buffer indices - using VecDeque for O(1) operations
    available_buffers: VecDeque<u16>,
}

impl BufferGroup {
    /// Create a new buffer group with the specified parameters.
    ///
    /// # Arguments
    ///
    /// * `group_id` - Unique identifier for this buffer group
    /// * `buffer_count` - Number of buffers to allocate
    /// * `buffer_size` - Size of each buffer in bytes
    ///
    /// # Errors
    ///
    /// Returns an error if buffer allocation fails or parameters are invalid.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// use safer_ring::advanced::BufferGroup;
    ///
    /// let group = BufferGroup::new(1, 100, 4096)?;
    /// # Ok::<(), safer_ring::error::SaferRingError>(())
    /// ```
    pub fn new(group_id: u16, buffer_count: u32, buffer_size: u32) -> Result<Self> {
        if buffer_count == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Buffer count must be greater than 0",
            )));
        }

        if buffer_size == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Buffer size must be greater than 0",
            )));
        }

        // Pre-allocate all buffers to avoid runtime allocation overhead
        #[cfg(target_os = "linux")]
        let buffers = {
            let mut buffers = Vec::with_capacity(buffer_count as usize);
            for _ in 0..buffer_count {
                // Use boxed slice for stable memory layout
                buffers.push(vec![0u8; buffer_size as usize].into_boxed_slice());
            }
            buffers
        };

        // Initialize all buffer indices as available
        let available_buffers = (0..buffer_count as u16).collect();

        Ok(Self {
            group_id,
            buffer_count,
            buffer_size,
            #[cfg(target_os = "linux")]
            buffers,
            available_buffers,
        })
    }

    /// Get the next available buffer index.
    ///
    /// Returns `None` if no buffers are available.
    #[inline]
    pub fn get_buffer(&mut self) -> Option<u16> {
        self.available_buffers.pop_front()
    }

    /// Return a buffer to the available pool.
    ///
    /// # Arguments
    ///
    /// * `buffer_id` - The buffer index to return
    ///
    /// # Panics
    ///
    /// Panics in debug mode if `buffer_id` is invalid.
    #[inline]
    pub fn return_buffer(&mut self, buffer_id: u16) {
        debug_assert!(
            buffer_id < self.buffer_count as u16,
            "Invalid buffer ID: {} >= {}",
            buffer_id,
            self.buffer_count
        );

        // Only add valid buffer IDs to prevent corruption
        if buffer_id < self.buffer_count as u16 {
            self.available_buffers.push_back(buffer_id);
        }
    }

    /// Get the number of available buffers.
    #[inline]
    pub fn available_count(&self) -> usize {
        self.available_buffers.len()
    }

    /// Check if any buffers are available.
    #[inline]
    pub fn has_available(&self) -> bool {
        !self.available_buffers.is_empty()
    }

    /// Get the utilization ratio (0.0 to 1.0).
    ///
    /// Returns the fraction of buffers currently in use.
    #[inline]
    pub fn utilization(&self) -> f64 {
        let in_use = self.buffer_count as usize - self.available_buffers.len();
        in_use as f64 / self.buffer_count as f64
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_buffer_group_creation() {
        let group = BufferGroup::new(1, 10, 4096).unwrap();

        assert_eq!(group.group_id, 1);
        assert_eq!(group.buffer_count, 10);
        assert_eq!(group.buffer_size, 4096);
        assert_eq!(group.available_count(), 10);
        assert!(group.has_available());
        assert_eq!(group.utilization(), 0.0);
    }

    #[test]
    fn test_buffer_allocation() {
        let mut group = BufferGroup::new(1, 5, 1024).unwrap();

        // Get all buffers
        let mut buffer_ids = Vec::new();
        for _ in 0..5 {
            let id = group.get_buffer().unwrap();
            buffer_ids.push(id);
        }

        assert_eq!(group.available_count(), 0);
        assert!(!group.has_available());
        assert_eq!(group.utilization(), 1.0);
        assert!(group.get_buffer().is_none());

        // Return buffers
        for id in buffer_ids {
            group.return_buffer(id);
        }

        assert_eq!(group.available_count(), 5);
        assert!(group.has_available());
        assert_eq!(group.utilization(), 0.0);
    }

    #[test]
    fn test_invalid_parameters() {
        assert!(BufferGroup::new(1, 0, 4096).is_err());
        assert!(BufferGroup::new(1, 10, 0).is_err());
    }
}
</file>

<file path="advanced/config.rs">
//! Advanced configuration for io_uring operations.

/// Advanced features configuration for io_uring operations.
///
/// Enables configuration of advanced io_uring features that may not be
/// available on all kernel versions. Features are disabled by default
/// to ensure compatibility.
#[derive(Debug, Clone, Default)]
pub struct AdvancedConfig {
    /// Enable buffer selection for read operations
    pub buffer_selection: bool,
    /// Enable multi-shot operations where supported
    pub multi_shot: bool,
    /// Enable provided buffers for zero-copy operations
    pub provided_buffers: bool,
    /// Enable fast poll for network operations
    pub fast_poll: bool,
    /// Enable submission queue polling
    pub sq_poll: bool,
    /// Enable io_uring kernel thread affinity
    pub sq_thread_cpu: Option<u32>,
    /// Enable cooperative task running
    pub coop_taskrun: bool,
    /// Enable task work defer
    pub defer_taskrun: bool,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = AdvancedConfig::default();

        assert!(!config.buffer_selection);
        assert!(!config.multi_shot);
        assert!(!config.provided_buffers);
        assert!(!config.fast_poll);
        assert!(!config.sq_poll);
        assert!(config.sq_thread_cpu.is_none());
        assert!(!config.coop_taskrun);
        assert!(!config.defer_taskrun);
    }
}
</file>

<file path="advanced/feature_detection.rs">
//! Kernel feature detection and capability probing.

use super::AdvancedConfig;
use crate::error::Result;
#[cfg(target_os = "linux")]
use crate::error::SaferRingError;

/// Kernel feature detection and capability probing.
///
/// Provides methods to detect which advanced io_uring features
/// are available on the current kernel version.
#[derive(Debug, Clone)]
pub struct FeatureDetector {
    /// Detected kernel version
    pub kernel_version: KernelVersion,
    /// Available features
    pub features: AvailableFeatures,
}

/// Kernel version information.
#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]
pub struct KernelVersion {
    /// Major version number
    pub major: u32,
    /// Minor version number
    pub minor: u32,
    /// Patch version number
    pub patch: u32,
}

/// Available io_uring features on this kernel.
#[derive(Debug, Clone)]
pub struct AvailableFeatures {
    /// Buffer selection is supported
    pub buffer_selection: bool,
    /// Multi-shot operations are supported
    pub multi_shot: bool,
    /// Provided buffers are supported
    pub provided_buffers: bool,
    /// Fast poll is supported
    pub fast_poll: bool,
    /// SQ polling is supported
    pub sq_poll: bool,
    /// Cooperative task running is supported
    pub coop_taskrun: bool,
    /// Task work defer is supported
    pub defer_taskrun: bool,
    /// Fixed files are supported
    pub fixed_files: bool,
    /// Fixed buffers are supported
    pub fixed_buffers: bool,
}

impl FeatureDetector {
    /// Create a new feature detector and probe the kernel.
    ///
    /// Detects the kernel version and probes for available features.
    ///
    /// # Errors
    ///
    /// Returns an error if kernel version detection fails.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// use safer_ring::advanced::FeatureDetector;
    ///
    /// let detector = FeatureDetector::new()?;
    /// println!("Kernel: {}.{}.{}",
    ///     detector.kernel_version.major,
    ///     detector.kernel_version.minor,
    ///     detector.kernel_version.patch);
    /// # Ok::<(), safer_ring::error::SaferRingError>(())
    /// ```
    pub fn new() -> Result<Self> {
        let kernel_version = Self::detect_kernel_version()?;
        let features = Self::probe_features(&kernel_version);

        Ok(Self {
            kernel_version,
            features,
        })
    }

    /// Detect the current kernel version.
    fn detect_kernel_version() -> Result<KernelVersion> {
        #[cfg(target_os = "linux")]
        {
            // Use libc to get kernel version via uname syscall
            let mut utsname = unsafe { std::mem::zeroed::<libc::utsname>() };
            let result = unsafe { libc::uname(&mut utsname) };

            if result != 0 {
                return Err(SaferRingError::Io(std::io::Error::last_os_error()));
            }

            let release =
                unsafe { std::ffi::CStr::from_ptr(utsname.release.as_ptr()).to_string_lossy() };

            let (major, minor, patch) = Self::parse_kernel_version(&release).map_err(|e| {
                SaferRingError::Io(std::io::Error::new(
                    std::io::ErrorKind::InvalidData,
                    format!("Failed to parse kernel version: {}", e),
                ))
            })?;

            Ok(KernelVersion {
                major,
                minor,
                patch,
            })
        }

        #[cfg(not(target_os = "linux"))]
        {
            // Return minimal version for non-Linux platforms
            Ok(KernelVersion {
                major: 0,
                minor: 0,
                patch: 0,
            })
        }
    }

    /// Parse kernel version string into components.
    ///
    /// Handles various kernel version formats including those with
    /// additional suffixes like "-arch1" or "-generic".
    #[allow(dead_code)]
    fn parse_kernel_version(version_str: &str) -> std::result::Result<(u32, u32, u32), String> {
        let parts: Vec<&str> = version_str.split('.').collect();
        if parts.len() < 2 {
            return Err("Invalid kernel version format".to_string());
        }

        let major = parts[0]
            .parse()
            .map_err(|_| "Invalid major version number".to_string())?;

        let minor = parts[1]
            .parse()
            .map_err(|_| "Invalid minor version number".to_string())?;

        let patch = if parts.len() > 2 {
            // Extract numeric part before any non-numeric characters
            // This handles cases like "12-arch1" -> 12
            let patch_str = parts[2]
                .chars()
                .take_while(|c| c.is_ascii_digit())
                .collect::<String>();
            patch_str.parse().unwrap_or(0)
        } else {
            0
        };

        Ok((major, minor, patch))
    }

    /// Probe for available features based on kernel version.
    ///
    /// Feature availability is determined by when they were introduced
    /// in the Linux kernel. This is a conservative approach that may
    /// miss backported features.
    fn probe_features(kernel_version: &KernelVersion) -> AvailableFeatures {
        AvailableFeatures {
            // Basic io_uring support (5.1+)
            fixed_files: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 1,
                    patch: 0,
                },
            fixed_buffers: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 1,
                    patch: 0,
                },

            // Fast poll (5.7+)
            fast_poll: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 7,
                    patch: 0,
                },

            // SQ polling (5.11+)
            sq_poll: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 11,
                    patch: 0,
                },

            // Buffer selection (5.13+)
            buffer_selection: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 13,
                    patch: 0,
                },
            provided_buffers: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 13,
                    patch: 0,
                },

            // Multi-shot operations (5.19+)
            multi_shot: kernel_version
                >= &KernelVersion {
                    major: 5,
                    minor: 19,
                    patch: 0,
                },

            // Cooperative task running (6.0+)
            coop_taskrun: kernel_version
                >= &KernelVersion {
                    major: 6,
                    minor: 0,
                    patch: 0,
                },
            defer_taskrun: kernel_version
                >= &KernelVersion {
                    major: 6,
                    minor: 0,
                    patch: 0,
                },
        }
    }

    /// Check if a specific feature is available.
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use safer_ring::advanced::FeatureDetector;
    /// let detector = FeatureDetector::new()?;
    ///
    /// if detector.has_feature("multi_shot") {
    ///     println!("Multi-shot operations are supported");
    /// }
    /// # Ok::<(), safer_ring::error::SaferRingError>(())
    /// ```
    pub fn has_feature(&self, feature: &str) -> bool {
        match feature {
            "buffer_selection" => self.features.buffer_selection,
            "multi_shot" => self.features.multi_shot,
            "provided_buffers" => self.features.provided_buffers,
            "fast_poll" => self.features.fast_poll,
            "sq_poll" => self.features.sq_poll,
            "coop_taskrun" => self.features.coop_taskrun,
            "defer_taskrun" => self.features.defer_taskrun,
            "fixed_files" => self.features.fixed_files,
            "fixed_buffers" => self.features.fixed_buffers,
            _ => false,
        }
    }

    /// Get a list of all available features.
    pub fn available_features(&self) -> Vec<&'static str> {
        let mut features = Vec::new();

        if self.features.fixed_files {
            features.push("fixed_files");
        }
        if self.features.fixed_buffers {
            features.push("fixed_buffers");
        }
        if self.features.fast_poll {
            features.push("fast_poll");
        }
        if self.features.sq_poll {
            features.push("sq_poll");
        }
        if self.features.buffer_selection {
            features.push("buffer_selection");
        }
        if self.features.provided_buffers {
            features.push("provided_buffers");
        }
        if self.features.multi_shot {
            features.push("multi_shot");
        }
        if self.features.coop_taskrun {
            features.push("coop_taskrun");
        }
        if self.features.defer_taskrun {
            features.push("defer_taskrun");
        }

        features
    }

    /// Create an AdvancedConfig with features enabled based on availability.
    ///
    /// SQ polling is disabled by default due to CPU usage concerns.
    pub fn create_optimal_config(&self) -> AdvancedConfig {
        AdvancedConfig {
            buffer_selection: self.features.buffer_selection,
            multi_shot: self.features.multi_shot,
            provided_buffers: self.features.provided_buffers,
            fast_poll: self.features.fast_poll,
            sq_poll: false, // Disabled by default due to CPU usage
            sq_thread_cpu: None,
            coop_taskrun: self.features.coop_taskrun,
            defer_taskrun: self.features.defer_taskrun,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_kernel_version_parsing() {
        let (major, minor, patch) = FeatureDetector::parse_kernel_version("5.19.0").unwrap();
        assert_eq!(major, 5);
        assert_eq!(minor, 19);
        assert_eq!(patch, 0);

        let (major, minor, patch) = FeatureDetector::parse_kernel_version("6.1.12-arch1").unwrap();
        assert_eq!(major, 6);
        assert_eq!(minor, 1);
        assert_eq!(patch, 12);
    }

    #[test]
    fn test_kernel_version_comparison() {
        let v1 = KernelVersion {
            major: 5,
            minor: 19,
            patch: 0,
        };
        let v2 = KernelVersion {
            major: 6,
            minor: 0,
            patch: 0,
        };

        assert!(v1 < v2);
        assert!(v2 > v1);
        assert_eq!(v1, v1);
    }

    #[test]
    fn test_feature_detection() {
        let detector = FeatureDetector::new().unwrap();

        // Basic sanity checks
        assert!(detector.kernel_version.major > 0 || cfg!(not(target_os = "linux")));

        // Test feature querying
        let _has_buffer_selection = detector.has_feature("buffer_selection");
        let _available_features = detector.available_features();

        // Test unknown feature
        assert!(!detector.has_feature("unknown_feature"));
    }

    #[test]
    fn test_feature_version_requirements() {
        let old_kernel = KernelVersion {
            major: 5,
            minor: 0,
            patch: 0,
        };
        let features = FeatureDetector::probe_features(&old_kernel);

        // Old kernel should not have advanced features
        assert!(!features.fixed_files);
        assert!(!features.multi_shot);
        assert!(!features.buffer_selection);

        let new_kernel = KernelVersion {
            major: 6,
            minor: 5,
            patch: 0,
        };
        let features = FeatureDetector::probe_features(&new_kernel);

        // New kernel should have all features
        assert!(features.fixed_files);
        assert!(features.multi_shot);
        assert!(features.buffer_selection);
        assert!(features.coop_taskrun);
    }
}
</file>

<file path="advanced/mod.rs">
//! Advanced io_uring features and optimizations.

pub mod buffer_group;
pub mod config;
pub mod feature_detection;
pub mod multi_shot;

pub use buffer_group::BufferGroup;
pub use config::AdvancedConfig;
pub use feature_detection::{AvailableFeatures, FeatureDetector, KernelVersion};
pub use multi_shot::MultiShotConfig;
</file>

<file path="advanced/multi_shot.rs">
//! Multi-shot operation configuration.

/// Multi-shot operation configuration.
///
/// Multi-shot operations allow a single submission to generate multiple
/// completion events, reducing submission overhead for operations like
/// `accept()` that can be repeated.
#[derive(Debug, Clone, Default)]
pub struct MultiShotConfig {
    /// Maximum number of completions to generate
    pub max_completions: Option<u32>,
    /// Whether to continue on errors
    pub continue_on_error: bool,
    /// Buffer group to use for multi-shot reads
    pub buffer_group_id: Option<u16>,
}

impl MultiShotConfig {
    /// Create a new multi-shot configuration.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::advanced::MultiShotConfig;
    ///
    /// let config = MultiShotConfig::new()
    ///     .with_max_completions(100)
    ///     .with_buffer_group(1);
    /// ```
    pub fn new() -> Self {
        Self::default()
    }

    /// Set the maximum number of completions.
    pub fn with_max_completions(mut self, max: u32) -> Self {
        self.max_completions = Some(max);
        self
    }

    /// Enable continuing on errors.
    pub fn with_continue_on_error(mut self) -> Self {
        self.continue_on_error = true;
        self
    }

    /// Set the buffer group ID for multi-shot reads.
    pub fn with_buffer_group(mut self, group_id: u16) -> Self {
        self.buffer_group_id = Some(group_id);
        self
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = MultiShotConfig::default();

        assert!(config.max_completions.is_none());
        assert!(!config.continue_on_error);
        assert!(config.buffer_group_id.is_none());
    }

    #[test]
    fn test_builder_pattern() {
        let config = MultiShotConfig::new()
            .with_max_completions(50)
            .with_continue_on_error()
            .with_buffer_group(2);

        assert_eq!(config.max_completions, Some(50));
        assert!(config.continue_on_error);
        assert_eq!(config.buffer_group_id, Some(2));
    }
}
</file>

<file path="backend/epoll.rs">
//! epoll-based fallback backend implementation.
//!
//! This backend provides a fallback mechanism for environments where io_uring
//! is not available, such as older kernels, containers with restricted capabilities,
//! or cloud environments that disable io_uring.

use std::collections::HashMap;
use std::io;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::backend::Backend;
use crate::error::{Result, SaferRingError};
use crate::operation::OperationType;

/// Pending operation in the epoll backend.
///
/// Represents an I/O operation that has been submitted to the epoll
/// backend but not yet completed. The operation is tracked until
/// the corresponding file descriptor becomes ready for I/O.
#[derive(Debug)]
#[allow(dead_code)] // Fields used only in actual epoll implementation, not stub
struct PendingOperation {
    op_type: OperationType,
    fd: RawFd,
    offset: u64,
    buffer_ptr: *mut u8,
    buffer_len: usize,
    user_data: u64,
}

/// epoll-based backend implementation for fallback support.
///
/// This backend provides a compatible I/O interface using the traditional
/// epoll mechanism available on Linux systems. While not as performant as
/// io_uring, it offers broad compatibility and can serve as a fallback
/// when io_uring is unavailable.
///
/// # Implementation Details
///
/// - Uses `EPOLLONESHOT` to ensure each operation triggers exactly once
/// - Executes I/O operations synchronously when file descriptors are ready
/// - Maintains internal tracking of pending operations
/// - Provides compatibility shims for io_uring features (file/buffer registration)
///
/// # Performance Characteristics
///
/// - Higher syscall overhead compared to io_uring
/// - No native support for registered files or buffers
/// - Operations execute synchronously once file descriptors are ready
/// - Still provides good performance for moderate I/O loads
///
/// # Resource Management
///
/// The backend automatically manages the epoll instance and cleans up
/// file descriptor registrations when dropped.
#[allow(dead_code)] // Fields used only in actual epoll implementation, not stub
pub struct EpollBackend {
    epoll_fd: RawFd,
    pending_operations: HashMap<u64, PendingOperation>,
    next_operation_id: u64,
}

impl EpollBackend {
    /// Create a new epoll backend.
    ///
    /// Creates a new epoll instance for managing I/O operations.
    /// The epoll instance is created with `EPOLL_CLOEXEC` to prevent
    /// inheritance by child processes.
    ///
    /// # Returns
    ///
    /// Returns a new EpollBackend instance ready for operation submission.
    ///
    /// # Errors
    ///
    /// - Returns `Unsupported` on non-Linux platforms
    /// - Returns `Io` errors if epoll creation fails (resource limits, etc.)
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use safer_ring::backend::{epoll::EpollBackend, Backend};
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let backend = EpollBackend::new()?;
    /// println!("Created epoll backend: {}", backend.name());
    /// # Ok(())
    /// # }
    /// ```
    pub fn new() -> Result<Self> {
        #[cfg(target_os = "linux")]
        {
            // Create epoll instance
            let epoll_fd = unsafe { libc::epoll_create1(libc::EPOLL_CLOEXEC) };

            if epoll_fd == -1 {
                return Err(SaferRingError::Io(io::Error::last_os_error()));
            }

            Ok(Self {
                epoll_fd,
                pending_operations: HashMap::new(),
                next_operation_id: 1,
            })
        }

        #[cfg(not(target_os = "linux"))]
        {
            Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::Unsupported,
                "epoll backend is only supported on Linux",
            )))
        }
    }
}

#[cfg(target_os = "linux")]
impl Drop for EpollBackend {
    fn drop(&mut self) {
        unsafe {
            libc::close(self.epoll_fd);
        }
    }
}

impl Backend for EpollBackend {
    fn submit_operation(
        &mut self,
        op_type: OperationType,
        fd: RawFd,
        offset: u64,
        buffer_ptr: *mut u8,
        buffer_len: usize,
        user_data: u64,
    ) -> Result<()> {
        #[cfg(target_os = "linux")]
        {
            let operation = PendingOperation {
                op_type,
                fd,
                offset,
                buffer_ptr,
                buffer_len,
                user_data,
            };

            // For read/recv operations, register for EPOLLIN
            // For write/send operations, register for EPOLLOUT
            let events = match op_type {
                OperationType::Read | OperationType::ReadVectored | OperationType::Recv => {
                    libc::EPOLLIN | libc::EPOLLONESHOT
                }
                OperationType::Write | OperationType::WriteVectored | OperationType::Send => {
                    libc::EPOLLOUT | libc::EPOLLONESHOT
                }
                OperationType::Accept => libc::EPOLLIN | libc::EPOLLONESHOT,
            };

            let mut event = libc::epoll_event {
                events: events as u32,
                u64: user_data,
            };

            let result =
                unsafe { libc::epoll_ctl(self.epoll_fd, libc::EPOLL_CTL_ADD, fd, &mut event) };

            if result == -1 {
                return Err(SaferRingError::Io(io::Error::last_os_error()));
            }

            self.pending_operations.insert(user_data, operation);
            Ok(())
        }

        #[cfg(not(target_os = "linux"))]
        {
            let _ = (op_type, fd, offset, buffer_ptr, buffer_len, user_data);
            Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::Unsupported,
                "epoll backend is only supported on Linux",
            )))
        }
    }

    fn try_complete(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        #[cfg(target_os = "linux")]
        {
            self.poll_completions(0) // Non-blocking
        }

        #[cfg(not(target_os = "linux"))]
        {
            Ok(Vec::new())
        }
    }

    fn wait_for_completion(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        #[cfg(target_os = "linux")]
        {
            if self.pending_operations.is_empty() {
                return Err(SaferRingError::Io(io::Error::new(
                    io::ErrorKind::InvalidInput,
                    "No operations to wait for",
                )));
            }

            self.poll_completions(-1) // Blocking
        }

        #[cfg(not(target_os = "linux"))]
        {
            Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::Unsupported,
                "epoll backend is only supported on Linux",
            )))
        }
    }

    fn operations_in_flight(&self) -> usize {
        self.pending_operations.len()
    }

    fn name(&self) -> &'static str {
        "epoll"
    }

    fn register_files(&mut self, _fds: &[RawFd]) -> Result<u32> {
        // Epoll doesn't support file descriptor registration
        // This is a no-op that pretends to work for compatibility
        Ok(0)
    }

    fn unregister_files(&mut self) -> Result<()> {
        // Epoll doesn't support file descriptor registration
        // This is a no-op that pretends to work for compatibility
        Ok(())
    }

    fn register_buffers(&mut self, _buffers: &[Pin<Box<[u8]>>]) -> Result<u32> {
        // Epoll doesn't support buffer registration
        // This is a no-op that pretends to work for compatibility
        Ok(0)
    }

    fn unregister_buffers(&mut self) -> Result<()> {
        // Epoll doesn't support buffer registration
        // This is a no-op that pretends to work for compatibility
        Ok(())
    }

    fn capacity(&self) -> u32 {
        // Epoll doesn't have a submission queue, return a reasonable default
        1024
    }

    fn completion_queue_stats(&mut self) -> (usize, usize) {
        // Epoll doesn't have a completion queue, return pending operations count
        (self.pending_operations.len(), 1024)
    }
}

#[cfg(target_os = "linux")]
impl EpollBackend {
    /// Poll for ready file descriptors and execute operations.
    ///
    /// Waits for file descriptors to become ready for I/O, then executes
    /// the corresponding operations synchronously.
    ///
    /// # Arguments
    ///
    /// * `timeout_ms` - Timeout in milliseconds (-1 for blocking, 0 for non-blocking)
    ///
    /// # Returns
    ///
    /// Returns completed operations as (user_data, result) tuples.
    ///
    /// # Errors
    ///
    /// Returns `Io` errors if epoll_wait fails or I/O operations encounter errors.
    fn poll_completions(&mut self, timeout_ms: i32) -> Result<Vec<(u64, io::Result<i32>)>> {
        const MAX_EVENTS: usize = 64;
        let mut events = Vec::with_capacity(MAX_EVENTS);
        events.resize_with(MAX_EVENTS, || libc::epoll_event { events: 0, u64: 0 });

        let num_events = unsafe {
            libc::epoll_wait(
                self.epoll_fd,
                events.as_mut_ptr(),
                MAX_EVENTS as i32,
                timeout_ms,
            )
        };

        if num_events == -1 {
            return Err(SaferRingError::Io(io::Error::last_os_error()));
        }

        let mut completed = Vec::with_capacity(num_events as usize);

        for i in 0..num_events as usize {
            let event = &events[i];
            let user_data = event.u64;

            if let Some(operation) = self.pending_operations.remove(&user_data) {
                // Execute the I/O operation
                let result = self.execute_operation(&operation);
                completed.push((user_data, result));

                // Remove from epoll (already done via EPOLLONESHOT)
            }
        }

        Ok(completed)
    }

    /// Execute a single I/O operation.
    ///
    /// Performs the actual I/O operation using traditional system calls
    /// once the file descriptor is ready. Handles different operation
    /// types (read, write, send, recv, accept) with appropriate syscalls.
    ///
    /// # Arguments
    ///
    /// * `op` - The pending operation to execute
    ///
    /// # Returns
    ///
    /// Returns the number of bytes transferred or an I/O error.
    ///
    /// # Error Handling
    ///
    /// Converts system call return values into appropriate `io::Result`
    /// values, handling errno translation and special cases like `EAGAIN`.
    fn execute_operation(&self, op: &PendingOperation) -> io::Result<i32> {
        match op.op_type {
            OperationType::Read => {
                // Use pread if offset is provided (non-zero), otherwise use read
                let result = if op.offset > 0 {
                    unsafe {
                        libc::pread(
                            op.fd,
                            op.buffer_ptr as *mut libc::c_void,
                            op.buffer_len,
                            op.offset as libc::off_t,
                        )
                    }
                } else {
                    unsafe { libc::read(op.fd, op.buffer_ptr as *mut libc::c_void, op.buffer_len) }
                };

                if result == -1 {
                    let error = io::Error::last_os_error();
                    // Handle EAGAIN/EWOULDBLOCK by re-registering for epoll
                    if error.kind() == io::ErrorKind::WouldBlock {
                        // This should not happen with epoll, but handle it gracefully
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::Write => {
                // Use pwrite if offset is provided (non-zero), otherwise use write
                let result = if op.offset > 0 {
                    unsafe {
                        libc::pwrite(
                            op.fd,
                            op.buffer_ptr as *const libc::c_void,
                            op.buffer_len,
                            op.offset as libc::off_t,
                        )
                    }
                } else {
                    unsafe {
                        libc::write(op.fd, op.buffer_ptr as *const libc::c_void, op.buffer_len)
                    }
                };

                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::Recv => {
                let result = unsafe {
                    libc::recv(op.fd, op.buffer_ptr as *mut libc::c_void, op.buffer_len, 0)
                };
                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::Send => {
                let result = unsafe {
                    libc::send(
                        op.fd,
                        op.buffer_ptr as *const libc::c_void,
                        op.buffer_len,
                        0,
                    )
                };
                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::Accept => {
                let result =
                    unsafe { libc::accept(op.fd, std::ptr::null_mut(), std::ptr::null_mut()) };
                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::ReadVectored => {
                // For vectored read, we need to interpret the buffer as an iovec array
                // This is a simplified implementation that treats it as a single buffer
                // A full implementation would need to handle the iovec structure properly
                let result = if op.offset > 0 {
                    unsafe {
                        libc::pread(
                            op.fd,
                            op.buffer_ptr as *mut libc::c_void,
                            op.buffer_len,
                            op.offset as libc::off_t,
                        )
                    }
                } else {
                    unsafe { libc::read(op.fd, op.buffer_ptr as *mut libc::c_void, op.buffer_len) }
                };

                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }

            OperationType::WriteVectored => {
                // For vectored write, we need to interpret the buffer as an iovec array
                // This is a simplified implementation that treats it as a single buffer
                // A full implementation would need to handle the iovec structure properly
                let result = if op.offset > 0 {
                    unsafe {
                        libc::pwrite(
                            op.fd,
                            op.buffer_ptr as *const libc::c_void,
                            op.buffer_len,
                            op.offset as libc::off_t,
                        )
                    }
                } else {
                    unsafe {
                        libc::write(op.fd, op.buffer_ptr as *const libc::c_void, op.buffer_len)
                    }
                };

                if result == -1 {
                    let error = io::Error::last_os_error();
                    if error.kind() == io::ErrorKind::WouldBlock {
                        return Err(io::Error::new(
                            io::ErrorKind::WouldBlock,
                            "Operation would block unexpectedly",
                        ));
                    }
                    Err(error)
                } else {
                    Ok(result as i32)
                }
            }
        }
    }
}
</file>

<file path="backend/io_uring.rs">
//! io_uring backend implementation.

use std::io;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::backend::Backend;
use crate::error::{Result, SaferRingError};
use crate::operation::OperationType;

#[cfg(target_os = "linux")]
use io_uring::{opcode, types, IoUring};

/// io_uring-based backend for high-performance I/O.
///
/// This backend provides the highest performance I/O on Linux systems
/// by using the io_uring interface introduced in Linux 5.1. It offers
/// true asynchronous I/O with minimal syscall overhead and kernel-level
/// batching of operations.
///
/// # Performance Benefits
///
/// - **Zero-copy I/O**: Direct data transfer between user and kernel space
/// - **Batched syscalls**: Multiple operations submitted in a single syscall
/// - **Registered resources**: Pre-registered files and buffers for faster access
/// - **Kernel polling**: Optional kernel-side polling eliminates most syscalls
///
/// # Platform Support
///
/// Only available on Linux 5.1 or later. On other platforms, this struct
/// exists but all operations will return `Unsupported` errors.
///
/// # Resource Management
///
/// The backend automatically manages submission and completion queues,
/// tracking in-flight operations to prevent resource leaks and ensure
/// proper cleanup on drop.
#[cfg(target_os = "linux")]
pub struct IoUringBackend {
    ring: IoUring,
    in_flight: std::collections::HashMap<u64, ()>,
}

#[cfg(target_os = "linux")]
impl IoUringBackend {
    /// Create a new io_uring backend.
    ///
    /// Initializes a new io_uring instance with the specified queue capacity.
    /// The actual capacity may be adjusted by the kernel to the nearest
    /// power of two.
    ///
    /// # Arguments
    ///
    /// * `entries` - Desired capacity for submission and completion queues
    ///
    /// # Returns
    ///
    /// Returns a new IoUringBackend instance ready for operation submission.
    ///
    /// # Errors
    ///
    /// - Returns `Unsupported` on non-Linux platforms
    /// - Returns `Io` errors if io_uring setup fails (insufficient permissions,
    ///   kernel too old, resource limits exceeded)
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use safer_ring::backend::io_uring::IoUringBackend;
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let backend = IoUringBackend::new(32)?;
    /// println!("Created io_uring backend with capacity: {}", backend.capacity());
    /// # Ok(())
    /// # }
    /// ```
    pub fn new(entries: u32) -> Result<Self> {
        let ring = IoUring::new(entries)?;
        Ok(Self {
            ring,
            in_flight: std::collections::HashMap::new(),
        })
    }
}

#[cfg(target_os = "linux")]
impl Backend for IoUringBackend {
    fn submit_operation(
        &mut self,
        op_type: OperationType,
        fd: RawFd,
        offset: u64,
        buffer_ptr: *mut u8,
        buffer_len: usize,
        user_data: u64,
    ) -> Result<()> {
        let entry = match op_type {
            OperationType::Read => opcode::Read::new(types::Fd(fd), buffer_ptr, buffer_len as u32)
                .offset(offset)
                .build()
                .user_data(user_data),
            OperationType::Write => {
                opcode::Write::new(types::Fd(fd), buffer_ptr, buffer_len as u32)
                    .offset(offset)
                    .build()
                    .user_data(user_data)
            }
            OperationType::Accept => opcode::Accept::new(
                types::Fd(fd),
                buffer_ptr as *mut libc::sockaddr,
                buffer_ptr as *mut libc::socklen_t,
            )
            .build()
            .user_data(user_data),
            OperationType::Send => opcode::Send::new(types::Fd(fd), buffer_ptr, buffer_len as u32)
                .build()
                .user_data(user_data),
            OperationType::Recv => opcode::Recv::new(types::Fd(fd), buffer_ptr, buffer_len as u32)
                .build()
                .user_data(user_data),
            OperationType::ReadVectored | OperationType::WriteVectored => {
                return Err(SaferRingError::Io(io::Error::new(
                    io::ErrorKind::Unsupported,
                    format!(
                        "Operation {:?} not yet implemented in io_uring backend",
                        op_type
                    ),
                )));
            }
        };

        unsafe {
            self.ring.submission().push(&entry).map_err(|e| {
                SaferRingError::Io(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    format!("Failed to push submission queue entry: {:?}", e),
                ))
            })?;
        }

        self.in_flight.insert(user_data, ());
        self.ring.submit()?;

        Ok(())
    }

    fn try_complete(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        let mut completions = Vec::new();
        let mut cq = self.ring.completion();

        for cqe in &mut cq {
            let user_data = cqe.user_data();
            let result = if cqe.result() < 0 {
                Err(io::Error::from_raw_os_error(-cqe.result()))
            } else {
                Ok(cqe.result())
            };

            self.in_flight.remove(&user_data);
            completions.push((user_data, result));
        }

        cq.sync();
        Ok(completions)
    }

    fn wait_for_completion(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        if self.in_flight.is_empty() {
            return Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::InvalidInput,
                "No operations in flight to wait for",
            )));
        }

        self.ring.submit_and_wait(1)?;
        self.try_complete()
    }

    fn operations_in_flight(&self) -> usize {
        self.in_flight.len()
    }

    fn name(&self) -> &'static str {
        "io_uring"
    }

    fn register_files(&mut self, fds: &[RawFd]) -> Result<u32> {
        if fds.is_empty() {
            return Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::InvalidInput,
                "Cannot register empty file descriptor list",
            )));
        }

        // Use io_uring register_files API
        self.ring.submitter().register_files(fds)?;
        Ok(0) // io_uring registers at index 0
    }

    fn unregister_files(&mut self) -> Result<()> {
        self.ring.submitter().unregister_files()?;
        Ok(())
    }

    fn register_buffers(&mut self, buffers: &[Pin<Box<[u8]>>]) -> Result<u32> {
        if buffers.is_empty() {
            return Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::InvalidInput,
                "Cannot register empty buffer list",
            )));
        }

        // Convert pinned buffers to iovec structures for io_uring
        let iovecs: Vec<libc::iovec> = buffers
            .iter()
            .map(|buffer| libc::iovec {
                iov_base: buffer.as_ptr() as *mut libc::c_void,
                iov_len: buffer.len(),
            })
            .collect();

        // SAFETY: The iovecs are properly constructed from valid buffer pointers
        // and the buffers remain pinned in memory for the duration of their use
        unsafe {
            self.ring.submitter().register_buffers(&iovecs)?;
        }
        Ok(0) // io_uring registers at index 0
    }

    fn unregister_buffers(&mut self) -> Result<()> {
        self.ring.submitter().unregister_buffers()?;
        Ok(())
    }

    fn capacity(&self) -> u32 {
        self.ring.params().sq_entries()
    }

    fn completion_queue_stats(&mut self) -> (usize, usize) {
        let capacity = self.ring.params().cq_entries() as usize;
        let cq = self.ring.completion();
        let ready = cq.len();
        (ready, capacity)
    }
}

/// Stub implementation for non-Linux platforms.
///
/// This provides a compile-time compatible interface for non-Linux platforms
/// where io_uring is not available. All operations will return `Unsupported`
/// errors, allowing code to compile but gracefully fail at runtime on
/// incompatible platforms.
#[cfg(not(target_os = "linux"))]
pub struct IoUringBackend;

#[cfg(not(target_os = "linux"))]
impl IoUringBackend {
    /// Create a new io_uring backend (stub for non-Linux platforms).
    ///
    /// Always returns an `Unsupported` error since io_uring is not available
    /// on non-Linux platforms.
    ///
    /// # Arguments
    ///
    /// * `_entries` - Ignored on non-Linux platforms
    ///
    /// # Errors
    ///
    /// Always returns `SaferRingError::Io` with `Unsupported` kind.
    pub fn new(_entries: u32) -> Result<Self> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }
}

#[cfg(not(target_os = "linux"))]
impl Backend for IoUringBackend {
    fn submit_operation(
        &mut self,
        _op_type: OperationType,
        _fd: RawFd,
        _offset: u64,
        _buffer_ptr: *mut u8,
        _buffer_len: usize,
        _user_data: u64,
    ) -> Result<()> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn try_complete(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        Ok(Vec::new())
    }

    fn wait_for_completion(&mut self) -> Result<Vec<(u64, io::Result<i32>)>> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn operations_in_flight(&self) -> usize {
        0
    }

    fn name(&self) -> &'static str {
        "io_uring (unsupported)"
    }

    fn register_files(&mut self, _fds: &[RawFd]) -> Result<u32> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn unregister_files(&mut self) -> Result<()> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn register_buffers(&mut self, _buffers: &[Pin<Box<[u8]>>]) -> Result<u32> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn unregister_buffers(&mut self) -> Result<()> {
        Err(SaferRingError::Io(io::Error::new(
            io::ErrorKind::Unsupported,
            "io_uring is only supported on Linux",
        )))
    }

    fn capacity(&self) -> u32 {
        0
    }

    fn completion_queue_stats(&mut self) -> (usize, usize) {
        (0, 0)
    }
}
</file>

<file path="backend/mod.rs">
//! Backend abstraction for different I/O mechanisms.
//!
//! This module provides a unified interface for different I/O backends,
//! allowing the library to fall back from io_uring to epoll when necessary.

use std::io;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::error::Result;
use crate::operation::OperationType;

pub mod epoll;
pub mod io_uring;

/// Trait for I/O backends that can execute operations.
///
/// This trait provides a unified interface for different I/O mechanisms,
/// allowing the library to abstract over io_uring and epoll backends.
/// Each backend must implement all methods to provide a complete I/O
/// abstraction layer.
///
/// # Backend Types
///
/// - **io_uring**: High-performance backend for Linux 5.1+ with kernel-level
///   asynchronous I/O support
/// - **epoll**: Fallback backend using traditional epoll for older systems
///   or restricted environments
///
/// # Safety
///
/// Implementations must ensure that buffer pointers remain valid during
/// the lifetime of operations and that file descriptors are properly
/// managed to prevent use-after-close bugs.
pub trait Backend {
    /// Submit an operation to the backend.
    ///
    /// Queues an I/O operation for execution by the backend. The operation
    /// is identified by the user_data parameter, which will be returned
    /// when the operation completes.
    ///
    /// # Arguments
    ///
    /// * `op_type` - The type of I/O operation to perform
    /// * `fd` - File descriptor for the operation
    /// * `offset` - Byte offset for file operations (0 for sockets)
    /// * `buffer_ptr` - Pointer to the buffer for data transfer
    /// * `buffer_len` - Size of the buffer in bytes
    /// * `user_data` - Unique identifier for this operation
    ///
    /// # Safety
    ///
    /// The caller must ensure that:
    /// - `buffer_ptr` points to a valid buffer of at least `buffer_len` bytes
    /// - The buffer remains valid until the operation completes
    /// - `fd` is a valid, open file descriptor
    /// - `user_data` is unique among pending operations
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - The backend's submission queue is full
    /// - The file descriptor is invalid
    /// - The operation type is unsupported by the backend
    fn submit_operation(
        &mut self,
        op_type: OperationType,
        fd: RawFd,
        offset: u64,
        buffer_ptr: *mut u8,
        buffer_len: usize,
        user_data: u64,
    ) -> Result<()>;

    /// Try to complete operations without blocking.
    ///
    /// Polls the backend for completed operations and returns them immediately.
    /// This method will not block if no operations are ready.
    ///
    /// # Returns
    ///
    /// Returns a vector of (user_data, result) tuples for all completed
    /// operations. The result contains either the number of bytes
    /// transferred or an I/O error.
    ///
    /// # Errors
    ///
    /// Returns an error if the backend encounters a system-level error
    /// while checking for completions.
    fn try_complete(&mut self) -> Result<Vec<(u64, io::Result<i32>)>>;

    /// Wait for at least one operation to complete.
    ///
    /// Blocks until at least one operation completes, then returns all
    /// currently completed operations. This is more efficient than
    /// polling when you know operations are pending.
    ///
    /// # Returns
    ///
    /// Returns a vector of (user_data, result) tuples for completed
    /// operations. At least one completion will be returned unless
    /// an error occurs.
    ///
    /// # Errors
    ///
    /// - Returns `InvalidInput` if no operations are in flight
    /// - Returns backend-specific errors for system-level failures
    ///
    /// # Panics
    ///
    /// May panic if called when no operations are pending on some backends.
    fn wait_for_completion(&mut self) -> Result<Vec<(u64, io::Result<i32>)>>;

    /// Get the number of operations currently in flight.
    ///
    /// Returns the count of operations that have been submitted but not
    /// yet completed. This includes operations waiting in submission
    /// queues and those actively being processed by the kernel.
    ///
    /// This is useful for flow control and debugging.
    fn operations_in_flight(&self) -> usize;

    /// Get backend name for debugging.
    ///
    /// Returns a static string identifying the backend type,
    /// such as "io_uring" or "epoll". Useful for logging,
    /// debugging, and performance analysis.
    fn name(&self) -> &'static str;

    /// Register file descriptors for optimized access.
    ///
    /// Pre-registers file descriptors with the backend for improved
    /// performance on subsequent operations. Some backends (like io_uring)
    /// can use registered files more efficiently by avoiding descriptor
    /// lookups and validations.
    ///
    /// # Arguments
    ///
    /// * `fds` - Slice of file descriptors to register
    ///
    /// # Returns
    ///
    /// Returns the starting index where files were registered in the
    /// backend's file table. This index can be used to reference
    /// registered files in operations.
    ///
    /// # Errors
    ///
    /// - Returns `InvalidInput` if the file descriptor array is empty
    /// - Returns backend-specific errors for registration failures
    ///
    /// # Note
    ///
    /// Some backends (like epoll) may not support file registration
    /// and will return success without doing anything.
    fn register_files(&mut self, fds: &[RawFd]) -> Result<u32>;

    /// Unregister all registered file descriptors.
    ///
    /// Removes all previously registered file descriptors from the
    /// backend's optimization tables. This should be called before
    /// closing registered file descriptors to avoid resource leaks.
    ///
    /// # Errors
    ///
    /// Returns backend-specific errors if unregistration fails.
    /// Some backends may return success even if no files were registered.
    fn unregister_files(&mut self) -> Result<()>;

    /// Register buffers for optimized access.
    ///
    /// Pre-registers buffers with the backend for improved performance.
    /// Registered buffers can be referenced by index in operations,
    /// avoiding the need to pass buffer addresses each time.
    ///
    /// # Arguments
    ///
    /// * `buffers` - Slice of pinned buffers to register
    ///
    /// # Returns
    ///
    /// Returns the starting index where buffers were registered in the
    /// backend's buffer table.
    ///
    /// # Safety
    ///
    /// The buffers must remain pinned and valid for the entire duration
    /// they are registered. Moving or deallocating registered buffers
    /// while they are registered will cause undefined behavior.
    ///
    /// # Errors
    ///
    /// - Returns `InvalidInput` if the buffer array is empty
    /// - Returns backend-specific errors for registration failures
    fn register_buffers(&mut self, buffers: &[Pin<Box<[u8]>>]) -> Result<u32>;

    /// Unregister all registered buffers.
    ///
    /// Removes all previously registered buffers from the backend.
    /// After this call, the buffers can be safely moved or deallocated.
    ///
    /// # Errors
    ///
    /// Returns backend-specific errors if unregistration fails.
    fn unregister_buffers(&mut self) -> Result<()>;

    /// Get the capacity of the submission queue.
    ///
    /// Returns the maximum number of operations that can be queued
    /// for submission at one time. This represents the backend's
    /// internal queue size and affects how many operations can be
    /// batched together.
    ///
    /// For backends without explicit submission queues, this returns
    /// a reasonable default value.
    fn capacity(&self) -> u32;

    /// Get completion queue statistics (ready count, total capacity).
    ///
    /// Returns a tuple of (ready_count, total_capacity) where:
    /// - ready_count: Number of completed operations waiting to be processed
    /// - total_capacity: Maximum number of completions the queue can hold
    ///
    /// This is useful for monitoring queue utilization and detecting
    /// when the completion queue might be getting full.
    ///
    /// For backends without explicit completion queues, returns
    /// reasonable approximations based on pending operations.
    fn completion_queue_stats(&mut self) -> (usize, usize);
}

/// Detect the best available backend for the current system.
///
/// Attempts to create the most performant backend available on the current
/// system, falling back to less optimal but more compatible backends if
/// necessary.
///
/// # Backend Selection Priority
///
/// 1. **io_uring** (Linux 5.1+): Highest performance, kernel-level async I/O
/// 2. **epoll** (Linux): Traditional event-driven I/O, widely compatible
///
/// # Arguments
///
/// * `entries` - Desired capacity for the backend's operation queues
///
/// # Returns
///
/// Returns a boxed Backend trait object for the best available backend.
///
/// # Errors
///
/// Returns an error only if no backends are available on the current system,
/// which should not happen on supported platforms.
///
/// # Examples
///
/// ```rust,no_run
/// # use safer_ring::backend::detect_backend;
/// # fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let backend = detect_backend(32)?;
/// println!("Using backend: {}", backend.name());
/// # Ok(())
/// # }
/// ```
pub fn detect_backend(_entries: u32) -> Result<Box<dyn Backend>> {
    // Try io_uring first on Linux
    #[cfg(target_os = "linux")]
    {
        match io_uring::IoUringBackend::new(_entries) {
            Ok(backend) => {
                return Ok(Box::new(backend));
            }
            Err(_e) => {
                // io_uring failed, fall back to epoll
            }
        }
    }

    // Fall back to epoll
    match epoll::EpollBackend::new() {
        Ok(backend) => Ok(Box::new(backend)),
        Err(e) => Err(e),
    }
}
</file>

<file path="buffer/allocation.rs">
//! Memory allocation utilities for pinned buffers.
//!
//! This module provides specialized buffer allocation functions optimized for
//! Direct Memory Access (DMA) operations and io_uring. The allocators ensure
//! proper memory alignment and zero-initialization for safe kernel interactions.
//!
//! # Key Features
//!
//! - Page-aligned allocation for optimal DMA performance
//! - Zero-initialized memory for security
//! - Custom alignment support for specialized use cases
//! - Fallback strategies for allocation failures
//!
//! # Examples
//!
//! ```
//! use safer_ring::buffer::allocation::{allocate_aligned_buffer, allocate_with_alignment};
//!
//! // Allocate a page-aligned buffer for DMA operations
//! let buffer = allocate_aligned_buffer(8192);
//! assert_eq!(buffer.len(), 8192);
//!
//! // Allocate with custom alignment
//! let aligned_buffer = allocate_with_alignment(1024, 64);
//! assert_eq!(aligned_buffer.len(), 1024);
//! ```

use std::alloc::{alloc_zeroed, Layout};

/// Allocates a zero-initialized buffer with optimal alignment for DMA operations.
///
/// This function attempts to allocate memory with page-aligned (4096 byte) alignment
/// for optimal performance with Direct Memory Access operations. If page alignment
/// fails, it falls back to natural byte alignment. The allocated memory is
/// zero-initialized for security.
///
/// # Parameters
///
/// * `size` - The size in bytes of the buffer to allocate. If 0, returns an empty slice.
///
/// # Returns
///
/// Returns a `Box<[u8]>` containing the allocated zero-initialized buffer.
/// The buffer will be page-aligned (4096 bytes) when possible, or naturally
/// aligned as a fallback.
///
/// # Panics
///
/// Panics if:
/// - Memory allocation fails (out of memory)
/// - The size parameter is too large for the system to handle
///
/// # Examples
///
/// ```
/// use safer_ring::buffer::allocation::allocate_aligned_buffer;
///
/// // Allocate an 8KB buffer
/// let buffer = allocate_aligned_buffer(8192);
/// assert_eq!(buffer.len(), 8192);
/// assert!(buffer.iter().all(|&b| b == 0)); // All zeros
///
/// // Empty buffer case
/// let empty = allocate_aligned_buffer(0);
/// assert_eq!(empty.len(), 0);
/// ```
pub fn allocate_aligned_buffer(size: usize) -> Box<[u8]> {
    if size == 0 {
        return Box::new([]);
    }

    // Try page-aligned allocation first for better DMA performance
    let layout = Layout::from_size_align(size, 4096).unwrap_or_else(|_| {
        // Fall back to natural alignment if page alignment fails
        Layout::from_size_align(size, std::mem::align_of::<u8>())
            .expect("Failed to create layout for buffer allocation")
    });

    unsafe {
        let ptr = alloc_zeroed(layout);
        if ptr.is_null() {
            panic!("Failed to allocate aligned buffer of size {}", size);
        }

        // Convert raw pointer to boxed slice
        let slice = std::slice::from_raw_parts_mut(ptr, size);
        Box::from_raw(slice)
    }
}

/// Allocates a buffer with specific alignment requirements.
///
/// This function allocates zero-initialized memory with a custom alignment
/// requirement. Unlike `allocate_aligned_buffer`, this function allows you to
/// specify the exact alignment needed, which is useful for specialized hardware
/// requirements or performance optimizations.
///
/// # Parameters
///
/// * `size` - The size in bytes of the buffer to allocate. If 0, returns an empty slice.
/// * `align` - The required alignment in bytes. Must be a power of 2.
///
/// # Returns
///
/// Returns a `Box<[u8]>` containing the allocated zero-initialized buffer
/// aligned to the specified boundary.
///
/// # Panics
///
/// Panics if:
/// - The `align` parameter is not a power of 2
/// - The `size` and `align` combination is invalid
/// - Memory allocation fails (out of memory)
/// - The alignment requirement cannot be satisfied
///
/// # Examples
///
/// ```
/// use safer_ring::buffer::allocation::allocate_with_alignment;
///
/// // Allocate 1KB buffer aligned to 64-byte boundary (for cache line alignment)
/// let buffer = allocate_with_alignment(1024, 64);
/// assert_eq!(buffer.len(), 1024);
/// assert!(buffer.iter().all(|&b| b == 0)); // All zeros
///
/// // Allocate with 16-byte alignment
/// let aligned = allocate_with_alignment(256, 16);
/// assert_eq!(aligned.len(), 256);
///
/// // Empty buffer case
/// let empty = allocate_with_alignment(0, 32);
/// assert_eq!(empty.len(), 0);
/// ```
pub fn allocate_with_alignment(size: usize, align: usize) -> Box<[u8]> {
    if size == 0 {
        return Box::new([]);
    }

    let layout = Layout::from_size_align(size, align).expect("Invalid size/alignment combination");

    unsafe {
        let ptr = alloc_zeroed(layout);
        if ptr.is_null() {
            panic!(
                "Failed to allocate buffer of size {} with alignment {}",
                size, align
            );
        }

        let slice = std::slice::from_raw_parts_mut(ptr, size);
        Box::from_raw(slice)
    }
}
</file>

<file path="buffer/generation.rs">
//! Generation tracking for buffer lifecycle management.

use std::sync::atomic::{AtomicU64, Ordering};

/// Atomic generation counter for tracking buffer lifecycle events.
///
/// This counter provides thread-safe tracking of buffer state changes throughout
/// its lifecycle. Each buffer operation (allocation, use, reuse) can increment
/// the generation to help with debugging buffer lifecycle issues and detecting
/// use-after-free scenarios in development builds.
///
/// The counter uses relaxed atomic ordering since exact ordering of generation
/// updates across threads is not critical for its debugging purposes.
///
/// # Thread Safety
///
/// All operations on `GenerationCounter` are thread-safe and can be called
/// concurrently from multiple threads.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::GenerationCounter;
///
/// let counter = GenerationCounter::new();
/// assert_eq!(counter.get(), 0);
///
/// counter.increment();
/// assert_eq!(counter.get(), 1);
///
/// counter.set(42);
/// assert_eq!(counter.get(), 42);
/// ```
#[derive(Debug)]
pub struct GenerationCounter {
    /// Atomic counter that tracks buffer lifecycle events
    counter: AtomicU64,
}

impl GenerationCounter {
    /// Creates a new generation counter starting at 0.
    #[inline]
    pub const fn new() -> Self {
        Self {
            counter: AtomicU64::new(0),
        }
    }

    /// Returns the current generation value.
    #[inline]
    pub fn get(&self) -> u64 {
        self.counter.load(Ordering::Relaxed)
    }

    /// Increments the generation counter atomically.
    #[inline]
    pub fn increment(&self) {
        self.counter.fetch_add(1, Ordering::Relaxed);
    }

    /// Sets the generation counter to a specific value.
    #[inline]
    pub fn set(&self, value: u64) {
        self.counter.store(value, Ordering::Relaxed);
    }
}

impl Default for GenerationCounter {
    fn default() -> Self {
        Self::new()
    }
}

impl Clone for GenerationCounter {
    /// Creates a new counter with the same generation value.
    fn clone(&self) -> Self {
        Self {
            counter: AtomicU64::new(self.get()),
        }
    }
}
</file>

<file path="buffer/mod.rs">
//! Pinned buffer management for safe io_uring operations.
//!
//! This module provides [`PinnedBuffer<T>`] which ensures buffers remain pinned in memory
//! during io_uring operations, preventing use-after-free bugs and ensuring memory safety.
//!
//! # Key Features
//!
//! - **Memory Pinning**: Guarantees stable memory addresses using [`Pin<Box<T>>`]
//! - **Generation Tracking**: Atomic counters for buffer lifecycle debugging
//! - **NUMA Awareness**: Platform-specific NUMA-aware allocation (Linux)
//! - **DMA Optimization**: Page-aligned allocation for optimal hardware performance
//! - **Thread Safety**: Safe sharing and transfer between threads
//!
//! # Usage Examples
//!
//! ```rust
//! use safer_ring::buffer::PinnedBuffer;
//!
//! // Create a pinned buffer for I/O operations
//! let mut buffer = PinnedBuffer::with_capacity(4096);
//! assert_eq!(buffer.len(), 4096);
//!
//! // Get a pinned mutable slice for io_uring operations
//! let pinned_slice = buffer.as_mut_slice();
//! // This slice can be safely used with io_uring
//!
//! // Create from existing data
//! let data = b"Hello, io_uring!".to_vec();
//! let buffer = PinnedBuffer::from_vec(data);
//! assert_eq!(buffer.as_slice(), b"Hello, io_uring!");
//! ```
//!
//! # Safety Considerations
//!
//! The pinned buffers in this module are designed to work safely with asynchronous
//! I/O operations. The pinning guarantees prevent the underlying memory from being
//! moved or freed while I/O operations are in flight, which is essential for the
//! zero-copy nature of io_uring.

/// Memory allocation utilities for creating aligned and optimized buffers.
///
/// This module provides functions for allocating buffers with specific alignment
/// requirements, particularly page-aligned buffers for optimal DMA performance
/// with io_uring operations.
pub mod allocation;

/// Generation tracking utilities for buffer lifecycle management.
///
/// This module provides atomic counters for tracking buffer state changes,
/// helping with debugging buffer lifecycle issues and detecting potential
/// use-after-free scenarios in development builds.
pub mod generation;

/// NUMA-aware buffer allocation for multi-socket systems.
///
/// This module provides NUMA-aware memory allocation functions that attempt
/// to allocate buffers on specific NUMA nodes for optimal performance on
/// multi-socket systems. On Linux systems, it uses CPU affinity and sysfs
/// to determine NUMA topology and allocate memory locally.
pub mod numa;

pub use allocation::*;
pub use generation::*;
pub use numa::*;

use std::pin::Pin;

/// A buffer that is pinned in memory for io_uring operations.
///
/// This type ensures the underlying buffer cannot be moved in memory while being used
/// for I/O operations. It uses [`Pin<Box<T>>`] to provide stable memory addresses
/// required by io_uring's zero-copy semantics.
///
/// # Thread Safety
///
/// `PinnedBuffer<T>` implements `Send` and `Sync` when `T` implements these traits,
/// making it safe to share across threads and use in async contexts.
///
/// # Generation Tracking
///
/// Each buffer includes a [`GenerationCounter`] for lifecycle tracking and debugging.
/// This helps identify buffer reuse patterns and can assist in detecting potential
/// use-after-free scenarios during development.
///
/// # Memory Layout
///
/// The buffer uses heap allocation via [`Pin<Box<T>>`] which guarantees:
/// - Stable memory addresses (required for io_uring)
/// - Automatic cleanup when dropped
/// - Zero-copy semantics for I/O operations
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::PinnedBuffer;
/// use std::pin::Pin;
///
/// // Create a pinned buffer from data
/// let buffer = PinnedBuffer::new([1, 2, 3, 4]);
/// assert_eq!(buffer.len(), 4);
///
/// // Access the pinned data
/// let pinned_ref: Pin<&[u8; 4]> = buffer.as_pin();
///
/// // Create a dynamic buffer
/// let mut dynamic = PinnedBuffer::with_capacity(1024);
/// let slice: Pin<&mut [u8]> = dynamic.as_mut_slice();
/// ```
pub struct PinnedBuffer<T: ?Sized> {
    /// Heap-allocated, pinned buffer data - guarantees stable memory address
    inner: Pin<Box<T>>,
    /// Generation counter for tracking buffer lifecycle and reuse  
    generation: GenerationCounter,
}

impl<T: ?Sized> PinnedBuffer<T> {
    /// Returns a pinned reference to the buffer data.
    ///
    /// This method provides safe access to the pinned data while maintaining
    /// the pinning guarantees required for io_uring operations.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    /// use std::pin::Pin;
    ///
    /// let buffer = PinnedBuffer::new([1, 2, 3, 4]);
    /// let pinned_ref: Pin<&[u8; 4]> = buffer.as_pin();
    /// assert_eq!(&*pinned_ref, &[1, 2, 3, 4]);
    /// ```
    #[inline]
    pub fn as_pin(&self) -> Pin<&T> {
        self.inner.as_ref()
    }

    /// Returns a mutable pinned reference to the buffer data.
    ///
    /// This method provides safe mutable access to the pinned data while
    /// maintaining the pinning guarantees. Essential for io_uring write operations.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    /// use std::pin::Pin;
    ///
    /// let mut buffer = PinnedBuffer::new([0; 4]);
    /// let mut pinned_ref: Pin<&mut [u8; 4]> = buffer.as_pin_mut();
    /// // Safe to modify through pinned reference
    /// ```
    #[inline]
    pub fn as_pin_mut(&mut self) -> Pin<&mut T> {
        self.inner.as_mut()
    }

    /// Returns the current generation of this buffer.
    ///
    /// The generation counter tracks buffer lifecycle events and can be used
    /// for debugging buffer reuse patterns and detecting potential issues.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    /// let initial_gen = buffer.generation();
    ///
    /// buffer.mark_in_use();
    /// assert!(buffer.generation() > initial_gen);
    /// ```
    #[inline]
    pub fn generation(&self) -> u64 {
        self.generation.get()
    }

    /// Mark this buffer as in use and increment generation.
    ///
    /// This method should be called when the buffer is being used for I/O
    /// operations. It helps track buffer lifecycle for debugging purposes.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    /// let gen_before = buffer.generation();
    ///
    /// buffer.mark_in_use();
    /// assert_eq!(buffer.generation(), gen_before + 1);
    /// ```
    pub fn mark_in_use(&mut self) {
        self.generation.increment();
    }

    /// Mark this buffer as available and increment generation.
    ///
    /// This method should be called when the buffer is no longer being used
    /// for I/O operations and is available for reuse.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    /// buffer.mark_in_use();
    /// let gen_after_use = buffer.generation();
    ///
    /// buffer.mark_available();
    /// assert_eq!(buffer.generation(), gen_after_use + 1);
    /// ```
    pub fn mark_available(&mut self) {
        self.generation.increment();
    }

    /// Check if this buffer is available for use.
    ///
    /// Note: This is a simple implementation - a more sophisticated
    /// version might track actual usage state.
    pub fn is_available(&self) -> bool {
        true // For now, always return true
    }

    /// Returns a raw pointer to the buffer data.
    ///
    /// # Safety
    ///
    /// The pointer is valid only while the buffer exists.
    #[inline]
    pub fn as_ptr(&self) -> *const T {
        Pin::as_ref(&self.inner).get_ref() as *const T
    }

    /// Returns a mutable raw pointer to the buffer data.
    ///
    /// # Safety
    ///
    /// The pointer is valid only while the buffer exists.
    #[inline]
    pub fn as_mut_ptr(&mut self) -> *mut T {
        unsafe { Pin::as_mut(&mut self.inner).get_unchecked_mut() as *mut T }
    }
}

impl<T> PinnedBuffer<T> {
    /// Creates a new pinned buffer from the given data.
    ///
    /// This constructor takes ownership of the provided data and pins it in memory,
    /// making it suitable for io_uring operations. The data is moved to the heap
    /// and its address becomes stable for the lifetime of the buffer.
    ///
    /// # Parameters
    ///
    /// * `data` - The data to pin in memory. Can be any type T.
    ///
    /// # Returns
    ///
    /// Returns a new `PinnedBuffer<T>` with the data pinned and generation counter
    /// initialized to 0.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// // Pin an array
    /// let buffer = PinnedBuffer::new([1, 2, 3, 4]);
    /// assert_eq!(buffer.len(), 4);
    ///
    /// // Pin a custom struct
    /// #[derive(Debug, PartialEq)]
    /// struct Data { value: u32 }
    ///
    /// let buffer = PinnedBuffer::new(Data { value: 42 });
    /// assert_eq!(buffer.as_pin().value, 42);
    /// ```
    #[inline]
    pub fn new(data: T) -> Self {
        Self {
            inner: Box::pin(data),
            generation: GenerationCounter::new(),
        }
    }
}

impl PinnedBuffer<[u8]> {
    /// Creates a new zero-initialized pinned buffer with the specified size.
    ///
    /// This is the primary method for creating buffers for I/O operations.
    /// The buffer is heap-allocated, zero-initialized, and pinned for stable
    /// memory addresses required by io_uring.
    ///
    /// # Parameters
    ///
    /// * `size` - The size of the buffer in bytes. Must be greater than 0 for meaningful use.
    ///
    /// # Returns
    ///
    /// Returns a `PinnedBuffer<[u8]>` containing a zero-initialized buffer of the
    /// specified size, ready for I/O operations.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// // Create a 4KB buffer for file I/O
    /// let buffer = PinnedBuffer::with_capacity(4096);
    /// assert_eq!(buffer.len(), 4096);
    /// assert!(buffer.as_slice().iter().all(|&b| b == 0)); // All zeros
    ///
    /// // Create buffer for network I/O
    /// let net_buffer = PinnedBuffer::with_capacity(1500); // MTU size
    /// assert_eq!(net_buffer.len(), 1500);
    /// ```
    pub fn with_capacity(size: usize) -> Self {
        let data = vec![0u8; size].into_boxed_slice();
        Self {
            inner: Pin::from(data),
            generation: GenerationCounter::new(),
        }
    }

    /// Creates a new pinned buffer from a vector.
    ///
    /// This method takes ownership of a vector and converts it into a pinned
    /// buffer. The vector's data is preserved and the buffer can be used
    /// immediately for I/O operations.
    ///
    /// # Parameters
    ///
    /// * `vec` - The vector to convert into a pinned buffer.
    ///
    /// # Returns
    ///
    /// Returns a `PinnedBuffer<[u8]>` containing the vector's data, pinned
    /// and ready for I/O operations.
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// let data = vec![1, 2, 3, 4, 5];
    /// let buffer = PinnedBuffer::from_vec(data);
    /// assert_eq!(buffer.as_slice(), &[1, 2, 3, 4, 5]);
    /// assert_eq!(buffer.len(), 5);
    /// ```
    #[inline]
    pub fn from_vec(vec: Vec<u8>) -> Self {
        Self::from_boxed_slice(vec.into_boxed_slice())
    }

    /// Creates a new pinned buffer from a boxed slice.
    #[inline]
    pub fn from_boxed_slice(slice: Box<[u8]>) -> Self {
        Self {
            inner: Pin::from(slice),
            generation: GenerationCounter::new(),
        }
    }

    /// Creates a new pinned buffer by copying from a slice.
    #[inline]
    pub fn from_slice(slice: &[u8]) -> Self {
        Self::from_vec(slice.to_vec())
    }

    /// Creates a new aligned pinned buffer with the specified size.
    ///
    /// This method creates a pinned buffer using page-aligned allocation (4096 bytes)
    /// for optimal DMA performance with io_uring operations. The alignment helps
    /// reduce memory copy overhead in the kernel.
    ///
    /// # Parameters
    ///
    /// * `size` - The size of the buffer in bytes. The buffer will be page-aligned
    ///   regardless of the size specified.
    ///
    /// # Returns
    ///
    /// Returns a `PinnedBuffer<[u8]>` with page-aligned, zero-initialized memory
    /// optimized for high-performance I/O operations.
    ///
    /// # Performance Notes
    ///
    /// Page-aligned buffers can provide significant performance benefits for:
    /// - Large sequential I/O operations
    /// - Direct memory access (DMA) operations
    /// - Kernel bypass operations with io_uring
    ///
    /// # Examples
    ///
    /// ```rust
    /// use safer_ring::buffer::PinnedBuffer;
    ///
    /// // Create aligned buffer for high-performance I/O
    /// let buffer = PinnedBuffer::with_capacity_aligned(8192);
    /// assert_eq!(buffer.len(), 8192);
    /// assert!(buffer.as_slice().iter().all(|&b| b == 0)); // Zero-initialized
    ///
    /// // Even small sizes get page alignment benefits
    /// let small_aligned = PinnedBuffer::with_capacity_aligned(64);
    /// assert_eq!(small_aligned.len(), 64);
    /// ```
    pub fn with_capacity_aligned(size: usize) -> Self {
        let data = allocate_aligned_buffer(size);
        Self {
            inner: Pin::from(data),
            generation: GenerationCounter::new(),
        }
    }

    /// Creates a new NUMA-aware pinned buffer with the specified size.
    /// On Linux, attempts to allocate memory on the specified NUMA node.
    #[cfg(target_os = "linux")]
    pub fn with_capacity_numa(size: usize, numa_node: Option<usize>) -> Self {
        let data = allocate_numa_buffer(size, numa_node);
        Self {
            inner: Pin::from(data),
            generation: GenerationCounter::new(),
        }
    }

    /// Creates a new NUMA-aware pinned buffer (stub implementation for non-Linux).
    #[cfg(not(target_os = "linux"))]
    pub fn with_capacity_numa(size: usize, _numa_node: Option<usize>) -> Self {
        // On non-Linux platforms, fall back to regular aligned allocation
        Self::with_capacity_aligned(size)
    }

    /// Returns a mutable slice reference with pinning guarantees.
    #[inline]
    pub fn as_mut_slice(&mut self) -> Pin<&mut [u8]> {
        self.inner.as_mut()
    }

    /// Returns an immutable slice reference.
    #[inline]
    pub fn as_slice(&self) -> &[u8] {
        &self.inner
    }

    /// Returns the length of the buffer.
    #[inline]
    pub fn len(&self) -> usize {
        self.inner.len()
    }

    /// Checks if the buffer is empty.
    #[inline]
    pub fn is_empty(&self) -> bool {
        self.inner.is_empty()
    }
}

impl<const N: usize> PinnedBuffer<[u8; N]> {
    /// Creates a new pinned buffer from a fixed-size array.
    #[inline]
    pub fn from_array(array: [u8; N]) -> Self {
        Self::new(array)
    }

    /// Creates a new zero-initialized pinned buffer.
    #[inline]
    pub fn zeroed() -> Self {
        Self::new([0u8; N])
    }

    /// Returns an immutable slice reference to the array.
    #[inline]
    pub fn as_slice(&self) -> &[u8] {
        &*self.inner
    }

    /// Returns a mutable slice reference with pinning guarantees.
    #[inline]
    pub fn as_mut_slice(&mut self) -> Pin<&mut [u8]> {
        unsafe {
            let array_ptr = self.inner.as_mut().get_unchecked_mut().as_mut_ptr();
            let slice = std::slice::from_raw_parts_mut(array_ptr, N);
            Pin::new_unchecked(slice)
        }
    }

    /// Returns the length of the buffer.
    #[inline]
    pub const fn len(&self) -> usize {
        N
    }

    /// Checks if the buffer is empty.
    #[inline]
    pub const fn is_empty(&self) -> bool {
        N == 0
    }
}

// SAFETY: PinnedBuffer can be sent between threads when T is Send
unsafe impl<T: Send + ?Sized> Send for PinnedBuffer<T> {}

// SAFETY: PinnedBuffer can be shared between threads when T is Sync
unsafe impl<T: Sync + ?Sized> Sync for PinnedBuffer<T> {}
</file>

<file path="buffer/numa.rs">
//! NUMA-aware buffer allocation for multi-socket systems.

#[cfg(target_os = "linux")]
use std::fs;
#[cfg(target_os = "linux")]
use std::path::Path;

use crate::buffer::allocation::allocate_aligned_buffer;

/// Allocates a buffer with NUMA affinity on Linux systems.
///
/// This function attempts to allocate memory on the specified NUMA node by
/// temporarily binding the current thread to CPUs on that node during allocation.
/// The Linux kernel's first-touch policy will then prefer to allocate memory
/// locally to those CPUs.
///
/// # Arguments
///
/// * `size` - The size of the buffer to allocate in bytes
/// * `numa_node` - The NUMA node to allocate on, or `None` for any node
///
/// # Returns
///
/// Returns a boxed slice containing the allocated buffer. The buffer is
/// zero-initialized and page-aligned for optimal DMA performance.
///
/// # Fallback Behavior
///
/// If NUMA allocation fails or NUMA is not available on the system, this
/// function falls back to regular page-aligned allocation using
/// [`allocate_aligned_buffer`].
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::allocate_numa_buffer;
///
/// // Allocate on any NUMA node
/// let buffer = allocate_numa_buffer(4096, None);
/// assert_eq!(buffer.len(), 4096);
///
/// // Try to allocate on NUMA node 0
/// let buffer = allocate_numa_buffer(8192, Some(0));
/// assert_eq!(buffer.len(), 8192);
/// ```
///
/// # Platform Notes
///
/// This function is only available on Linux. On other platforms, use the
/// stub version which falls back to regular aligned allocation.
#[cfg(target_os = "linux")]
pub fn allocate_numa_buffer(size: usize, numa_node: Option<usize>) -> Box<[u8]> {
    match numa_node {
        Some(node) => {
            // Try NUMA-aware allocation if available
            if is_numa_available() {
                match try_numa_allocation(size, node) {
                    Ok(buffer) => buffer,
                    Err(_) => {
                        // Fall back to regular allocation on failure
                        allocate_aligned_buffer(size)
                    }
                }
            } else {
                allocate_aligned_buffer(size)
            }
        }
        None => allocate_aligned_buffer(size),
    }
}

/// Try NUMA-aware allocation by setting CPU affinity.
#[cfg(target_os = "linux")]
fn try_numa_allocation(size: usize, node: usize) -> Result<Box<[u8]>, std::io::Error> {
    // Simplified NUMA allocation approach:
    // 1. Bind current thread to CPUs on the specified NUMA node
    // 2. Allocate memory (Linux will prefer local memory)
    // 3. Return to original affinity

    // Save current CPU affinity
    let original_affinity = get_current_affinity()?;

    // Set affinity to NUMA node CPUs
    if let Err(e) = set_numa_affinity(node) {
        return Err(e);
    }

    // Allocate buffer (kernel will prefer local memory)
    let result = allocate_aligned_buffer(size);

    // Restore original affinity (best effort)
    let _ = set_cpu_affinity(&original_affinity);

    Ok(result)
}

/// Get current CPU affinity mask.
#[cfg(target_os = "linux")]
fn get_current_affinity() -> Result<libc::cpu_set_t, std::io::Error> {
    use std::mem;

    unsafe {
        let mut cpu_set: libc::cpu_set_t = mem::zeroed();
        if libc::sched_getaffinity(0, mem::size_of::<libc::cpu_set_t>(), &mut cpu_set) == 0 {
            Ok(cpu_set)
        } else {
            Err(std::io::Error::last_os_error())
        }
    }
}

/// Set CPU affinity to CPUs on the specified NUMA node.
#[cfg(target_os = "linux")]
fn set_numa_affinity(node: usize) -> Result<(), std::io::Error> {
    use std::mem;

    // Get CPUs for this NUMA node
    let cpus = get_numa_node_cpus(node)?;

    if cpus.is_empty() {
        return Err(std::io::Error::new(
            std::io::ErrorKind::InvalidInput,
            format!("No CPUs found for NUMA node {}", node),
        ));
    }

    unsafe {
        let mut cpu_set: libc::cpu_set_t = mem::zeroed();
        libc::CPU_ZERO(&mut cpu_set);

        // Set CPU bits for this NUMA node
        for cpu in cpus {
            if cpu < 1024 {
                // CPU_SETSIZE limit
                libc::CPU_SET(cpu, &mut cpu_set);
            }
        }

        if libc::sched_setaffinity(0, mem::size_of::<libc::cpu_set_t>(), &cpu_set) == 0 {
            Ok(())
        } else {
            Err(std::io::Error::last_os_error())
        }
    }
}

/// Set specific CPU affinity.
#[cfg(target_os = "linux")]
fn set_cpu_affinity(cpu_set: &libc::cpu_set_t) -> Result<(), std::io::Error> {
    use std::mem;

    unsafe {
        if libc::sched_setaffinity(0, mem::size_of::<libc::cpu_set_t>(), cpu_set) == 0 {
            Ok(())
        } else {
            Err(std::io::Error::last_os_error())
        }
    }
}

/// Get list of CPUs for a NUMA node by reading sysfs.
#[cfg(target_os = "linux")]
fn get_numa_node_cpus(node: usize) -> Result<Vec<usize>, std::io::Error> {
    let path = format!("/sys/devices/system/node/node{}/cpulist", node);

    if !Path::new(&path).exists() {
        return Err(std::io::Error::new(
            std::io::ErrorKind::NotFound,
            format!("NUMA node {} not found", node),
        ));
    }

    let cpulist = fs::read_to_string(&path)?;
    parse_cpu_list(&cpulist.trim())
}

/// Parse CPU list format (e.g., "0-7,16-23" -> [0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23]).
#[allow(dead_code)]
fn parse_cpu_list(cpulist: &str) -> Result<Vec<usize>, std::io::Error> {
    let mut cpus = Vec::new();

    for part in cpulist.split(',') {
        if part.contains('-') {
            // Range format: "0-7"
            let range: Vec<&str> = part.split('-').collect();
            if range.len() == 2 {
                let start: usize = range[0].parse().map_err(|_| {
                    std::io::Error::new(std::io::ErrorKind::InvalidData, "Invalid CPU range")
                })?;
                let end: usize = range[1].parse().map_err(|_| {
                    std::io::Error::new(std::io::ErrorKind::InvalidData, "Invalid CPU range")
                })?;

                for cpu in start..=end {
                    cpus.push(cpu);
                }
            }
        } else {
            // Single CPU: "16"
            let cpu: usize = part.parse().map_err(|_| {
                std::io::Error::new(std::io::ErrorKind::InvalidData, "Invalid CPU number")
            })?;
            cpus.push(cpu);
        }
    }

    Ok(cpus)
}

/// Checks if NUMA (Non-Uniform Memory Access) is available on the system.
///
/// This function determines NUMA availability by checking for the existence
/// of `/sys/devices/system/node` and verifying that multiple NUMA nodes exist.
/// A system is considered NUMA-capable if it has more than just "node0".
///
/// # Returns
///
/// Returns `true` if NUMA is available and the system has multiple nodes,
/// `false` otherwise.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::is_numa_available;
///
/// if is_numa_available() {
///     println!("NUMA is available on this system");
///     // Use NUMA-aware allocation
/// } else {
///     println!("NUMA not available, using regular allocation");
///     // Fall back to regular allocation
/// }
/// ```
///
/// # Platform Notes
///
/// This function is only available on Linux. On other platforms, NUMA
/// support is not available and the function will return `false`.
#[cfg(target_os = "linux")]
pub fn is_numa_available() -> bool {
    Path::new("/sys/devices/system/node").exists()
        && fs::read_dir("/sys/devices/system/node")
            .map(|entries| entries.count() > 1) // More than just "node0"
            .unwrap_or(false)
}

/// Allocates a buffer with NUMA preference (stub for non-Linux platforms).
///
/// On non-Linux platforms, NUMA support is not available, so this function
/// serves as a compatibility stub that falls back to regular page-aligned
/// allocation regardless of the `numa_node` parameter.
///
/// # Arguments
///
/// * `size` - The size of the buffer to allocate in bytes
/// * `_numa_node` - Ignored on non-Linux platforms
///
/// # Returns
///
/// Returns a boxed slice containing a page-aligned, zero-initialized buffer
/// allocated using [`allocate_aligned_buffer`].
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::allocate_numa_buffer;
///
/// // On non-Linux platforms, numa_node parameter is ignored
/// let buffer = allocate_numa_buffer(4096, Some(0));
/// assert_eq!(buffer.len(), 4096);
/// ```
#[cfg(not(target_os = "linux"))]
pub fn allocate_numa_buffer(size: usize, _numa_node: Option<usize>) -> Box<[u8]> {
    allocate_aligned_buffer(size)
}

/// Gets the NUMA node for the current CPU (Linux only).
///
/// This function determines which NUMA node the current thread is running on
/// by examining `/proc/self/stat` and using the `getcpu` system call as a fallback.
/// This information can be useful for making NUMA-aware allocation decisions.
///
/// # Returns
///
/// Returns `Some(node_id)` if the NUMA node can be determined, or `None` if
/// the information is not available or an error occurs.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::current_numa_node;
///
/// match current_numa_node() {
///     Some(node) => println!("Currently running on NUMA node {}", node),
///     None => println!("Could not determine current NUMA node"),
/// }
/// ```
///
/// # Implementation Notes
///
/// This function tries two methods:
/// 1. Parse `/proc/self/stat` to get the current CPU, then determine its NUMA node
/// 2. Use the `getcpu` system call directly (x86_64 only)
///
/// # Platform Notes
///
/// This function is only available on Linux. On other platforms, use the
/// stub version which always returns `None`.
#[cfg(target_os = "linux")]
pub fn current_numa_node() -> Option<usize> {
    // Method 1: Try to get from /proc/self/stat
    if let Ok(stat) = fs::read_to_string("/proc/self/stat") {
        // CPU is field 39 (0-indexed: field 38)
        let fields: Vec<&str> = stat.split_whitespace().collect();
        if let Some(cpu_str) = fields.get(38) {
            if let Ok(cpu) = cpu_str.parse::<usize>() {
                // Try to determine NUMA node for this CPU
                if let Ok(node) = get_cpu_numa_node(cpu) {
                    return Some(node);
                }
            }
        }
    }

    // Method 2: Use getcpu system call if available
    #[cfg(target_arch = "x86_64")]
    {
        unsafe {
            let mut cpu: libc::c_uint = 0;
            let mut node: libc::c_uint = 0;

            // Try getcpu syscall
            if libc::syscall(
                libc::SYS_getcpu,
                &mut cpu,
                &mut node,
                std::ptr::null_mut::<libc::c_void>(),
            ) == 0
            {
                return Some(node as usize);
            }
        }
    }

    None
}

/// Get NUMA node for a specific CPU.
#[cfg(target_os = "linux")]
fn get_cpu_numa_node(cpu: usize) -> Result<usize, std::io::Error> {
    // Read from /sys/devices/system/cpu/cpuX/node
    let path = format!("/sys/devices/system/cpu/cpu{}/node", cpu);

    if Path::new(&path).exists() {
        let node_str = fs::read_to_string(&path)?;
        node_str
            .trim()
            .parse()
            .map_err(|_| std::io::Error::new(std::io::ErrorKind::InvalidData, "Invalid NUMA node"))
    } else {
        // Fallback: assume CPU 0-7 -> node 0, 8-15 -> node 1, etc.
        Ok(cpu / 8)
    }
}

/// Gets the number of NUMA nodes on the system (Linux).
///
/// This function counts the number of NUMA nodes by examining the
/// `/sys/devices/system/node` directory and counting entries that match
/// the pattern `nodeN` where N is a digit.
///
/// # Returns
///
/// Returns the number of NUMA nodes detected on the system, or 1 if
/// the NUMA information cannot be accessed (fallback assumption).
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::numa_node_count;
///
/// let count = numa_node_count();
/// println!("System has {} NUMA nodes", count);
///
/// // Use for NUMA-aware allocation
/// for node in 0..count {
///     // Allocate buffers on each node
/// }
/// ```
///
/// # Implementation Notes
///
/// The function looks for directories matching `/sys/devices/system/node/nodeN`
/// where N consists only of digits. This follows the Linux kernel's NUMA
/// node naming convention.
#[cfg(target_os = "linux")]
pub fn numa_node_count() -> usize {
    if let Ok(entries) = fs::read_dir("/sys/devices/system/node") {
        entries
            .filter_map(|entry| entry.ok())
            .filter(|entry| {
                entry.file_name().to_string_lossy().starts_with("node")
                    && entry
                        .file_name()
                        .to_string_lossy()
                        .chars()
                        .skip(4)
                        .all(|c| c.is_ascii_digit())
            })
            .count()
    } else {
        1 // Default to single node
    }
}

/// Gets the number of NUMA nodes (non-Linux stub).
///
/// On non-Linux platforms, NUMA support is not available, so this function
/// always returns 1, indicating a single uniform memory domain.
///
/// # Returns
///
/// Always returns 1 on non-Linux platforms.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::numa_node_count;
///
/// let count = numa_node_count();
/// // On non-Linux platforms, this will always be 1
/// assert_eq!(count, 1);
/// ```
#[cfg(not(target_os = "linux"))]
pub fn numa_node_count() -> usize {
    1
}

/// Checks if NUMA is available on the system (non-Linux stub).
///
/// On non-Linux platforms, NUMA support is not available, so this function
/// always returns `false`.
///
/// # Returns
///
/// Always returns `false` on non-Linux platforms.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::is_numa_available;
///
/// // On non-Linux platforms, this will always be false
/// assert!(!is_numa_available());
/// ```
#[cfg(not(target_os = "linux"))]
pub fn is_numa_available() -> bool {
    false
}

/// Gets the NUMA node for the current CPU (non-Linux stub).
///
/// On non-Linux platforms, NUMA support is not available, so this function
/// always returns `None` to indicate that the current NUMA node cannot
/// be determined.
///
/// # Returns
///
/// Always returns `None` on non-Linux platforms.
///
/// # Examples
///
/// ```rust
/// use safer_ring::buffer::current_numa_node;
///
/// // On non-Linux platforms, this will always be None
/// assert_eq!(current_numa_node(), None);
/// ```
#[cfg(not(target_os = "linux"))]
pub fn current_numa_node() -> Option<usize> {
    None
}
</file>

<file path="future/io_futures/common.rs">
//! Common utilities and macros for I/O futures.

/// Common polling logic for I/O futures that return buffer ownership.
///
/// This macro reduces code duplication while maintaining type safety.
/// Using a macro instead of a generic function allows us to:
/// - Avoid complex trait bounds and lifetime constraints
/// - Maintain zero-cost abstraction with compile-time expansion
/// - Keep the polling logic inline for better optimization
macro_rules! poll_io_operation {
    ($self:expr, $cx:expr, $future_name:literal) => {{
        let operation = match $self.operation.as_ref() {
            Some(op) => op,
            None => {
                // Polling after completion is a programming error
                panic!("{} polled after completion", $future_name);
            }
        };

        let operation_id = operation.id();

        match $self.ring.try_complete_by_id(operation_id) {
            Ok(Some(result)) => {
                // Extract operation and complete it
                let operation = $self.operation.take().unwrap();
                let completed = operation.complete_with_result(result);
                let (io_result, buffer) = completed.into_result_with_buffer();

                // Clean up waker to prevent memory leaks
                $self.waker_registry.remove_waker(operation_id);

                match io_result {
                    Ok(bytes) => {
                        // Defensive conversion - negative values should already be errors
                        let bytes_usize = if bytes >= 0 {
                            bytes as usize
                        } else {
                            return Poll::Ready(Err(io::Error::new(
                                io::ErrorKind::Other,
                                "Unexpected negative byte count",
                            )));
                        };

                        match buffer {
                            Some(buf) => Poll::Ready(Ok((bytes_usize, buf))),
                            None => Poll::Ready(Err(io::Error::new(
                                io::ErrorKind::Other,
                                concat!($future_name, " completed without buffer"),
                            ))),
                        }
                    }
                    Err(e) => Poll::Ready(Err(e)),
                }
            }
            Ok(None) => {
                // Still pending - register waker for notification
                $self
                    .waker_registry
                    .register_waker(operation_id, $cx.waker().clone());
                Poll::Pending
            }
            Err(e) => {
                // Completion check failed
                $self.waker_registry.remove_waker(operation_id);
                Poll::Ready(Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("Error checking operation completion: {}", e),
                )))
            }
        }
    }};
}

/// Common polling logic for vectored I/O operations.
///
/// Similar to `poll_io_operation` but handles multiple buffers.
/// Vectored operations require different result extraction methods
/// but follow the same async polling pattern.
macro_rules! poll_vectored_operation {
    ($self:expr, $cx:expr, $future_name:literal) => {{
        let operation = match $self.operation.as_ref() {
            Some(op) => op,
            None => {
                panic!("{} polled after completion", $future_name);
            }
        };

        let operation_id = operation.id();

        match $self.ring.try_complete_by_id(operation_id) {
            Ok(Some(result)) => {
                let operation = $self.operation.take().unwrap();
                let completed = operation.complete_with_result(result);
                let (io_result, buffers) = completed.into_result_with_vectored_buffers();

                $self.waker_registry.remove_waker(operation_id);

                match io_result {
                    Ok(bytes) => {
                        let bytes_usize = if bytes >= 0 {
                            bytes as usize
                        } else {
                            return Poll::Ready(Err(io::Error::new(
                                io::ErrorKind::Other,
                                "Unexpected negative byte count",
                            )));
                        };

                        match buffers {
                            Some(bufs) => Poll::Ready(Ok((bytes_usize, bufs))),
                            None => Poll::Ready(Err(io::Error::new(
                                io::ErrorKind::Other,
                                concat!($future_name, " completed without buffers"),
                            ))),
                        }
                    }
                    Err(e) => Poll::Ready(Err(e)),
                }
            }
            Ok(None) => {
                $self
                    .waker_registry
                    .register_waker(operation_id, $cx.waker().clone());
                Poll::Pending
            }
            Err(e) => {
                $self.waker_registry.remove_waker(operation_id);
                Poll::Ready(Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("Error checking {} completion: {}", $future_name, e),
                )))
            }
        }
    }};
}

/// Common drop logic for I/O futures.
///
/// Ensures waker cleanup when futures are dropped before completion.
/// This prevents memory leaks in the waker registry and is critical
/// for proper resource management in async contexts.
macro_rules! impl_future_drop {
    ($self:expr) => {
        if let Some(operation) = &$self.operation {
            $self.waker_registry.remove_waker(operation.id());
        }
    };
}

pub(super) use {impl_future_drop, poll_io_operation, poll_vectored_operation};
</file>

<file path="future/io_futures/file_io.rs">
//! File I/O futures for read and write operations.

use std::future::Future;
use std::io;
use std::marker::PhantomData;
use std::pin::Pin as StdPin;
use std::sync::Arc;
use std::task::{Context, Poll};

use super::common::{impl_future_drop, poll_io_operation};
use crate::future::waker::WakerRegistry;
use crate::operation::{Operation, Submitted};
use crate::ring::Ring;

/// Future for file read operations.
///
/// This future polls the completion queue until the read operation completes,
/// then returns the number of bytes read and buffer ownership. The future
/// ensures proper cleanup of waker registrations and handles both successful
/// completions and error conditions.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
/// * `'buf` - Lifetime of the buffer used for the read operation
///
/// # Returns
///
/// Returns `(usize, Pin<&'buf mut [u8]>)` on success where:
/// - `usize` is the number of bytes read
/// - `Pin<&'buf mut [u8]>` is the buffer with read data
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::fs::File;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let mut buffer = PinnedBuffer::with_capacity(1024);
/// let file = File::open("example.txt")?;
///
/// // Buffer lifetime must outlive the operation
/// let read_future = ring.read(file.as_raw_fd(), buffer.as_mut_slice())?;
/// let (bytes_read, _buffer) = read_future.await?;
///
/// println!("Read {} bytes", bytes_read);
/// # Ok(())
/// # }
/// ```
pub struct ReadFuture<'ring, 'buf> {
    // Option allows taking ownership during completion without Clone
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    // Rc allows sharing waker registry across multiple futures efficiently
    waker_registry: Arc<WakerRegistry>,
    // Explicit lifetime tracking for compile-time safety verification
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

/// Future for file write operations.
///
/// This future polls the completion queue until the write operation completes,
/// then returns the number of bytes written and buffer ownership. Like all
/// I/O futures in this crate, it ensures proper resource cleanup and handles
/// error conditions gracefully.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance  
/// * `'buf` - Lifetime of the buffer containing data to write
///
/// # Returns
///
/// Returns `(usize, Pin<&'buf mut [u8]>)` on success where:
/// - `usize` is the number of bytes written
/// - `Pin<&'buf mut [u8]>` is the buffer that was written from
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::fs::OpenOptions;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let mut buffer = PinnedBuffer::from_slice(b"Hello, world!");
/// let file = OpenOptions::new()
///     .write(true)
///     .create(true)
///     .open("output.txt")?;
///
/// let write_future = ring.write(file.as_raw_fd(), buffer.as_mut_slice())?;
/// let (bytes_written, _buffer) = write_future.await?;
///
/// println!("Wrote {} bytes", bytes_written);
/// # Ok(())
/// # }
/// ```
pub struct WriteFuture<'ring, 'buf> {
    // Same structure as ReadFuture for consistency and shared macro usage
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

impl<'ring, 'buf> ReadFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> WriteFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> Future for ReadFuture<'ring, 'buf> {
    type Output = io::Result<(usize, StdPin<&'buf mut [u8]>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_io_operation!(self, cx, "ReadFuture")
    }
}

impl<'ring, 'buf> Future for WriteFuture<'ring, 'buf> {
    type Output = io::Result<(usize, StdPin<&'buf mut [u8]>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_io_operation!(self, cx, "WriteFuture")
    }
}

impl<'ring, 'buf> Drop for ReadFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}

impl<'ring, 'buf> Drop for WriteFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}
</file>

<file path="future/io_futures/mod.rs">
//! I/O-specific future implementations.
//!
//! This module contains futures for different types of I/O operations,
//! organized by operation type for better maintainability.

mod common;
mod file_io;
mod network_io;
mod vectored_io;

// Re-export all future types
pub use file_io::{ReadFuture, WriteFuture};
pub use network_io::{AcceptFuture, RecvFuture, SendFuture};
pub use vectored_io::{VectoredReadFuture, VectoredWriteFuture};
</file>

<file path="future/io_futures/network_io.rs">
//! Network I/O futures for socket operations.

use std::future::Future;
use std::io;
use std::marker::PhantomData;
use std::os::unix::io::RawFd;
use std::pin::Pin as StdPin;
use std::sync::Arc;
use std::task::{Context, Poll};

use super::common::{impl_future_drop, poll_io_operation};
use crate::future::waker::WakerRegistry;
use crate::operation::{Operation, Submitted};
use crate::ring::Ring;

/// Future for socket accept operations.
///
/// This future waits for an incoming connection on a listening socket and
/// returns the new client file descriptor when a connection is accepted.
/// Unlike read/write operations, accept operations don't require buffer
/// management, so this future has a simpler interface.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
///
/// # Returns
///
/// Returns the raw file descriptor (`RawFd`) of the accepted client connection
/// on success. The caller is responsible for managing the returned file descriptor.
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation};
/// # use std::net::{TcpListener, SocketAddr};
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let listener = TcpListener::bind("127.0.0.1:8080")?;
/// listener.set_nonblocking(true)?;
///
/// let accept_future = ring.accept(listener.as_raw_fd())?;
/// let client_fd = accept_future.await?;
///
/// println!("Accepted client connection: fd {}", client_fd);
/// # Ok(())
/// # }
/// ```
pub struct AcceptFuture<'ring> {
    operation: Option<Operation<'ring, 'static, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    // No buffer lifetime needed for accept operations
    _phantom: PhantomData<&'ring ()>,
}

/// Future for socket send operations.
///
/// This future sends data over a socket connection and returns the number
/// of bytes sent along with buffer ownership when the operation completes.
/// The future handles partial sends and error conditions appropriately.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
/// * `'buf` - Lifetime of the buffer containing data to send
///
/// # Returns
///
/// Returns `(usize, Pin<&'buf mut [u8]>)` on success where:
/// - `usize` is the number of bytes sent
/// - `Pin<&'buf mut [u8]>` is the buffer that was sent from
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::net::TcpStream;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let mut buffer = PinnedBuffer::from_slice(b"Hello, client!");
/// let stream = TcpStream::connect("127.0.0.1:8080")?;
/// stream.set_nonblocking(true)?;
///
/// let send_future = ring.send(stream.as_raw_fd(), buffer.as_mut_slice())?;
/// let (bytes_sent, _buffer) = send_future.await?;
///
/// println!("Sent {} bytes", bytes_sent);
/// # Ok(())
/// # }
/// ```
pub struct SendFuture<'ring, 'buf> {
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

/// Future for socket receive operations.
///
/// This future receives data from a socket connection and returns the number
/// of bytes received along with buffer ownership when the operation completes.
/// The buffer will contain the received data upon successful completion.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
/// * `'buf` - Lifetime of the buffer to receive data into
///
/// # Returns
///
/// Returns `(usize, Pin<&'buf mut [u8]>)` on success where:
/// - `usize` is the number of bytes received
/// - `Pin<&'buf mut [u8]>` is the buffer containing the received data
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::net::TcpStream;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let mut buffer = PinnedBuffer::with_capacity(1024);
/// let stream = TcpStream::connect("127.0.0.1:8080")?;
/// stream.set_nonblocking(true)?;
///
/// let recv_future = ring.recv(stream.as_raw_fd(), buffer.as_mut_slice())?;
/// let (bytes_received, _buffer) = recv_future.await?;
///
/// println!("Received {} bytes", bytes_received);
/// # Ok(())
/// # }
/// ```
pub struct RecvFuture<'ring, 'buf> {
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

impl<'ring> AcceptFuture<'ring> {
    pub(crate) fn new(
        operation: Operation<'ring, 'static, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> SendFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> RecvFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring> Future for AcceptFuture<'ring> {
    type Output = io::Result<RawFd>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let operation = match self.operation.as_ref() {
            Some(op) => op,
            None => {
                panic!("AcceptFuture polled after completion");
            }
        };

        let operation_id = operation.id();

        match self.ring.try_complete_by_id(operation_id) {
            Ok(Some(result)) => {
                let _operation = self.operation.take().unwrap();
                self.waker_registry.remove_waker(operation_id);

                match result {
                    Ok(fd) => {
                        // Accept operations return the new client fd as i32
                        // Negative values indicate errors in io_uring
                        if fd >= 0 {
                            Poll::Ready(Ok(fd))
                        } else {
                            Poll::Ready(Err(io::Error::other(
                                "Accept returned invalid file descriptor",
                            )))
                        }
                    }
                    Err(e) => Poll::Ready(Err(e)),
                }
            }
            Ok(None) => {
                self.waker_registry
                    .register_waker(operation_id, cx.waker().clone());
                Poll::Pending
            }
            Err(e) => {
                self.waker_registry.remove_waker(operation_id);
                Poll::Ready(Err(io::Error::other(format!(
                    "Error checking accept completion: {}",
                    e
                ))))
            }
        }
    }
}

impl<'ring, 'buf> Future for SendFuture<'ring, 'buf> {
    type Output = io::Result<(usize, StdPin<&'buf mut [u8]>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_io_operation!(self, cx, "SendFuture")
    }
}

impl<'ring, 'buf> Future for RecvFuture<'ring, 'buf> {
    type Output = io::Result<(usize, StdPin<&'buf mut [u8]>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_io_operation!(self, cx, "RecvFuture")
    }
}

impl<'ring> Drop for AcceptFuture<'ring> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}

impl<'ring, 'buf> Drop for SendFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}

impl<'ring, 'buf> Drop for RecvFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}
</file>

<file path="future/io_futures/vectored_io.rs">
//! Vectored I/O futures for scatter-gather operations.

use std::future::Future;
use std::io;
use std::marker::PhantomData;
use std::pin::Pin as StdPin;
use std::sync::Arc;
use std::task::{Context, Poll};

use super::common::{impl_future_drop, poll_vectored_operation};
use crate::future::waker::WakerRegistry;
use crate::operation::{Operation, Submitted};
use crate::ring::Ring;

/// Future for vectored read operations.
///
/// This future handles scatter-gather reads that operate on multiple buffers
/// simultaneously, allowing for efficient I/O when data needs to be read into
/// multiple non-contiguous memory regions. Returns the total bytes read and
/// ownership of all buffers when the operation completes.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
/// * `'buf` - Lifetime of all buffers used for the vectored read
///
/// # Returns
///
/// Returns `(usize, Vec<Pin<&'buf mut [u8]>>)` on success where:
/// - `usize` is the total number of bytes read across all buffers
/// - `Vec<Pin<&'buf mut [u8]>>` are all the buffers containing read data
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::fs::File;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let file = File::open("data.bin")?;
///
/// // Create buffers for vectored read
/// let mut header_buf = PinnedBuffer::with_capacity(512);
/// let mut data_buf = PinnedBuffer::with_capacity(4096);
/// let buffers = vec![header_buf.as_mut_slice(), data_buf.as_mut_slice()];
///
/// let read_future = ring.read_vectored(file.as_raw_fd(), buffers)?;
/// let (total_bytes, _buffers) = read_future.await?;
///
/// println!("Read {} bytes total", total_bytes);
/// # Ok(())
/// # }
/// ```
pub struct VectoredReadFuture<'ring, 'buf> {
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    // Same lifetime structure as single-buffer operations for consistency
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

/// Future for vectored write operations.
///
/// This future handles gather writes that operate on multiple buffers
/// simultaneously, allowing for efficient I/O when data from multiple
/// non-contiguous memory regions needs to be written in a single operation.
/// Returns the total bytes written and ownership of all buffers when complete.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring Ring instance
/// * `'buf` - Lifetime of all buffers used for the vectored write
///
/// # Returns
///
/// Returns `(usize, Vec<Pin<&'buf mut [u8]>>)` on success where:
/// - `usize` is the total number of bytes written from all buffers
/// - `Vec<Pin<&'buf mut [u8]>>` are all the buffers that were written from
///
/// # Examples
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Operation, PinnedBuffer};
/// # use std::fs::OpenOptions;
/// # use std::os::unix::io::AsRawFd;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let file = OpenOptions::new()
///     .write(true)
///     .create(true)
///     .open("output.bin")?;
///
/// // Create buffers for vectored write
/// let mut header_buf = PinnedBuffer::from_slice(b"HEADER: ");
/// let mut data_buf = PinnedBuffer::from_slice(b"Important data content");
/// let buffers = vec![header_buf.as_mut_slice(), data_buf.as_mut_slice()];
///
/// let write_future = ring.write_vectored(file.as_raw_fd(), buffers)?;
/// let (total_bytes, _buffers) = write_future.await?;
///
/// println!("Wrote {} bytes total", total_bytes);
/// # Ok(())
/// # }
/// ```
pub struct VectoredWriteFuture<'ring, 'buf> {
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    ring: &'ring mut Ring<'ring>,
    waker_registry: Arc<WakerRegistry>,
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

impl<'ring, 'buf> VectoredReadFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> VectoredWriteFuture<'ring, 'buf> {
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> Future for VectoredReadFuture<'ring, 'buf> {
    type Output = io::Result<(usize, Vec<StdPin<&'buf mut [u8]>>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_vectored_operation!(self, cx, "VectoredReadFuture")
    }
}

impl<'ring, 'buf> Future for VectoredWriteFuture<'ring, 'buf> {
    type Output = io::Result<(usize, Vec<StdPin<&'buf mut [u8]>>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        poll_vectored_operation!(self, cx, "VectoredWriteFuture")
    }
}

impl<'ring, 'buf> Drop for VectoredReadFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}

impl<'ring, 'buf> Drop for VectoredWriteFuture<'ring, 'buf> {
    fn drop(&mut self) {
        impl_future_drop!(self);
    }
}
</file>

<file path="future/batch_future.rs">
//! Future implementation for batch operations.

use std::collections::HashMap;
use std::future::Future;
use std::pin::Pin;
use std::sync::Arc;
use std::task::{Context, Poll};

use crate::error::Result;
use crate::future::WakerRegistry;

use crate::ring::batch::{BatchResult, OperationResult};
use crate::ring::Ring;

/// Future for batch operations that can be awaited.
///
/// This future manages the completion of multiple operations submitted as a batch,
/// handling dependencies and partial failures according to the batch configuration.
///
/// # Example
///
/// ```rust,ignore
/// # use safer_ring::{Ring, Batch, Operation, PinnedBuffer};
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
/// let mut batch = Batch::new();
/// let mut buffer = PinnedBuffer::with_capacity(1024);
///
/// batch.add_operation(Operation::read().fd(0).buffer(buffer.as_mut_slice()))?;
/// let results = ring.submit_batch(batch).await?;
///
/// println!("Batch completed with {} operations", results.results.len());
/// # Ok(())
/// # }
/// ```
pub struct BatchFuture<'ring> {
    /// Ring reference for polling completions
    ring: &'ring mut Ring<'ring>,
    /// Results collected so far
    results: Vec<Option<OperationResult>>,
    /// Dependencies between operations (dependent -> dependencies)
    dependencies: HashMap<usize, Vec<usize>>,
    /// Whether to fail fast on first error
    fail_fast: bool,
    /// Whether the batch has completed
    completed: bool,
    /// Operation IDs for tracking completions
    #[allow(dead_code)] // Used for tracking operations, may be needed for debugging
    operation_ids: Vec<Option<u64>>,
    /// Fast lookup map: operation_id -> batch_index for O(1) completion matching
    id_to_index: HashMap<u64, usize>,
}

impl<'ring> BatchFuture<'ring> {
    /// Create a new batch future.
    ///
    /// # Arguments
    ///
    /// * `operation_ids` - Vector of operation IDs that have been submitted
    /// * `dependencies` - Map of operation dependencies
    /// * `ring` - Ring reference for completion polling
    /// * `waker_registry` - Waker registry for async coordination
    /// * `fail_fast` - Whether to cancel remaining operations on first failure
    pub(crate) fn new(
        operation_ids: Vec<Option<u64>>,
        dependencies: HashMap<usize, Vec<usize>>,
        ring: &'ring mut Ring<'ring>,
        _waker_registry: Arc<WakerRegistry>,
        fail_fast: bool,
    ) -> Self {
        let operation_count = operation_ids.len();
        let results = (0..operation_count).map(|_| None).collect();

        // Build the fast lookup map for O(1) operation_id -> batch_index mapping
        let mut id_to_index = HashMap::new();
        for (index, id_opt) in operation_ids.iter().enumerate() {
            if let Some(id) = id_opt {
                id_to_index.insert(*id, index);
            }
        }

        Self {
            ring,
            results,
            dependencies,
            fail_fast,
            completed: false,
            operation_ids,
            id_to_index,
        }
    }

    /// Poll for completion of submitted operations.
    fn poll_completions(&mut self, cx: &mut Context<'_>) -> Poll<Result<()>> {
        let mut any_completed = false;
        let mut any_failed = false;
        let mut completed_operations = Vec::new();

        // Process ALL available completions in one batch for efficiency
        // This is much more efficient than checking each operation individually
        match self.ring.try_complete() {
            Ok(completions) => {
                // Process each completion and match it to our pending operations
                for completion in completions {
                    let operation_id = completion.id();

                    // Use O(1) HashMap lookup instead of O(N) linear search
                    if let Some(&index) = self.id_to_index.get(&operation_id) {
                        if self.results[index].is_some() {
                            continue; // Already completed (shouldn't happen, but defensive)
                        }

                        // Extract the result from the completion
                        let result = match completion.result() {
                            Ok(bytes) => OperationResult::Success(*bytes),
                            Err(e) => {
                                let error_msg = e.to_string();
                                OperationResult::Error(error_msg)
                            }
                        };

                        let is_error = matches!(result, OperationResult::Error(_));
                        self.results[index] = Some(result);
                        any_completed = true;
                        if is_error {
                            any_failed = true;
                        }
                        completed_operations.push(index);
                    }
                    // If we can't find the operation, it might be from a different batch
                    // or completed operation - ignore it
                }
            }
            Err(e) => {
                // Error polling completions - this might be a system error
                return Poll::Ready(Err(e));
            }
        }

        // Process completed operations to check for ready dependencies
        for completed_index in completed_operations {
            self.check_ready_operations(completed_index);

            // Cancel dependent operations if fail_fast is enabled and this operation failed
            if self.fail_fast
                && matches!(
                    self.results[completed_index],
                    Some(OperationResult::Error(_))
                )
            {
                self.cancel_dependent_operations(completed_index);
            }
        }

        // If we're in fail_fast mode and something failed, cancel everything
        if self.fail_fast && any_failed {
            self.cancel_all_remaining_operations();
            return Poll::Ready(Ok(()));
        }

        // Check if all operations have completed
        if self.all_operations_completed() {
            self.completed = true;
            return Poll::Ready(Ok(()));
        }

        // If we made progress, continue polling
        if any_completed {
            cx.waker().wake_by_ref();
            return Poll::Pending;
        }

        // For batch operations, we'll use a simple polling approach
        // In a more sophisticated implementation, we could register wakers
        // for individual operations, but for now we'll just return Pending
        Poll::Pending
    }

    /// Check if operations that were waiting for dependencies are now ready.
    fn check_ready_operations(&mut self, completed_index: usize) {
        // For now, we submit all operations immediately, so dependency handling
        // is simplified. In a more sophisticated implementation, we would
        // track which operations are waiting for dependencies and submit them
        // when their dependencies complete.

        // This is a placeholder for future dependency handling logic
        let _newly_ready: Vec<usize> = Vec::new();

        // Find operations that were waiting for this one to complete
        for (&_dependent_index, dependencies) in &self.dependencies {
            if dependencies.contains(&completed_index) {
                // Check if all dependencies for this operation are now satisfied
                let _all_deps_satisfied = dependencies.iter().all(|&dep_index| {
                    self.results[dep_index].is_some()
                        && self.results[dep_index].as_ref().unwrap().is_success()
                });

                // In the current implementation, all operations are submitted immediately
                // so we don't need to track ready operations
            }
        }
    }

    /// Cancel operations that depend on a failed operation.
    fn cancel_dependent_operations(&mut self, failed_index: usize) {
        let mut to_cancel = Vec::new();
        let mut visited = std::collections::HashSet::new();
        let mut stack = vec![failed_index];

        // Find all operations that transitively depend on the failed operation
        while let Some(current) = stack.pop() {
            if visited.contains(&current) {
                continue;
            }
            visited.insert(current);

            for (&dependent, dependencies) in &self.dependencies {
                if dependencies.contains(&current) && !visited.contains(&dependent) {
                    to_cancel.push(dependent);
                    stack.push(dependent);
                }
            }
        }

        // Cancel the dependent operations
        for &index in &to_cancel {
            if self.results[index].is_none() {
                self.results[index] = Some(OperationResult::Cancelled);
            }
        }
    }

    /// Cancel all remaining operations (used in fail_fast mode).
    fn cancel_all_remaining_operations(&mut self) {
        for result in self.results.iter_mut() {
            if result.is_none() {
                *result = Some(OperationResult::Cancelled);
            }
        }
    }

    /// Check if all operations have completed (successfully, failed, or cancelled).
    fn all_operations_completed(&self) -> bool {
        self.results.iter().all(|result| result.is_some())
    }

    /// Submit operations that are ready (have no pending dependencies).
    fn submit_ready_operations(&mut self) -> Result<()> {
        // This would be called during initial setup or when dependencies are satisfied
        // For now, we assume operations are submitted externally
        Ok(())
    }
}

impl<'ring> Future for BatchFuture<'ring> {
    type Output = Result<BatchResult>;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        if self.completed {
            // Collect all results
            let results: Vec<OperationResult> = self
                .results
                .iter()
                .map(|opt| opt.as_ref().cloned().unwrap_or(OperationResult::Cancelled))
                .collect();

            return Poll::Ready(Ok(BatchResult::new(results)));
        }

        // Submit any operations that are ready
        if let Err(e) = self.submit_ready_operations() {
            return Poll::Ready(Err(e));
        }

        // Poll for completions
        match self.poll_completions(cx) {
            Poll::Ready(Ok(())) => {
                // All operations completed, collect results
                let results: Vec<OperationResult> = self
                    .results
                    .iter()
                    .map(|opt| opt.as_ref().cloned().unwrap_or(OperationResult::Cancelled))
                    .collect();

                Poll::Ready(Ok(BatchResult::new(results)))
            }
            Poll::Ready(Err(e)) => Poll::Ready(Err(e)),
            Poll::Pending => Poll::Pending,
        }
    }
}

// Implement Drop to ensure proper cleanup
impl<'ring> Drop for BatchFuture<'ring> {
    fn drop(&mut self) {
        // Cancel any remaining operations to prevent resource leaks
        self.cancel_all_remaining_operations();
    }
}
</file>

<file path="future/mod.rs">
//! Future implementations for async/await support.
//!
//! This module provides Future implementations that integrate io_uring operations
//! with Rust's async/await ecosystem. The futures handle polling the completion
//! queue and managing wakers for efficient async operation.
//!
//! # Example
//!
//! ```rust,no_run
//! use safer_ring::{Ring, PinnedBuffer, Operation};
//! use std::pin::Pin;
//!
//! # async fn example() -> Result<(), Box<dyn std::error::Error>> {
//! let mut buffer = PinnedBuffer::with_capacity(1024);
//! let ring = Ring::new(32)?;
//!
//! // Create a read operation
//! let operation = Operation::read()
//!     .fd(0)
//!     .buffer(buffer.as_mut_slice());
//!
//! // Example usage - actual async processing would be more complex
//! # Ok(())
//! # }
//! ```

mod batch_future;
mod io_futures;
mod operation_future;
mod standalone_batch_future;
pub(crate) mod waker;

#[cfg(test)]
mod tests;

// Re-export public types
pub use batch_future::BatchFuture;
pub use io_futures::{
    AcceptFuture, ReadFuture, RecvFuture, SendFuture, VectoredReadFuture, VectoredWriteFuture,
    WriteFuture,
};
pub use operation_future::OperationFuture;
pub use standalone_batch_future::StandaloneBatchFuture;

// Re-export internal types for crate use
pub(crate) use waker::WakerRegistry;
</file>

<file path="future/operation_future.rs">
//! Generic future for any operation type.

use std::future::Future;
use std::io;
use std::marker::PhantomData;
use std::pin::Pin as StdPin;
use std::sync::Arc;
use std::task::{Context, Poll};

use crate::future::waker::WakerRegistry;
use crate::operation::BufferType;
use crate::operation::{Operation, Submitted};
use crate::ring::Ring;

/// Generic future for any operation type.
///
/// This provides a unified interface for different operation types while
/// maintaining type safety and proper buffer ownership semantics.
/// Unlike the specialized I/O futures, this returns the raw i32 result
/// from io_uring without conversion to usize.
///
/// # Type Parameters
///
/// * `'ring` - Lifetime of the io_uring instance
/// * `'buf` - Lifetime of the buffer being used for the operation
///
/// # Returns
///
/// Returns `(i32, Option<Pin<&'buf mut [u8]>>)` where:
/// - `i32` is the raw result from io_uring (can be negative for errors)
/// - `Option<Pin<&'buf mut [u8]>>` is the buffer if the operation used one
pub struct OperationFuture<'ring, 'buf> {
    /// The underlying operation (None after completion)
    /// Using Option to allow taking ownership during completion
    operation: Option<Operation<'ring, 'buf, Submitted>>,
    /// Reference to the ring for polling completions
    ring: &'ring mut Ring<'ring>,
    /// Waker registry for async notification
    waker_registry: Arc<WakerRegistry>,
    /// Phantom data for lifetime tracking
    _phantom: PhantomData<(&'ring (), &'buf ())>,
}

impl<'ring, 'buf> OperationFuture<'ring, 'buf> {
    /// Create a new operation future from a submitted operation.
    pub(crate) fn new(
        operation: Operation<'ring, 'buf, Submitted>,
        ring: &'ring mut Ring<'ring>,
        waker_registry: Arc<WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
            _phantom: PhantomData,
        }
    }
}

impl<'ring, 'buf> Future for OperationFuture<'ring, 'buf> {
    type Output = io::Result<(i32, Option<StdPin<&'buf mut [u8]>>)>;

    fn poll(mut self: StdPin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        let operation = match self.operation.as_ref() {
            Some(op) => op,
            None => {
                // Future has already been polled to completion
                // This is a programming error - futures should not be polled after Ready
                panic!("OperationFuture polled after completion");
            }
        };

        let operation_id = operation.id();

        // Check if the operation has completed
        match self.ring.try_complete_by_id(operation_id) {
            Ok(Some(result)) => {
                // Operation completed, extract the result and buffer
                let operation = self.operation.take().unwrap();
                let completed = operation.complete_with_result(result);
                let (io_result, buffer) = completed.into_result();

                // Clean up waker registration to prevent memory leaks
                self.waker_registry.remove_waker(operation_id);

                // Return the raw result and buffer without conversion
                // This allows callers to handle negative results as needed
                // Convert BufferType to Option<Pin<&mut [u8]>> for compatibility
                let buffer_option = match buffer {
                    BufferType::Pinned(buf) => Some(buf),
                    _ => None,
                };
                Poll::Ready(io_result.map(|bytes| (bytes, buffer_option)))
            }
            Ok(None) => {
                // Operation still in flight, register waker and return Pending
                // Clone the waker to avoid borrowing issues
                self.waker_registry
                    .register_waker(operation_id, cx.waker().clone());
                Poll::Pending
            }
            Err(e) => {
                // Error checking completion status
                self.waker_registry.remove_waker(operation_id);
                Poll::Ready(Err(io::Error::other(format!(
                    "Error checking operation completion: {}",
                    e
                ))))
            }
        }
    }
}

impl<'ring, 'buf> Drop for OperationFuture<'ring, 'buf> {
    fn drop(&mut self) {
        // Clean up waker registration if the future is dropped before completion
        // This prevents memory leaks in the waker registry
        if let Some(operation) = &self.operation {
            self.waker_registry.remove_waker(operation.id());
        }
    }
}
</file>

<file path="future/standalone_batch_future.rs">
//! Standalone batch future that doesn't hold Ring reference.
//!
//! This solves the lifetime constraint issue by allowing the batch future
//! to exist without borrowing the Ring mutably. Instead, polling operations
//! can take Ring references as needed.

use std::collections::HashMap;
use std::future::Future;
use std::pin::Pin;
use std::sync::Arc;
use std::task::{Context, Poll};

use crate::error::Result;
use crate::future::WakerRegistry;
use crate::ring::batch::{BatchResult, OperationResult};
use crate::ring::Ring;

/// A batch future that doesn't hold a reference to the Ring.
///
/// This future can be created and stored independently of Ring lifetime,
/// resolving the API ergonomics issues with the original BatchFuture.
pub struct StandaloneBatchFuture {
    /// Operation IDs for tracking completions
    operation_ids: Vec<Option<u64>>,
    /// Results collected so far
    results: Vec<Option<OperationResult>>,
    /// Dependencies between operations (dependent -> dependencies)
    dependencies: HashMap<usize, Vec<usize>>,
    /// Whether to fail fast on first error
    fail_fast: bool,
    /// Whether the batch has completed
    completed: bool,
    /// Fast lookup map: operation_id -> batch_index for O(1) completion matching
    id_to_index: HashMap<u64, usize>,
    /// Waker registry for async notification
    waker_registry: Arc<WakerRegistry>,
}

impl StandaloneBatchFuture {
    /// Create a new standalone batch future.
    pub(crate) fn new(
        operation_ids: Vec<Option<u64>>,
        dependencies: HashMap<usize, Vec<usize>>,
        waker_registry: Arc<WakerRegistry>,
        fail_fast: bool,
    ) -> Self {
        let operation_count = operation_ids.len();
        let results = (0..operation_count).map(|_| None).collect();

        // Build the fast lookup map for O(1) operation_id -> batch_index mapping
        let mut id_to_index = HashMap::new();
        for (index, id_opt) in operation_ids.iter().enumerate() {
            if let Some(id) = id_opt {
                id_to_index.insert(*id, index);
            }
        }

        Self {
            operation_ids,
            results,
            dependencies,
            fail_fast,
            completed: false,
            id_to_index,
            waker_registry,
        }
    }

    /// Poll the batch future with an externally provided Ring reference.
    ///
    /// This method allows the caller to provide Ring access only when polling,
    /// avoiding the lifetime constraint issues of holding a Ring reference.
    /// This is the primary way to poll a `StandaloneBatchFuture` since the
    /// standard `Future::poll` implementation cannot work without Ring access.
    ///
    /// # Arguments
    ///
    /// * `ring` - Mutable reference to the Ring for polling completions
    /// * `cx` - Task context for waker registration and async coordination
    ///
    /// # Returns
    ///
    /// Returns `Poll::Ready(Ok(BatchResult))` when all operations complete,
    /// `Poll::Pending` when operations are still in flight, or
    /// `Poll::Ready(Err(error))` if polling encounters an error.
    ///
    /// # Examples
    ///
    /// ```rust,ignore
    /// # use safer_ring::{Ring, Batch, Operation, PinnedBuffer};
    /// # use std::task::{Context, Poll, Waker};
    /// # use std::future::Future;
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut batch = Batch::new();
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// batch.add_operation(Operation::read().fd(0).buffer(buffer.as_mut_slice()))?;
    /// let mut batch_future = ring.submit_batch_standalone(batch)?;
    ///
    /// // Poll the batch future manually with Ring access
    /// let waker = Waker::noop();
    /// let mut cx = Context::from_waker(&waker);
    /// match batch_future.poll_with_ring(&mut ring, &mut cx) {
    ///     Poll::Ready(Ok(results)) => {
    ///         println!("Batch completed with {} results", results.results.len());
    ///     }
    ///     Poll::Pending => println!("Batch still in progress"),
    ///     Poll::Ready(Err(e)) => println!("Batch failed: {}", e),
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub fn poll_with_ring(
        &mut self,
        ring: &mut Ring<'_>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<BatchResult>> {
        if self.completed {
            // Collect all results
            let results: Vec<OperationResult> = self
                .results
                .iter()
                .map(|opt| opt.as_ref().cloned().unwrap_or(OperationResult::Cancelled))
                .collect();

            return Poll::Ready(Ok(BatchResult::new(results)));
        }

        // Poll for completions using the provided Ring
        match self.poll_completions_with_ring(ring, cx) {
            Poll::Ready(Ok(())) => {
                // All operations completed, collect results
                let results: Vec<OperationResult> = self
                    .results
                    .iter()
                    .map(|opt| opt.as_ref().cloned().unwrap_or(OperationResult::Cancelled))
                    .collect();

                Poll::Ready(Ok(BatchResult::new(results)))
            }
            Poll::Ready(Err(e)) => Poll::Ready(Err(e)),
            Poll::Pending => Poll::Pending,
        }
    }

    /// Poll for completion of submitted operations using the provided Ring.
    fn poll_completions_with_ring(
        &mut self,
        ring: &mut Ring<'_>,
        cx: &mut Context<'_>,
    ) -> Poll<Result<()>> {
        let mut any_completed = false;
        let mut any_failed = false;
        let mut completed_operations = Vec::new();

        // Process ALL available completions in one batch for efficiency
        match ring.try_complete() {
            Ok(completions) => {
                // Process each completion and match it to our pending operations
                for completion in completions {
                    let operation_id = completion.id();

                    // Use O(1) HashMap lookup instead of O(N) linear search
                    if let Some(&index) = self.id_to_index.get(&operation_id) {
                        if self.results[index].is_some() {
                            continue; // Already completed (shouldn't happen, but defensive)
                        }

                        // Extract the result from the completion
                        let result = match completion.result() {
                            Ok(bytes) => OperationResult::Success(*bytes),
                            Err(e) => {
                                let error_msg = e.to_string();
                                OperationResult::Error(error_msg)
                            }
                        };

                        let is_error = matches!(result, OperationResult::Error(_));
                        self.results[index] = Some(result);
                        any_completed = true;
                        if is_error {
                            any_failed = true;
                        }
                        completed_operations.push(index);
                    }
                    // If we can't find the operation, it might be from a different batch
                    // or completed operation - ignore it
                }
            }
            Err(e) => {
                // Error polling completions - this might be a system error
                return Poll::Ready(Err(e));
            }
        }

        // Process completed operations to check for ready dependencies
        for completed_index in completed_operations {
            self.check_ready_operations(completed_index);

            // Cancel dependent operations if fail_fast is enabled and this operation failed
            if self.fail_fast
                && matches!(
                    self.results[completed_index],
                    Some(OperationResult::Error(_))
                )
            {
                self.cancel_dependent_operations(completed_index);
            }
        }

        // If we're in fail_fast mode and something failed, cancel everything
        if self.fail_fast && any_failed {
            self.cancel_all_remaining_operations();
            return Poll::Ready(Ok(()));
        }

        // Check if all operations have completed
        if self.all_operations_completed() {
            self.completed = true;
            return Poll::Ready(Ok(()));
        }

        // If we made progress, continue polling
        if any_completed {
            cx.waker().wake_by_ref();
            return Poll::Pending;
        }

        // For batch operations, we'll use a simple polling approach
        Poll::Pending
    }

    /// Check if operations that were waiting for dependencies are now ready.
    fn check_ready_operations(&mut self, completed_index: usize) {
        // Placeholder for future dependency handling logic
        let _newly_ready: Vec<usize> = Vec::new();

        // Find operations that were waiting for this one to complete
        for (&_dependent_index, dependencies) in &self.dependencies {
            if dependencies.contains(&completed_index) {
                // Check if all dependencies for this operation are now satisfied
                let _all_deps_satisfied = dependencies.iter().all(|&dep_index| {
                    self.results[dep_index].is_some()
                        && self.results[dep_index].as_ref().unwrap().is_success()
                });

                // In the current implementation, all operations are submitted immediately
                // so we don't need to track ready operations
            }
        }
    }

    /// Cancel operations that depend on a failed operation.
    fn cancel_dependent_operations(&mut self, failed_index: usize) {
        let mut to_cancel = Vec::new();
        let mut visited = std::collections::HashSet::new();
        let mut stack = vec![failed_index];

        // Find all operations that transitively depend on the failed operation
        while let Some(current) = stack.pop() {
            if visited.contains(&current) {
                continue;
            }
            visited.insert(current);

            for (&dependent, dependencies) in &self.dependencies {
                if dependencies.contains(&current) && !visited.contains(&dependent) {
                    to_cancel.push(dependent);
                    stack.push(dependent);
                }
            }
        }

        // Cancel the dependent operations
        for &index in &to_cancel {
            if self.results[index].is_none() {
                self.results[index] = Some(OperationResult::Cancelled);
            }
        }
    }

    /// Cancel all remaining operations (used in fail_fast mode).
    fn cancel_all_remaining_operations(&mut self) {
        for result in self.results.iter_mut() {
            if result.is_none() {
                *result = Some(OperationResult::Cancelled);
            }
        }
    }

    /// Check if all operations have completed (successfully, failed, or cancelled).
    fn all_operations_completed(&self) -> bool {
        self.results.iter().all(|result| result.is_some())
    }
}

impl Future for StandaloneBatchFuture {
    type Output = Result<BatchResult>;

    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        // This implementation cannot work because we don't have access to a Ring
        // The caller must use poll_with_ring instead
        let _ = cx;
        Poll::Pending
    }
}

// Implement Drop to ensure proper cleanup
impl Drop for StandaloneBatchFuture {
    fn drop(&mut self) {
        // Cancel any remaining operations to prevent resource leaks
        self.cancel_all_remaining_operations();

        // Clean up wakers from the registry
        for id in self.operation_ids.iter().flatten() {
            self.waker_registry.remove_waker(*id);
        }
    }
}
</file>

<file path="future/tests.rs">
//! Tests for future implementations.

use crate::future::waker::WakerRegistry;
use std::sync::{Arc, Mutex};
use std::task::{RawWaker, RawWakerVTable, Waker};

// Helper to create a test waker that tracks wake calls
fn create_test_waker() -> (Waker, Arc<Mutex<bool>>) {
    let woken = Arc::new(Mutex::new(false));
    let woken_clone = woken.clone();

    let raw_waker = RawWaker::new(
        Arc::into_raw(woken_clone) as *const (),
        &RawWakerVTable::new(
            |data| {
                let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                let woken_clone = woken.clone();
                std::mem::forget(woken);
                RawWaker::new(
                    Arc::into_raw(woken_clone) as *const (),
                    &RawWakerVTable::new(
                        |_| panic!("clone should not be called"),
                        |data| {
                            let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                            *woken.lock().unwrap() = true;
                        },
                        |data| {
                            let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                            *woken.lock().unwrap() = true;
                        },
                        |data| {
                            let _ = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                        },
                    ),
                )
            },
            |data| {
                let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                *woken.lock().unwrap() = true;
            },
            |data| {
                let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                *woken.lock().unwrap() = true;
            },
            |data| {
                let _ = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
            },
        ),
    );

    (unsafe { Waker::from_raw(raw_waker) }, woken)
}

#[test]
fn waker_registry_basic_functionality() {
    let registry = WakerRegistry::new();
    let (waker, woken) = create_test_waker();

    // Register waker
    registry.register_waker(1, waker);
    assert_eq!(registry.waker_count(), 1);

    // Wake operation
    let was_woken = registry.wake_operation(1);
    assert!(was_woken);
    assert_eq!(registry.waker_count(), 0);
    assert!(*woken.lock().unwrap());
}

#[test]
fn waker_registry_cleanup() {
    let registry = WakerRegistry::new();
    let (waker, woken) = create_test_waker();

    // Register and remove without waking
    registry.register_waker(1, waker);
    let was_removed = registry.remove_waker(1);
    assert!(was_removed);
    assert_eq!(registry.waker_count(), 0);
    assert!(!*woken.lock().unwrap());
}

// Note: Full integration tests for the futures would require a working Ring implementation
// and actual io_uring operations, which are tested in the integration test suite.
// These unit tests focus on the waker registry functionality that can be tested in isolation.
</file>

<file path="future/waker.rs">
//! Waker registry for managing async operation notifications.

use std::sync::Mutex;
use std::collections::HashMap;
use std::task::Waker;

/// Shared waker registry for managing async operations.
///
/// This registry allows the ring to wake up futures when their operations
/// complete. Uses `RefCell` for interior mutability since we're in a
/// single-threaded async context with io_uring.
#[derive(Debug, Default)]
pub(crate) struct WakerRegistry {
    /// Map from operation ID to waker
    /// Using Mutex for interior mutability to support Arc sharing
    wakers: Mutex<HashMap<u64, Waker>>,
}

impl WakerRegistry {
    /// Create a new waker registry.
    #[allow(dead_code)] // Used by ring initialization
    pub(crate) fn new() -> Self {
        Self {
            wakers: Mutex::new(HashMap::new()),
        }
    }

    /// Register a waker for an operation ID.
    ///
    /// If a waker already exists for this operation, it will be replaced.
    /// This is safe because futures should only be polled from one task.
    pub(crate) fn register_waker(&self, operation_id: u64, waker: Waker) {
        self.wakers.lock().unwrap().insert(operation_id, waker);
    }

    /// Wake a specific operation and remove its waker.
    ///
    /// Returns `true` if a waker was found and woken, `false` otherwise.
    #[allow(dead_code)] // Used by completion processor
    pub(crate) fn wake_operation(&self, operation_id: u64) -> bool {
        if let Some(waker) = self.wakers.lock().unwrap().remove(&operation_id) {
            waker.wake();
            true
        } else {
            false
        }
    }

    /// Remove a waker without waking it (for cleanup).
    ///
    /// Returns `true` if a waker was removed, `false` if none existed.
    pub(crate) fn remove_waker(&self, operation_id: u64) -> bool {
        self.wakers.lock().unwrap().remove(&operation_id).is_some()
    }

    /// Get the number of registered wakers.
    ///
    /// Useful for debugging and monitoring async operation load.
    #[cfg(test)]
    pub(crate) fn waker_count(&self) -> usize {
        self.wakers.lock().unwrap().len()
    }

    /// Check if any wakers are registered.
    ///
    /// More efficient than checking `waker_count() == 0`.
    #[cfg(test)]
    pub(crate) fn has_wakers(&self) -> bool {
        !self.wakers.lock().unwrap().is_empty()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::{Arc, Mutex};
    use std::task::{RawWaker, RawWakerVTable, Waker};

    // Helper to create a test waker that tracks wake calls
    fn create_test_waker() -> (Waker, Arc<Mutex<bool>>) {
        let woken = Arc::new(Mutex::new(false));
        let woken_clone = woken.clone();

        let raw_waker = RawWaker::new(
            Arc::into_raw(woken_clone) as *const (),
            &RawWakerVTable::new(
                |data| {
                    let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                    let woken_clone = woken.clone();
                    std::mem::forget(woken);
                    RawWaker::new(
                        Arc::into_raw(woken_clone) as *const (),
                        &RawWakerVTable::new(
                            |_| panic!("clone should not be called"),
                            |data| {
                                let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                                *woken.lock().unwrap() = true;
                            },
                            |data| {
                                let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                                *woken.lock().unwrap() = true;
                            },
                            |data| {
                                let _ = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                            },
                        ),
                    )
                },
                |data| {
                    let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                    *woken.lock().unwrap() = true;
                },
                |data| {
                    let woken = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                    *woken.lock().unwrap() = true;
                },
                |data| {
                    let _ = unsafe { Arc::from_raw(data as *const Mutex<bool>) };
                },
            ),
        );

        (unsafe { Waker::from_raw(raw_waker) }, woken)
    }

    #[test]
    fn new_registry_is_empty() {
        let registry = WakerRegistry::new();
        assert_eq!(registry.waker_count(), 0);
        assert!(!registry.has_wakers());
    }

    #[test]
    fn register_and_wake_waker() {
        let registry = WakerRegistry::new();
        let (waker, woken) = create_test_waker();

        registry.register_waker(1, waker);
        assert_eq!(registry.waker_count(), 1);
        assert!(registry.has_wakers());

        let was_woken = registry.wake_operation(1);
        assert!(was_woken);
        assert_eq!(registry.waker_count(), 0);
        assert!(!registry.has_wakers());

        // Check that the waker was actually called
        assert!(*woken.lock().unwrap());
    }

    #[test]
    fn wake_nonexistent_operation() {
        let registry = WakerRegistry::new();
        let was_woken = registry.wake_operation(999);
        assert!(!was_woken);
    }

    #[test]
    fn remove_waker_without_waking() {
        let registry = WakerRegistry::new();
        let (waker, woken) = create_test_waker();

        registry.register_waker(1, waker);
        assert_eq!(registry.waker_count(), 1);

        let was_removed = registry.remove_waker(1);
        assert!(was_removed);
        assert_eq!(registry.waker_count(), 0);

        // Waker should not have been called
        assert!(!*woken.lock().unwrap());
    }

    #[test]
    fn remove_nonexistent_waker() {
        let registry = WakerRegistry::new();
        let was_removed = registry.remove_waker(999);
        assert!(!was_removed);
    }

    #[test]
    fn replace_existing_waker() {
        let registry = WakerRegistry::new();
        let (waker1, woken1) = create_test_waker();
        let (waker2, woken2) = create_test_waker();

        registry.register_waker(1, waker1);
        registry.register_waker(1, waker2); // Replace the first waker

        assert_eq!(registry.waker_count(), 1);

        registry.wake_operation(1);

        // Only the second waker should have been called
        assert!(!*woken1.lock().unwrap());
        assert!(*woken2.lock().unwrap());
    }
}
</file>

<file path="operation/building.rs">
//! Building state implementation and operation constructors.
//!
//! This module contains all the functionality for operations in the Building state,
//! including constructors and configuration methods.

use std::marker::PhantomData;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use super::core::{BufferType, FdType, Operation};
use crate::operation::{Building, OperationType, Submitted};
use crate::registry::{RegisteredBuffer, RegisteredFd};

impl<'ring, 'buf> Default for Operation<'ring, 'buf, Building> {
    fn default() -> Self {
        Self::new()
    }
}

impl<'ring, 'buf> Operation<'ring, 'buf, Building> {
    /// Create a new operation in the building state.
    ///
    /// The operation starts with default values and must be configured
    /// before it can be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// let op = Operation::new()
    ///     .fd(0)
    ///     .offset(1024);
    /// ```
    pub fn new() -> Self {
        Self::with_type(OperationType::Read) // Default to read for backwards compatibility
    }

    /// Create a new read operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer = vec![0u8; 1024];
    /// let op = Operation::read()
    ///     .fd(0)
    ///     .buffer(Pin::new(buffer.as_mut_slice()));
    /// ```
    #[inline]
    pub fn read() -> Self {
        Self::with_type(OperationType::Read)
    }

    /// Create a new vectored read operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer1 = vec![0u8; 512];
    /// let mut buffer2 = vec![0u8; 512];
    /// let buffers = vec![
    ///     Pin::new(buffer1.as_mut_slice()),
    ///     Pin::new(buffer2.as_mut_slice()),
    /// ];
    /// let op = Operation::read_vectored()
    ///     .fd(0)
    ///     .buffers(buffers);
    /// ```
    #[inline]
    pub fn read_vectored() -> Self {
        Self::with_type(OperationType::ReadVectored)
    }

    /// Create a new write operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer = b"Hello, world!".to_vec();
    /// let op = Operation::write()
    ///     .fd(1)
    ///     .buffer(Pin::new(buffer.as_mut_slice()));
    /// ```
    #[inline]
    pub fn write() -> Self {
        Self::with_type(OperationType::Write)
    }

    /// Create a new vectored write operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer1 = b"Hello, ".to_vec();
    /// let mut buffer2 = b"world!".to_vec();
    /// let buffers = vec![
    ///     Pin::new(buffer1.as_mut_slice()),
    ///     Pin::new(buffer2.as_mut_slice()),
    /// ];
    /// let op = Operation::write_vectored()
    ///     .fd(1)
    ///     .buffers(buffers);
    /// ```
    #[inline]
    pub fn write_vectored() -> Self {
        Self::with_type(OperationType::WriteVectored)
    }

    /// Create a new accept operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// let op = Operation::accept().fd(3); // listening socket fd
    /// ```
    #[inline]
    pub fn accept() -> Self {
        Self::with_type(OperationType::Accept)
    }

    /// Create a new send operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer = b"Hello, client!".to_vec();
    /// let op = Operation::send()
    ///     .fd(4)
    ///     .buffer(Pin::new(buffer.as_mut_slice()));
    /// ```
    #[inline]
    pub fn send() -> Self {
        Self::with_type(OperationType::Send)
    }

    /// Create a new receive operation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer = vec![0u8; 1024];
    /// let op = Operation::recv()
    ///     .fd(4)
    ///     .buffer(Pin::new(buffer.as_mut_slice()));
    /// ```
    #[inline]
    pub fn recv() -> Self {
        Self::with_type(OperationType::Recv)
    }

    /// Create a new operation with the specified type.
    ///
    /// This is a helper method to reduce code duplication in the constructor methods.
    #[inline]
    fn with_type(op_type: OperationType) -> Self {
        Self {
            ring: PhantomData,
            buffer: BufferType::None,
            fd: FdType::Raw(-1), // Invalid fd that must be set before submission
            offset: 0,
            op_type,
            state: Building,
        }
    }

    /// Set the file descriptor for this operation.
    ///
    /// This is required for all operations and must be a valid file descriptor.
    ///
    /// # Arguments
    ///
    /// * `fd` - A valid file descriptor (>= 0)
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// let op = Operation::read().fd(0); // stdin
    /// ```
    #[inline]
    pub fn fd(mut self, fd: RawFd) -> Self {
        self.fd = FdType::Raw(fd);
        self
    }

    /// Set a registered file descriptor for this operation.
    ///
    /// Using registered file descriptors can improve performance for frequently
    /// used file descriptors by avoiding kernel lookups.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - A registered file descriptor
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{operation::Operation, Registry};
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let registered_fd = registry.register_fd(0)?;
    /// let op = Operation::read().registered_fd(registered_fd);
    /// # Ok(())
    /// # }
    /// ```
    #[inline]
    pub fn registered_fd(mut self, registered_fd: RegisteredFd) -> Self {
        self.fd = FdType::Registered(registered_fd);
        self
    }

    /// Set a fixed file for this operation.
    ///
    /// Fixed files provide the best performance for frequently used files
    /// by avoiding both file descriptor lookups and translation overhead.
    /// The file must be pre-registered with the registry.
    ///
    /// # Arguments
    ///
    /// * `fixed_file` - A fixed file from the registry
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{operation::Operation, Registry};
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let fixed_files = registry.register_fixed_files(vec![0, 1])?;
    /// let op = Operation::read().fixed_file(fixed_files[0].clone());
    /// # Ok(())
    /// # }
    /// ```
    #[inline]
    pub fn fixed_file(mut self, fixed_file: crate::registry::FixedFile) -> Self {
        self.fd = FdType::Fixed(fixed_file);
        self
    }

    /// Set the buffer for this operation.
    ///
    /// The buffer lifetime must be at least as long as the ring lifetime
    /// to ensure memory safety during the operation. The buffer must remain
    /// pinned in memory until the operation completes.
    ///
    /// # Arguments
    ///
    /// * `buffer` - A pinned mutable slice that will be used for I/O
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut data = vec![0u8; 4096];
    /// let op = Operation::read()
    ///     .fd(0)
    ///     .buffer(Pin::new(data.as_mut_slice()));
    /// ```
    #[inline]
    pub fn buffer(mut self, buffer: Pin<&'buf mut [u8]>) -> Self {
        self.buffer = BufferType::Pinned(buffer);
        self
    }

    /// Set a registered buffer for this operation.
    ///
    /// Using registered buffers can improve performance by avoiding kernel
    /// buffer validation and setup overhead.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - A registered buffer
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{operation::Operation, Registry};
    /// # use std::pin::Pin;
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let buffer = Pin::new(Box::new([0u8; 1024]));
    /// let registered_buffer = registry.register_buffer(buffer)?;
    /// let op = Operation::read()
    ///     .fd(0)
    ///     .registered_buffer(registered_buffer);
    /// # Ok(())
    /// # }
    /// ```
    #[inline]
    pub fn registered_buffer(mut self, registered_buffer: RegisteredBuffer) -> Self {
        self.buffer = BufferType::Registered(registered_buffer);
        self
    }

    /// Set multiple buffers for vectored I/O operations.
    ///
    /// This enables scatter-gather I/O where data can be read into or written
    /// from multiple non-contiguous buffers in a single operation.
    ///
    /// # Arguments
    ///
    /// * `buffers` - A vector of pinned mutable slices
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # use std::pin::Pin;
    /// let mut buffer1 = vec![0u8; 512];
    /// let mut buffer2 = vec![0u8; 512];
    /// let buffers = vec![
    ///     Pin::new(buffer1.as_mut_slice()),
    ///     Pin::new(buffer2.as_mut_slice()),
    /// ];
    /// let op = Operation::read_vectored()
    ///     .fd(0)
    ///     .buffers(buffers);
    /// ```
    #[inline]
    pub fn buffers(mut self, buffers: Vec<Pin<&'buf mut [u8]>>) -> Self {
        self.buffer = BufferType::Vectored(buffers);
        self
    }

    /// Set the offset for this operation.
    ///
    /// This is used for file operations to specify the position in the file.
    /// For socket operations, this parameter is typically ignored by the kernel.
    ///
    /// # Arguments
    ///
    /// * `offset` - Byte offset in the file (0-based)
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// let op = Operation::read()
    ///     .fd(3)
    ///     .offset(1024); // Read starting at byte 1024
    /// ```
    #[inline]
    pub fn offset(mut self, offset: u64) -> Self {
        self.offset = offset;
        self
    }

    /// Get the current offset.
    ///
    /// Returns the byte offset for file operations, or 0 if not set.
    #[inline]
    pub fn get_offset(&self) -> u64 {
        self.offset
    }

    /// Validate that the operation is ready for submission.
    ///
    /// This checks that all required fields are set for the operation type.
    /// Using the type system's knowledge about operation requirements for
    /// more efficient validation.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - File descriptor is not set (< 0)
    /// - Buffer is required but not set
    /// - Vectored operation has empty buffer list
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// let op = Operation::read().fd(0);
    /// assert!(op.validate().is_err()); // Missing buffer
    /// ```
    pub fn validate(&self) -> Result<(), &'static str> {
        // Check file descriptor
        match &self.fd {
            FdType::Raw(fd) if *fd < 0 => return Err("File descriptor must be set"),
            _ => {}
        }

        // Use the type system's knowledge about buffer requirements
        if self.op_type.requires_buffer() {
            match &self.buffer {
                BufferType::None => return Err("Buffer must be set for I/O operations"),
                BufferType::Vectored(buffers) if buffers.is_empty() => {
                    return Err("Vectored operations require at least one buffer")
                }
                _ => {}
            }
        }

        // Validate operation type matches buffer type
        if self.op_type.is_vectored() && !matches!(self.buffer, BufferType::Vectored(_)) {
            return Err("Vectored operation types require vectored buffers");
        }

        if !self.op_type.is_vectored() && matches!(self.buffer, BufferType::Vectored(_)) {
            return Err("Non-vectored operation types cannot use vectored buffers");
        }

        Ok(())
    }

    /// Convert this building operation to a submitted operation.
    ///
    /// This is typically called by the Ring when submitting the operation.
    /// It validates the operation and transitions to the Submitted state.
    ///
    /// # Arguments
    ///
    /// * `id` - Unique operation ID assigned by the ring
    ///
    /// # Errors
    ///
    /// Returns an error if the operation is not properly configured.
    #[allow(dead_code)]
    pub(crate) fn submit_with_id(
        self,
        id: u64,
    ) -> Result<Operation<'ring, 'buf, Submitted>, &'static str> {
        self.validate()?;

        // Zero-cost state transition - just change the type parameter
        Ok(Operation {
            ring: self.ring,
            buffer: self.buffer,
            fd: self.fd,
            offset: self.offset,
            op_type: self.op_type,
            state: Submitted { id },
        })
    }
}
</file>

<file path="operation/completed.rs">
//! Completed state implementation for finished operations.
//!
//! This module contains functionality for operations that have completed
//! and contain their results.

use std::os::unix::io::RawFd;
use std::pin::Pin;

use super::core::{BufferType, FdType, Operation};
use crate::operation::{Completed, OperationType};

impl<'ring, 'buf, T> Operation<'ring, 'buf, Completed<T>> {
    /// Extract the result from the completed operation.
    ///
    /// This consumes the operation and returns both the result and the buffer
    /// ownership, ensuring no resource leaks. This is the primary way to
    /// retrieve results from completed operations.
    ///
    /// # Returns
    ///
    /// A tuple containing:
    /// - The operation result
    /// - The buffer (if one was used), returned to the caller for reuse
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::operation::Operation;
    /// # let completed_op: Operation<'_, '_, safer_ring::operation::Completed<i32>> = todo!();
    /// let (bytes_read, buffer) = completed_op.into_result();
    /// println!("Read {} bytes", bytes_read);
    /// // Buffer can now be reused for another operation
    /// ```
    pub fn into_result(self) -> (T, BufferType<'buf>) {
        (self.state.result, self.buffer)
    }

    /// Extract the result and return a pinned buffer if available.
    ///
    /// This is a convenience method for operations that use regular pinned buffers.
    /// For other buffer types, use `into_result()` instead.
    pub fn into_result_with_buffer(self) -> (T, Option<Pin<&'buf mut [u8]>>) {
        let (result, buffer_type) = self.into_result();
        let buffer = match buffer_type {
            BufferType::Pinned(buf) => Some(buf),
            _ => None,
        };
        (result, buffer)
    }

    /// Extract the result and return vectored buffers if available.
    ///
    /// This is a convenience method for vectored operations.
    pub fn into_result_with_vectored_buffers(self) -> (T, Option<Vec<Pin<&'buf mut [u8]>>>) {
        let (result, buffer_type) = self.into_result();
        let buffers = match buffer_type {
            BufferType::Vectored(bufs) => Some(bufs),
            _ => None,
        };
        (result, buffers)
    }

    /// Get a reference to the result without consuming the operation.
    ///
    /// This allows inspecting the result while keeping the operation intact.
    #[inline]
    pub fn result(&self) -> &T {
        &self.state.result
    }

    /// Get the file descriptor for this operation.
    #[inline]
    pub fn fd(&self) -> RawFd {
        match &self.fd {
            FdType::Raw(fd) => *fd,
            FdType::Registered(reg_fd) => reg_fd.raw_fd(),
            FdType::Fixed(fixed_file) => fixed_file.raw_fd(),
        }
    }

    /// Get the offset for this operation.
    #[inline]
    pub fn offset(&self) -> u64 {
        self.offset
    }

    /// Get the operation type.
    #[inline]
    pub fn op_type(&self) -> OperationType {
        self.op_type
    }
}
</file>

<file path="operation/core.rs">
//! Core Operation struct definition and common functionality.
//!
//! This module contains the main Operation struct and methods that are
//! available across all states.

use std::marker::PhantomData;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::operation::{OperationState, OperationType};
use crate::registry::{FixedFile, RegisteredBuffer, RegisteredFd};

/// Buffer type for operations.
///
/// This enum represents the different types of buffers that can be used
/// with operations, supporting both regular pinned buffers and registered buffers.
#[derive(Debug)]
pub enum BufferType<'buf> {
    /// No buffer (for operations like accept)
    None,
    /// Regular pinned buffer
    Pinned(Pin<&'buf mut [u8]>),
    /// Registered buffer with the registry
    Registered(RegisteredBuffer),
    /// Multiple pinned buffers for vectored I/O
    Vectored(Vec<Pin<&'buf mut [u8]>>),
}

/// File descriptor type for operations.
///
/// This enum represents the different types of file descriptors that can be used
/// with operations, supporting both regular file descriptors and registered ones.
#[derive(Debug)]
pub enum FdType {
    /// Regular file descriptor
    Raw(RawFd),
    /// Registered file descriptor
    Registered(RegisteredFd),
    /// Fixed file (accessed by index)
    Fixed(FixedFile),
}

/// Type-safe operation with compile-time state tracking.
///
/// The operation struct uses phantom types to track its current state and enforce
/// valid state transitions at compile time. The lifetime parameters ensure that:
/// - `'ring`: The operation cannot outlive the ring that will execute it
/// - `'buf`: The buffer cannot be dropped while the operation is in flight
///
/// # Type Parameters
///
/// - `'ring`: Lifetime of the ring that will execute this operation
/// - `'buf`: Lifetime of the buffer used by this operation
/// - `S`: Current state of the operation ([`crate::operation::Building`], [`crate::operation::Submitted`], or [`crate::operation::Completed<T>`])
#[derive(Debug)]
pub struct Operation<'ring, 'buf, S> {
    // PhantomData is zero-sized, so this doesn't add runtime overhead
    pub(crate) ring: PhantomData<&'ring ()>,
    // Buffer type supports different buffer configurations
    pub(crate) buffer: BufferType<'buf>,
    // File descriptor type supports both raw and registered fds
    pub(crate) fd: FdType,
    // u64 offset supports large files (>4GB) on all platforms
    pub(crate) offset: u64,
    pub(crate) op_type: OperationType,
    pub(crate) state: S,
}

impl<'ring, 'buf, S: OperationState> Operation<'ring, 'buf, S> {
    /// Get the operation type.
    ///
    /// Returns the type of I/O operation this will perform.
    #[inline]
    pub fn get_type(&self) -> OperationType {
        self.op_type
    }

    /// Check if the operation has a buffer set.
    ///
    /// Returns `true` if a buffer has been configured for this operation.
    #[inline]
    pub fn has_buffer(&self) -> bool {
        !matches!(self.buffer, BufferType::None)
    }

    /// Get the file descriptor for this operation.
    ///
    /// Returns the raw file descriptor, resolving registered fds if necessary.
    #[inline]
    pub fn get_fd(&self) -> RawFd {
        match &self.fd {
            FdType::Raw(fd) => *fd,
            FdType::Registered(reg_fd) => reg_fd.raw_fd(),
            FdType::Fixed(fixed_file) => fixed_file.raw_fd(),
        }
    }
}
</file>

<file path="operation/mod.rs">
//! Type-safe operation state management.
//!
//! This module provides a type-safe state machine for io_uring operations that prevents
//! common usage errors at compile time. Operations progress through well-defined states:
//!
//! - [`Building`]: Initial state where the operation can be configured
//! - [`Submitted`]: Operation has been submitted to the kernel and is in flight
//! - [`Completed<T>`]: Operation has finished and contains the result
//!
//! State transitions are enforced at compile time, making it impossible to:
//! - Submit an operation twice
//! - Poll an operation that hasn't been submitted
//! - Extract results from an incomplete operation
//!
//! # Example
//!
//! ```rust,no_run
//! # use safer_ring::operation::{Operation, OperationType};
//! # use std::pin::Pin;
//! let mut buffer = vec![0u8; 1024];
//! let pinned = Pin::new(buffer.as_mut_slice());
//!
//! let operation = Operation::read()
//!     .fd(0)
//!     .buffer(pinned)
//!     .offset(0);
//! ```

// Public modules
pub mod types;

// Internal modules
mod building;
mod completed;
mod core;
mod states;
mod submitted;

// Internal operation tracking module
pub(crate) mod tracker;

// Test module
#[cfg(test)]
mod tests;

// Re-exports for public API
pub use core::{BufferType, FdType, Operation};
pub use states::{Building, Completed, OperationState, Submitted};
pub use types::OperationType;
</file>

<file path="operation/states.rs">
//! Operation state types and state machine definitions.
//!
//! This module defines the state types used in the Operation state machine
//! and the sealed OperationState trait that ensures type safety.

/// Marker trait for operation states.
///
/// This trait is sealed to prevent external implementations and ensure
/// that only valid states can be used with operations.
pub trait OperationState: private::Sealed {}

/// Operation is being built and can be configured.
///
/// In this state, the operation can have its parameters modified but cannot
/// be submitted to the kernel. This prevents incomplete operations from being
/// submitted accidentally.
#[derive(Debug, Clone, Copy)]
pub struct Building;

/// Operation has been submitted and is in flight.
///
/// In this state, the operation cannot be modified but can be polled for
/// completion. The operation ID is used to track the operation in the kernel.
#[derive(Debug, Clone, Copy)]
pub struct Submitted {
    /// Operation ID for tracking in the completion queue
    /// This ID is assigned by the ring when the operation is submitted
    pub(crate) id: u64,
}

/// Operation has completed with a result.
///
/// In this state, the operation result can be extracted along with the
/// buffer ownership. This is the terminal state for operations.
#[derive(Debug)]
pub struct Completed<T> {
    /// The result of the operation
    pub(crate) result: T,
}

// Implement the sealed trait for all valid states
impl OperationState for Building {}
impl OperationState for Submitted {}
impl<T> OperationState for Completed<T> {}

/// Private module to seal the OperationState trait.
///
/// This prevents external crates from implementing OperationState,
/// ensuring type safety of the state machine.
mod private {
    pub trait Sealed {}
    impl Sealed for super::Building {}
    impl Sealed for super::Submitted {}
    impl<T> Sealed for super::Completed<T> {}
}
</file>

<file path="operation/submitted.rs">
//! Submitted state implementation for in-flight operations.
//!
//! This module contains functionality for operations that have been submitted
//! to the kernel and are currently in flight.

use std::os::unix::io::RawFd;

use super::core::{BufferType, FdType, Operation};
use crate::operation::{Completed, OperationType, Submitted};

impl<'ring, 'buf> Operation<'ring, 'buf, Submitted> {
    /// Get the operation ID.
    ///
    /// This ID is used to track the operation in the completion queue
    /// and match completions to their corresponding operations.
    #[inline]
    pub fn id(&self) -> u64 {
        self.state.id
    }

    /// Get the file descriptor for this operation.
    #[inline]
    pub fn fd(&self) -> RawFd {
        match &self.fd {
            FdType::Raw(fd) => *fd,
            FdType::Registered(reg_fd) => reg_fd.raw_fd(),
            FdType::Fixed(fixed_file) => fixed_file.raw_fd(),
        }
    }

    /// Get the offset for this operation.
    #[inline]
    pub fn offset(&self) -> u64 {
        self.offset
    }

    /// Get the operation type.
    #[inline]
    pub fn op_type(&self) -> OperationType {
        self.op_type
    }

    /// Get buffer information for kernel submission.
    ///
    /// Returns a tuple of (pointer, length) for the buffer if present.
    /// This is used internally by the Ring for kernel submission.
    ///
    /// # Safety
    ///
    /// The returned pointer is only valid while the buffer remains pinned
    /// and the operation is in flight. The caller must ensure the buffer
    /// is not moved or dropped until the operation completes.
    #[allow(dead_code)] // Used by ring submission logic
    pub(crate) fn buffer_info(&self) -> Option<(*mut u8, usize)> {
        match &self.buffer {
            BufferType::None => None,
            BufferType::Pinned(buf) => {
                let slice = buf.as_ref();
                Some((slice.as_ptr() as *mut u8, slice.len()))
            }
            BufferType::Registered(_) => {
                // For registered buffers, we need to get the buffer info from the registry
                // This will be handled by the ring during submission
                None
            }
            BufferType::Vectored(_) => {
                // For vectored operations, buffer info is handled differently
                // This will be handled by the ring during submission
                None
            }
        }
    }

    /// Get vectored buffer information for kernel submission.
    ///
    /// Returns a vector of (pointer, length) tuples for vectored operations.
    /// This is used internally by the Ring for vectored operation submission.
    ///
    /// # Safety
    ///
    /// The returned pointers are only valid while the buffers remain pinned
    /// and the operation is in flight.
    #[allow(dead_code)] // Used by ring submission logic
    pub(crate) fn vectored_buffer_info(&self) -> Option<Vec<(*mut u8, usize)>> {
        match &self.buffer {
            BufferType::Vectored(buffers) => {
                let info: Vec<_> = buffers
                    .iter()
                    .map(|buf| {
                        let slice = buf.as_ref();
                        (slice.as_ptr() as *mut u8, slice.len())
                    })
                    .collect();
                Some(info)
            }
            _ => None,
        }
    }

    /// Check if this operation uses a registered buffer.
    #[inline]
    pub fn uses_registered_buffer(&self) -> bool {
        matches!(self.buffer, BufferType::Registered(_))
    }

    /// Check if this operation uses a registered file descriptor.
    #[inline]
    pub fn uses_registered_fd(&self) -> bool {
        matches!(self.fd, FdType::Registered(_))
    }

    /// Check if this operation uses a fixed file.
    #[inline]
    pub fn uses_fixed_file(&self) -> bool {
        matches!(self.fd, FdType::Fixed(_))
    }

    /// Check if this operation is vectored.
    #[inline]
    pub fn is_vectored(&self) -> bool {
        matches!(self.buffer, BufferType::Vectored(_))
    }

    /// Convert this submitted operation to a completed operation.
    ///
    /// This is typically called by the Ring when processing completions.
    /// The state transition is zero-cost at runtime.
    ///
    /// # Arguments
    ///
    /// * `result` - The result of the completed operation
    #[allow(dead_code)]
    pub(crate) fn complete_with_result<T>(self, result: T) -> Operation<'ring, 'buf, Completed<T>> {
        // Zero-cost state transition - just change the type parameter
        Operation {
            ring: self.ring,
            buffer: self.buffer,
            fd: self.fd,
            offset: self.offset,
            op_type: self.op_type,
            state: Completed { result },
        }
    }
}
</file>

<file path="operation/tests.rs">
//! Comprehensive tests for operation state management.

use super::*;
use std::pin::Pin;

// Compile-time assertions to ensure our types have the expected properties
#[cfg(test)]
mod compile_time_tests {
    use super::*;
    use static_assertions::*;

    // Ensure operations are Send when appropriate
    assert_impl_all!(Operation<'static, 'static, Building>: Send);
    assert_impl_all!(Operation<'static, 'static, Submitted>: Send);
    assert_impl_all!(Operation<'static, 'static, Completed<i32>>: Send);

    // Ensure state types are the expected size for optimal memory layout
    assert_eq_size!(Building, ()); // Zero-sized type
    assert_eq_size!(Submitted, u64); // Just the operation ID
}

#[test]
fn test_operation_creation() {
    let op = Operation::<'_, '_, Building>::new();
    assert_eq!(op.get_fd(), -1);
    assert_eq!(op.get_offset(), 0);
    assert_eq!(op.get_type(), OperationType::Read);
    assert!(!op.has_buffer());
}

#[test]
fn test_operation_builder_methods() {
    let op = Operation::read().fd(5).offset(1024);

    assert_eq!(op.get_fd(), 5);
    assert_eq!(op.get_offset(), 1024);
    assert_eq!(op.get_type(), OperationType::Read);
}

#[test]
fn test_operation_types() {
    assert_eq!(Operation::read().get_type(), OperationType::Read);
    assert_eq!(Operation::write().get_type(), OperationType::Write);
    assert_eq!(Operation::accept().get_type(), OperationType::Accept);
    assert_eq!(Operation::send().get_type(), OperationType::Send);
    assert_eq!(Operation::recv().get_type(), OperationType::Recv);
}

#[test]
fn test_operation_validation() {
    // Invalid: no fd set
    let op = Operation::read();
    assert!(op.validate().is_err());

    // Invalid: fd set but no buffer for I/O operation
    let op = Operation::read().fd(0);
    assert!(op.validate().is_err());

    // Valid: accept operation doesn't need buffer
    let op = Operation::accept().fd(0);
    assert!(op.validate().is_ok());
}

#[test]
fn test_operation_with_buffer() {
    let mut buffer = vec![0u8; 1024];
    let pinned = Pin::new(buffer.as_mut_slice());

    let op = Operation::read().fd(0).buffer(pinned);

    assert!(op.has_buffer());
    assert!(op.validate().is_ok());
}

#[test]
fn test_state_transitions() {
    let mut buffer = vec![0u8; 1024];
    let pinned = Pin::new(buffer.as_mut_slice());

    let op = Operation::read().fd(0).buffer(pinned);

    // Building -> Submitted
    let submitted = op.submit_with_id(42).unwrap();
    assert_eq!(submitted.id(), 42);
    assert_eq!(submitted.fd(), 0);

    // Submitted -> Completed
    let completed = submitted.complete_with_result(100i32);
    assert_eq!(*completed.result(), 100);

    // Completed -> extracted
    let (result, _buffer) = completed.into_result();
    assert_eq!(result, 100);
}

#[test]
fn test_operation_properties() {
    let mut buffer = vec![0u8; 1024];
    let pinned = Pin::new(buffer.as_mut_slice());

    let submitted = Operation::write()
        .fd(1)
        .offset(512)
        .buffer(pinned)
        .submit_with_id(123)
        .unwrap();

    assert_eq!(submitted.id(), 123);
    assert_eq!(submitted.fd(), 1);
    assert_eq!(submitted.offset(), 512);
    assert_eq!(submitted.op_type(), OperationType::Write);
}

#[test]
fn test_completed_operation_access() {
    let mut buffer = vec![0u8; 1024];
    let pinned = Pin::new(buffer.as_mut_slice());

    let completed = Operation::read()
        .fd(0)
        .buffer(pinned)
        .submit_with_id(1)
        .unwrap()
        .complete_with_result("test result".to_string());

    // Can access result by reference
    assert_eq!(completed.result(), "test result");
    assert_eq!(completed.fd(), 0);
    assert_eq!(completed.op_type(), OperationType::Read);

    // Can extract result by value
    let (result, _buffer) = completed.into_result();
    assert_eq!(result, "test result");
}

#[test]
fn test_operation_state_machine_invariants() {
    let mut buffer = vec![0u8; 1024];
    let pinned = Pin::new(buffer.as_mut_slice());

    let building = Operation::read().fd(0).buffer(pinned);

    // Building -> Submitted
    let submitted = building.submit_with_id(1).unwrap();
    assert_eq!(submitted.id(), 1);

    // Submitted -> Completed
    let completed = submitted.complete_with_result(42);
    assert_eq!(*completed.result(), 42);

    // Completed -> extracted
    let (result, _) = completed.into_result();
    assert_eq!(result, 42);
}

#[test]
fn test_operation_validation_rules() {
    // Missing FD
    let op = Operation::read();
    assert!(op.validate().is_err());

    // Missing buffer for I/O operations
    let op = Operation::read().fd(0);
    assert!(op.validate().is_err());

    let op = Operation::write().fd(0);
    assert!(op.validate().is_err());

    // Accept doesn't need buffer
    let op = Operation::accept().fd(0);
    assert!(op.validate().is_ok());
}

#[test]
fn test_builder_pattern_fluency() {
    // Test that the builder pattern works fluently
    let op = Operation::write().fd(1).offset(1024);

    assert_eq!(op.get_fd(), 1);
    assert_eq!(op.get_offset(), 1024);
    assert_eq!(op.get_type(), OperationType::Write);
}

#[test]
fn test_default_implementation() {
    let op1 = Operation::<'_, '_, Building>::default();
    let op2 = Operation::<'_, '_, Building>::new();

    // Both should have the same initial state
    assert_eq!(op1.get_fd(), op2.get_fd());
    assert_eq!(op1.get_offset(), op2.get_offset());
    assert_eq!(op1.get_type(), op2.get_type());
    assert_eq!(op1.has_buffer(), op2.has_buffer());
}
</file>

<file path="operation/tracker.rs">
//! Operation tracking for ensuring ring safety.

use std::collections::HashMap;
use std::marker::PhantomData;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::operation::OperationType;

/// Tracks in-flight operations to ensure safety.
///
/// Prevents the ring from being dropped while operations are pending,
/// which would leave dangling pointers in the kernel.
#[derive(Debug)]
pub(crate) struct OperationTracker<'ring> {
    in_flight: HashMap<u64, OperationHandle<'ring>>,
    next_id: u64,
}

/// Handle for tracking an in-flight operation.
#[derive(Debug)]
pub(crate) struct OperationHandle<'ring> {
    pub(crate) id: u64,
    pub(crate) op_type: OperationType,
    pub(crate) fd: RawFd,
    /// Buffer ownership for operations that use buffers
    pub(crate) buffer: Option<BufferOwnership>,
    _phantom: PhantomData<&'ring ()>,
}

/// Represents ownership of a buffer used in an operation.
/// This allows the completion API to return buffer ownership to the caller.
///
/// Note: This is designed for use with owned buffers (like PinnedBuffer) that can
/// be transferred between the submission and completion phases. The future-based API
/// manages ownership through lifetimes and doesn't need this mechanism.
#[derive(Debug)]
pub enum BufferOwnership {
    /// Single owned buffer (e.g. from PinnedBuffer)
    Single(Pin<Box<[u8]>>),
    /// Multiple owned buffers for vectored operations
    Vectored(Vec<Pin<Box<[u8]>>>),
}

impl<'ring> OperationTracker<'ring> {
    /// Create a new operation tracker.
    #[allow(dead_code)] // Used by ring initialization
    pub(crate) fn new() -> Self {
        Self {
            in_flight: HashMap::new(),
            next_id: 1, // Start from 1, reserve 0 for special cases
        }
    }

    /// Register a new operation and return its ID.
    pub(crate) fn register_operation(&mut self, op_type: OperationType, fd: RawFd) -> u64 {
        self.register_operation_with_buffer(op_type, fd, None)
    }

    /// Register a new operation with buffer ownership and return its ID.
    pub(crate) fn register_operation_with_buffer(
        &mut self,
        op_type: OperationType,
        fd: RawFd,
        buffer: Option<BufferOwnership>,
    ) -> u64 {
        let id = self.next_id;
        // Wrapping add prevents overflow panics in long-running applications
        self.next_id = self.next_id.wrapping_add(1);

        let handle = OperationHandle {
            id,
            op_type,
            fd,
            buffer,
            _phantom: PhantomData,
        };

        self.in_flight.insert(id, handle);
        id
    }

    /// Mark an operation as completed and remove it from tracking.
    pub(crate) fn complete_operation(&mut self, id: u64) -> Option<OperationHandle<'ring>> {
        self.in_flight.remove(&id)
    }

    /// Get the number of operations currently in flight.
    pub(crate) fn count(&self) -> usize {
        self.in_flight.len()
    }

    /// Check if there are any operations in flight.
    pub(crate) fn has_operations(&self) -> bool {
        !self.in_flight.is_empty()
    }

    /// Get debug information about all in-flight operations.
    pub(crate) fn debug_info(&self) -> Vec<(u64, OperationType, RawFd)> {
        self.in_flight
            .values()
            .map(|handle| (handle.id, handle.op_type, handle.fd))
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn new_tracker_is_empty() {
        let tracker = OperationTracker::new();
        assert_eq!(tracker.count(), 0);
        assert!(!tracker.has_operations());
    }

    #[test]
    fn register_and_complete_operations() {
        let mut tracker = OperationTracker::new();

        let id1 = tracker.register_operation(OperationType::Read, 0);
        assert_eq!(tracker.count(), 1);
        assert!(tracker.has_operations());
        assert_eq!(id1, 1);

        let id2 = tracker.register_operation(OperationType::Write, 1);
        assert_eq!(tracker.count(), 2);
        assert_eq!(id2, 2);

        let handle = tracker.complete_operation(id1);
        assert!(handle.is_some());
        assert_eq!(handle.unwrap().id, id1);
        assert_eq!(tracker.count(), 1);

        tracker.complete_operation(id2);
        assert_eq!(tracker.count(), 0);
        assert!(!tracker.has_operations());
    }

    #[test]
    fn complete_nonexistent_operation() {
        let mut tracker = OperationTracker::new();
        let handle = tracker.complete_operation(999);
        assert!(handle.is_none());
    }

    #[test]
    fn id_wraparound() {
        let mut tracker = OperationTracker::new();
        tracker.next_id = u64::MAX;

        let id1 = tracker.register_operation(OperationType::Read, 0);
        assert_eq!(id1, u64::MAX);

        let id2 = tracker.register_operation(OperationType::Read, 0);
        assert_eq!(id2, 0); // Should wrap around
    }

    #[test]
    fn debug_info() {
        let mut tracker = OperationTracker::new();

        tracker.register_operation(OperationType::Read, 3);
        tracker.register_operation(OperationType::Write, 4);

        let info = tracker.debug_info();
        assert_eq!(info.len(), 2);

        // Sort by ID for consistent testing
        let mut sorted_info = info;
        sorted_info.sort_by_key(|&(id, _, _)| id);

        assert_eq!(sorted_info[0], (1, OperationType::Read, 3));
        assert_eq!(sorted_info[1], (2, OperationType::Write, 4));
    }
}
</file>

<file path="operation/types.rs">
//! Operation type definitions and utilities.

/// Type of I/O operation to perform.
///
/// This enum represents the different types of operations that can be submitted
/// to io_uring. Each variant corresponds to a specific system call or operation type.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
#[repr(u8)]
pub enum OperationType {
    /// Read data from a file descriptor into a buffer
    Read = 0,
    /// Write data from a buffer to a file descriptor
    Write = 1,
    /// Accept a connection on a listening socket
    Accept = 2,
    /// Send data on a socket
    Send = 3,
    /// Receive data from a socket
    Recv = 4,
    /// Vectored read operation (readv)
    ReadVectored = 5,
    /// Vectored write operation (writev)
    WriteVectored = 6,
}

impl OperationType {
    /// Returns true if this operation type requires a buffer.
    ///
    /// Accept operations don't require a buffer as they only return
    /// a new file descriptor for the accepted connection.
    #[inline]
    pub const fn requires_buffer(self) -> bool {
        match self {
            Self::Read
            | Self::Write
            | Self::Send
            | Self::Recv
            | Self::ReadVectored
            | Self::WriteVectored => true,
            Self::Accept => false,
        }
    }

    /// Returns true if this operation type is a read-like operation.
    ///
    /// Read-like operations populate the buffer with data from the kernel.
    #[inline]
    pub const fn is_read_like(self) -> bool {
        matches!(self, Self::Read | Self::Recv | Self::ReadVectored)
    }

    /// Returns true if this operation type is a write-like operation.
    ///
    /// Write-like operations send data from the buffer to the kernel.
    #[inline]
    pub const fn is_write_like(self) -> bool {
        matches!(self, Self::Write | Self::Send | Self::WriteVectored)
    }

    /// Returns true if this operation type is vectored.
    ///
    /// Vectored operations use multiple buffers (scatter-gather I/O).
    #[inline]
    pub const fn is_vectored(self) -> bool {
        matches!(self, Self::ReadVectored | Self::WriteVectored)
    }
}

impl std::fmt::Display for OperationType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Read => write!(f, "read"),
            Self::Write => write!(f, "write"),
            Self::Accept => write!(f, "accept"),
            Self::Send => write!(f, "send"),
            Self::Recv => write!(f, "recv"),
            Self::ReadVectored => write!(f, "readv"),
            Self::WriteVectored => write!(f, "writev"),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_operation_type_properties() {
        assert!(OperationType::Read.requires_buffer());
        assert!(OperationType::Write.requires_buffer());
        assert!(!OperationType::Accept.requires_buffer());
        assert!(OperationType::Send.requires_buffer());
        assert!(OperationType::Recv.requires_buffer());
        assert!(OperationType::ReadVectored.requires_buffer());
        assert!(OperationType::WriteVectored.requires_buffer());

        assert!(OperationType::Read.is_read_like());
        assert!(!OperationType::Write.is_read_like());
        assert!(OperationType::Recv.is_read_like());
        assert!(OperationType::ReadVectored.is_read_like());
        assert!(!OperationType::WriteVectored.is_read_like());

        assert!(!OperationType::Read.is_write_like());
        assert!(OperationType::Write.is_write_like());
        assert!(OperationType::Send.is_write_like());
        assert!(!OperationType::ReadVectored.is_write_like());
        assert!(OperationType::WriteVectored.is_write_like());

        assert!(!OperationType::Read.is_vectored());
        assert!(!OperationType::Write.is_vectored());
        assert!(OperationType::ReadVectored.is_vectored());
        assert!(OperationType::WriteVectored.is_vectored());
    }

    #[test]
    fn test_operation_type_display() {
        assert_eq!(OperationType::Read.to_string(), "read");
        assert_eq!(OperationType::Write.to_string(), "write");
        assert_eq!(OperationType::Accept.to_string(), "accept");
        assert_eq!(OperationType::Send.to_string(), "send");
        assert_eq!(OperationType::Recv.to_string(), "recv");
        assert_eq!(OperationType::ReadVectored.to_string(), "readv");
        assert_eq!(OperationType::WriteVectored.to_string(), "writev");
    }
}
</file>

<file path="pool/buffer_pool.rs">
//! Thread-safe buffer pool implementation.

use std::collections::VecDeque;
use std::sync::{Arc, Mutex};

use crate::buffer::PinnedBuffer;
use crate::error::Result;

use super::{PoolInner, PoolStats, PooledBuffer};

/// Thread-safe pool of pre-allocated pinned buffers.
///
/// Pre-allocates all buffers during construction and pins them in memory,
/// making them immediately ready for io_uring operations. This eliminates
/// allocation overhead and ensures predictable performance.
///
/// # Thread Safety
///
/// [`BufferPool`] is [`Send`] and [`Sync`] - internal synchronization
/// is handled through a [`Mutex`] protecting the pool state.
///
/// # Memory Management
///
/// All buffers are pre-allocated and remain allocated for the pool's lifetime.
/// This provides predictable memory usage but requires careful sizing.
///
/// # Examples
///
/// ```rust
/// use safer_ring::pool::BufferPool;
///
/// let pool = BufferPool::new(10, 4096);
/// if let Some(buffer) = pool.try_get().unwrap() {
///     // Use buffer for I/O operations
///     // Buffer automatically returns to pool on drop
/// }
/// ```
pub struct BufferPool {
    /// Shared pool state protected by mutex
    inner: Arc<Mutex<PoolInner>>,
    /// Immutable capacity - stored outside mutex for lock-free access
    capacity: usize,
    /// Immutable buffer size - stored outside mutex for lock-free access  
    buffer_size: usize,
}

impl BufferPool {
    /// Create a new buffer pool with specified capacity and buffer size.
    ///
    /// All buffers are pre-allocated and pinned during construction.
    ///
    /// # Arguments
    ///
    /// * `capacity` - Number of buffers to pre-allocate (must be > 0)
    /// * `buffer_size` - Size of each buffer in bytes (must be > 0)
    ///
    /// # Panics
    ///
    /// Panics if `capacity` or `buffer_size` is zero.
    pub fn new(capacity: usize, buffer_size: usize) -> Self {
        assert!(capacity > 0, "Pool capacity must be greater than zero");
        assert!(buffer_size > 0, "Buffer size must be greater than zero");

        let mut available = VecDeque::with_capacity(capacity);

        // Pre-allocate all buffers - this is the key optimization
        for _ in 0..capacity {
            available.push_back(PinnedBuffer::with_capacity(buffer_size));
        }

        Self {
            inner: Arc::new(Mutex::new(PoolInner {
                available,
                in_use: 0,
                total_allocations: 0,
                failed_allocations: 0,
            })),
            capacity,
            buffer_size,
        }
    }

    /// Create a buffer pool with custom buffer initialization.
    ///
    /// Allows more control over buffer initialization, such as pre-filling
    /// buffers with specific patterns.
    ///
    /// # Arguments
    ///
    /// * `capacity` - Number of buffers to create
    /// * `buffer_factory` - Closure that creates each buffer
    ///
    /// # Panics
    ///
    /// Panics if buffers have inconsistent sizes.
    pub fn with_factory<F>(capacity: usize, mut buffer_factory: F) -> Self
    where
        F: FnMut() -> PinnedBuffer<[u8]>,
    {
        assert!(capacity > 0, "Pool capacity must be greater than zero");

        let mut available = VecDeque::with_capacity(capacity);
        let mut buffer_size = 0;

        for i in 0..capacity {
            let buffer = buffer_factory();
            if i == 0 {
                buffer_size = buffer.len();
            } else {
                // Ensure consistency - all buffers must be same size
                assert_eq!(
                    buffer.len(),
                    buffer_size,
                    "All buffers must have the same size"
                );
            }
            available.push_back(buffer);
        }

        Self {
            inner: Arc::new(Mutex::new(PoolInner {
                available,
                in_use: 0,
                total_allocations: 0,
                failed_allocations: 0,
            })),
            capacity,
            buffer_size,
        }
    }

    /// Try to get a buffer from the pool.
    ///
    /// Returns `Some(PooledBuffer)` if available, `None` if pool is empty.
    /// Never blocks and never allocates new buffers.
    pub fn try_get(&self) -> Result<Option<PooledBuffer>> {
        let mut inner = PoolInner::lock(&self.inner)?;

        if let Some(buffer) = inner.available.pop_front() {
            inner.in_use += 1;
            inner.total_allocations += 1;

            Ok(Some(PooledBuffer::new(buffer, Arc::clone(&self.inner))))
        } else {
            inner.failed_allocations += 1;
            Ok(None)
        }
    }

    /// Fast path buffer acquisition with minimal locking.
    ///
    /// This is an optimized version that uses atomic operations where possible
    /// to reduce lock contention in high-throughput scenarios.
    pub fn try_get_fast(&self) -> Result<Option<PooledBuffer>> {
        // Fast path: check if pool is likely empty without locking
        {
            let inner = PoolInner::lock(&self.inner)?;
            if inner.available.is_empty() {
                return Ok(None);
            }
        }

        // Slow path: actually acquire buffer
        self.try_get()
    }

    /// Get a buffer from the pool.
    ///
    /// Returns `Some(PooledBuffer)` if available, `None` if pool is empty.
    /// This is a convenience method that unwraps the Result from try_get.
    pub fn get(&self) -> Option<PooledBuffer> {
        self.try_get().unwrap_or(None)
    }

    /// Get a buffer from the pool, blocking until one becomes available.
    ///
    /// This method blocks the current thread until a buffer is returned.
    /// Uses exponential backoff to reduce CPU usage while waiting.
    ///
    /// # Performance Note
    ///
    /// For high-performance applications, consider using `try_get()` in a loop
    /// with your own scheduling strategy rather than this blocking method.
    pub fn get_blocking(&self) -> Result<PooledBuffer> {
        let mut backoff_us = 1;
        const MAX_BACKOFF_US: u64 = 1000; // Cap at 1ms

        loop {
            if let Some(buffer) = self.try_get()? {
                return Ok(buffer);
            }

            // Exponential backoff to reduce CPU usage
            std::thread::sleep(std::time::Duration::from_micros(backoff_us));
            backoff_us = (backoff_us * 2).min(MAX_BACKOFF_US);
        }
    }

    /// Get the total capacity of the pool.
    ///
    /// This is a lock-free operation since capacity is immutable.
    pub fn capacity(&self) -> usize {
        self.capacity
    }

    /// Get the number of available buffers.
    pub fn available(&self) -> Result<usize> {
        let inner = PoolInner::lock(&self.inner)?;
        Ok(inner.available.len())
    }

    /// Get the number of buffers currently in use.
    pub fn in_use(&self) -> Result<usize> {
        let inner = PoolInner::lock(&self.inner)?;
        Ok(inner.in_use)
    }

    /// Get the size of each buffer in the pool.
    ///
    /// This is a lock-free operation since buffer size is immutable.
    pub fn buffer_size(&self) -> usize {
        self.buffer_size
    }

    /// Get comprehensive statistics about the pool.
    ///
    /// Returns detailed information about pool usage and allocation patterns.
    /// Takes a single lock to ensure all statistics are consistent.
    pub fn stats(&self) -> PoolStats {
        let inner = PoolInner::lock(&self.inner).unwrap();
        let utilization = inner.in_use as f64 / self.capacity as f64;
        let available = inner.available.len();

        PoolStats {
            capacity: self.capacity,
            available,
            in_use: inner.in_use,
            buffer_size: self.buffer_size,
            total_allocations: inner.total_allocations,
            failed_allocations: inner.failed_allocations,
            utilization,
            total_buffers: self.capacity,
            available_buffers: available,
            in_use_buffers: inner.in_use,
        }
    }

    /// Check if the pool is empty (no available buffers).
    pub fn is_empty(&self) -> Result<bool> {
        let inner = PoolInner::lock(&self.inner)?;
        Ok(inner.available.is_empty())
    }

    /// Check if the pool is full (all buffers available).
    pub fn is_full(&self) -> Result<bool> {
        let inner = PoolInner::lock(&self.inner)?;
        Ok(inner.available.len() == self.capacity)
    }

    /// Get a snapshot of current pool state in a single lock operation.
    ///
    /// More efficient than calling multiple methods separately when you need
    /// multiple pieces of information about the pool state.
    pub fn snapshot(&self) -> Result<(usize, usize, bool, bool)> {
        let inner = PoolInner::lock(&self.inner)?;
        let available = inner.available.len();
        let in_use = inner.in_use;
        let is_empty = inner.available.is_empty();
        let is_full = available == self.capacity;

        Ok((available, in_use, is_empty, is_full))
    }
}

// SAFETY: BufferPool can be safely sent between threads
unsafe impl Send for BufferPool {}

// SAFETY: BufferPool can be safely shared between threads
unsafe impl Sync for BufferPool {}
</file>

<file path="pool/mod.rs">
//! Buffer pool for efficient buffer reuse.
//!
//! This module provides thread-safe buffer pooling for io_uring operations,
//! eliminating allocation overhead in hot paths while maintaining memory safety.

mod buffer_pool;
mod pooled_buffer;
mod stats;

#[cfg(test)]
mod tests;

pub use buffer_pool::BufferPool;
pub use pooled_buffer::PooledBuffer;
pub use stats::PoolStats;

use std::collections::VecDeque;
use std::sync::{Arc, Mutex, MutexGuard};

use crate::buffer::PinnedBuffer;
use crate::error::{Result, SaferRingError};

/// Internal pool state protected by mutex for thread safety.
///
/// Only contains mutable state - immutable fields like capacity and buffer_size
/// are stored directly in BufferPool for lock-free access.
pub(crate) struct PoolInner {
    /// Available buffers - FIFO queue ensures fair allocation
    pub(crate) available: VecDeque<PinnedBuffer<[u8]>>,
    /// Number of buffers currently in use
    pub(crate) in_use: usize,
    /// Total successful allocations (for monitoring)
    pub(crate) total_allocations: u64,
    /// Total failed allocation attempts (for monitoring)
    pub(crate) failed_allocations: u64,
}

impl PoolInner {
    /// Helper to lock pool state with proper error handling.
    pub(crate) fn lock(inner: &Arc<Mutex<PoolInner>>) -> Result<MutexGuard<'_, PoolInner>> {
        inner.lock().map_err(|_| SaferRingError::PoolPoisoned)
    }
}
</file>

<file path="pool/pooled_buffer.rs">
//! RAII wrapper for pool-managed buffers.

use std::pin::Pin;
use std::sync::{Arc, Mutex};

use crate::buffer::PinnedBuffer;

use super::PoolInner;

/// A buffer borrowed from a pool that automatically returns on drop.
///
/// Provides RAII semantics - the buffer is automatically returned to the pool
/// when dropped, ensuring no buffer leaks even in error conditions.
///
/// # Safety
///
/// Maintains all safety guarantees of [`PinnedBuffer`] while adding
/// automatic pool return semantics.
pub struct PooledBuffer {
    /// The actual buffer (None after being returned)
    buffer: Option<PinnedBuffer<[u8]>>,
    /// Reference to the pool for return on drop
    pool: Arc<Mutex<PoolInner>>,
}

impl PooledBuffer {
    /// Create a new pooled buffer.
    ///
    /// This is an internal constructor used by the pool.
    pub(super) fn new(buffer: PinnedBuffer<[u8]>, pool: Arc<Mutex<PoolInner>>) -> Self {
        Self {
            buffer: Some(buffer),
            pool,
        }
    }

    /// Get a reference to the underlying buffer.
    ///
    /// # Panics
    ///
    /// Panics if the buffer has already been returned (internal bug).
    pub fn buffer(&self) -> &PinnedBuffer<[u8]> {
        self.buffer
            .as_ref()
            .expect("Buffer should be present - this is a bug")
    }

    /// Get a mutable reference to the underlying buffer.
    ///
    /// # Panics
    ///
    /// Panics if the buffer has already been returned (internal bug).
    pub fn buffer_mut(&mut self) -> &mut PinnedBuffer<[u8]> {
        self.buffer
            .as_mut()
            .expect("Buffer should be present - this is a bug")
    }

    /// Get a pinned mutable slice reference to the buffer data.
    ///
    /// This maintains pinning guarantees required for io_uring operations.
    pub fn as_mut_slice(&mut self) -> Pin<&mut [u8]> {
        self.buffer_mut().as_mut_slice()
    }

    /// Get an immutable slice reference to the buffer data.
    pub fn as_slice(&self) -> &[u8] {
        self.buffer().as_slice()
    }

    /// Get the length of the buffer.
    pub fn len(&self) -> usize {
        self.buffer().len()
    }

    /// Check if the buffer is empty.
    pub fn is_empty(&self) -> bool {
        self.buffer().is_empty()
    }

    /// Detach the buffer from the pool, taking ownership.
    ///
    /// This removes the buffer from pool management, preventing automatic
    /// return on drop. Use when you need to transfer ownership elsewhere.
    pub fn detach(mut self) -> PinnedBuffer<[u8]> {
        self.buffer
            .take()
            .expect("Buffer should be present - this is a bug")
    }
}

impl Drop for PooledBuffer {
    /// Automatically return the buffer to the pool when dropped.
    ///
    /// Ensures proper resource management even in error conditions.
    fn drop(&mut self) {
        if let Some(buffer) = self.buffer.take() {
            // Return buffer to pool - ignore lock errors during drop
            if let Ok(mut inner) = self.pool.lock() {
                inner.available.push_back(buffer);
                inner.in_use = inner.in_use.saturating_sub(1);
            }
            // If lock fails during drop, we're likely in a panic situation
            // and the buffer will be dropped normally, which is acceptable
        }
    }
}

// Debug implementation that doesn't expose buffer contents
impl std::fmt::Debug for PooledBuffer {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("PooledBuffer")
            .field("len", &self.len())
            .field("has_buffer", &self.buffer.is_some())
            .finish()
    }
}

// SAFETY: PooledBuffer can be sent between threads when the underlying buffer is Send
unsafe impl Send for PooledBuffer {}

// SAFETY: PooledBuffer can be shared between threads when the underlying buffer is Sync
// However, since we provide mutable access, it's typically used with exclusive ownership
unsafe impl Sync for PooledBuffer {}
</file>

<file path="pool/stats.rs">
//! Pool statistics and monitoring.

/// Statistics about buffer pool usage.
///
/// Provides insights into pool performance and utilization patterns.
/// All statistics are captured at a specific point in time and may
/// become stale as the pool state changes.
///
/// # Examples
///
/// ```rust
/// use safer_ring::pool::BufferPool;
///
/// let pool = BufferPool::new(10, 4096);
/// let stats = pool.stats();
///
/// println!("Pool utilization: {:.1}%", stats.utilization_percent());
/// println!("Success rate: {:.1}%", stats.success_rate_percent());
/// ```
#[derive(Debug, Clone, Copy, PartialEq)]
pub struct PoolStats {
    /// Total capacity of the pool
    pub capacity: usize,
    /// Number of buffers currently available
    pub available: usize,
    /// Number of buffers currently in use
    pub in_use: usize,
    /// Size of each buffer in bytes
    pub buffer_size: usize,
    /// Total successful allocations since pool creation
    pub total_allocations: u64,
    /// Total failed allocation attempts since pool creation
    pub failed_allocations: u64,
    /// Current utilization as a ratio (0.0 to 1.0)
    pub utilization: f64,
    /// Total number of buffers in the pool (same as capacity)
    pub total_buffers: usize,
    /// Number of buffers currently available (same as available)
    pub available_buffers: usize,
    /// Number of buffers currently in use (same as in_use)
    pub in_use_buffers: usize,
}

impl PoolStats {
    /// Get utilization as a percentage (0.0 to 100.0).
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use safer_ring::pool::PoolStats;
    /// let stats = PoolStats {
    ///     capacity: 10,
    ///     available: 3,
    ///     in_use: 7,
    ///     buffer_size: 4096,
    ///     total_allocations: 100,
    ///     failed_allocations: 5,
    ///     utilization: 0.7,
    ///     total_buffers: 10,
    ///     available_buffers: 3,
    ///     in_use_buffers: 7,
    /// };
    /// assert_eq!(stats.utilization_percent(), 70.0);
    /// ```
    pub fn utilization_percent(&self) -> f64 {
        self.utilization * 100.0
    }

    /// Get the success rate of allocations as a percentage (0.0 to 100.0).
    ///
    /// Returns 100.0 if no allocation attempts have been made.
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use safer_ring::pool::PoolStats;
    /// let stats = PoolStats {
    ///     capacity: 10,
    ///     available: 5,
    ///     in_use: 5,
    ///     buffer_size: 4096,
    ///     total_allocations: 95,
    ///     failed_allocations: 5,
    ///     utilization: 0.5,
    ///     total_buffers: 10,
    ///     available_buffers: 5,
    ///     in_use_buffers: 5,
    /// };
    /// assert_eq!(stats.success_rate_percent(), 95.0);
    /// ```
    pub fn success_rate_percent(&self) -> f64 {
        let total_attempts = self.total_allocations + self.failed_allocations;
        if total_attempts == 0 {
            100.0 // No attempts means perfect success rate
        } else {
            (self.total_allocations as f64 / total_attempts as f64) * 100.0
        }
    }

    /// Get the total memory allocated by the pool in bytes.
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use safer_ring::pool::PoolStats;
    /// let stats = PoolStats {
    ///     capacity: 10,
    ///     buffer_size: 4096,
    ///     // ... other fields
    ///     # available: 5, in_use: 5, total_allocations: 100,
    ///     # failed_allocations: 0, utilization: 0.5,
    ///     # total_buffers: 10, available_buffers: 5, in_use_buffers: 5,
    /// };
    /// assert_eq!(stats.total_memory_bytes(), 40960); // 10 * 4096
    /// ```
    pub fn total_memory_bytes(&self) -> usize {
        self.capacity * self.buffer_size
    }

    /// Get the memory currently in use in bytes.
    pub fn memory_in_use_bytes(&self) -> usize {
        self.in_use * self.buffer_size
    }

    /// Check if the pool is under high pressure (utilization > 80%).
    ///
    /// This can be used to trigger alerts or scaling decisions.
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use safer_ring::pool::PoolStats;
    /// let high_pressure = PoolStats {
    ///     utilization: 0.85, // 85% utilization
    ///     # capacity: 10, available: 2, in_use: 8, buffer_size: 4096,
    ///     # total_allocations: 100, failed_allocations: 0,
    ///     # total_buffers: 10, available_buffers: 2, in_use_buffers: 8,
    /// };
    /// assert!(high_pressure.is_under_pressure());
    ///
    /// let normal_pressure = PoolStats {
    ///     utilization: 0.60, // 60% utilization
    ///     # capacity: 10, available: 4, in_use: 6, buffer_size: 4096,
    ///     # total_allocations: 100, failed_allocations: 0,
    ///     # total_buffers: 10, available_buffers: 4, in_use_buffers: 6,
    /// };
    /// assert!(!normal_pressure.is_under_pressure());
    /// ```
    pub fn is_under_pressure(&self) -> bool {
        self.utilization > 0.8
    }

    /// Check if the pool has experienced allocation failures.
    pub fn has_allocation_failures(&self) -> bool {
        self.failed_allocations > 0
    }
}
</file>

<file path="pool/tests.rs">
//! Tests for buffer pool functionality.

use super::*;
use crate::buffer::PinnedBuffer;
use std::pin::Pin;

#[test]
fn pool_creation() {
    let pool = BufferPool::new(5, 1024);
    assert_eq!(pool.capacity(), 5);
    assert_eq!(pool.available().unwrap(), 5);
    assert_eq!(pool.in_use().unwrap(), 0);
    assert_eq!(pool.buffer_size(), 1024);
    assert!(pool.is_full().unwrap());
    assert!(!pool.is_empty().unwrap());
}

#[test]
#[should_panic(expected = "Pool capacity must be greater than zero")]
fn pool_creation_zero_capacity() {
    BufferPool::new(0, 1024);
}

#[test]
#[should_panic(expected = "Buffer size must be greater than zero")]
fn pool_creation_zero_buffer_size() {
    BufferPool::new(5, 0);
}

#[test]
fn pool_with_factory() {
    let pool = BufferPool::with_factory(3, || PinnedBuffer::from_vec(vec![0xFF; 512]));
    assert_eq!(pool.capacity(), 3);
    assert_eq!(pool.buffer_size(), 512);

    let buffer = pool.try_get().unwrap().unwrap();
    assert_eq!(buffer.len(), 512);
    assert!(buffer.as_slice().iter().all(|&b| b == 0xFF));
}

#[test]
fn buffer_allocation_and_return() {
    let pool = BufferPool::new(2, 1024);

    // Initially full
    assert_eq!(pool.available().unwrap(), 2);
    assert_eq!(pool.in_use().unwrap(), 0);

    // Get first buffer
    let buffer1 = pool.try_get().unwrap().unwrap();
    assert_eq!(pool.available().unwrap(), 1);
    assert_eq!(pool.in_use().unwrap(), 1);

    // Get second buffer
    let buffer2 = pool.try_get().unwrap().unwrap();
    assert_eq!(pool.available().unwrap(), 0);
    assert_eq!(pool.in_use().unwrap(), 2);

    // Pool is now empty
    let buffer3 = pool.try_get().unwrap();
    assert!(buffer3.is_none());

    // Drop buffers - should return to pool
    drop(buffer1);
    drop(buffer2);
    assert_eq!(pool.available().unwrap(), 2);
    assert_eq!(pool.in_use().unwrap(), 0);
}

#[test]
fn pooled_buffer_operations() {
    let pool = BufferPool::new(1, 1024);
    let mut buffer = pool.try_get().unwrap().unwrap();

    assert_eq!(buffer.len(), 1024);
    assert!(!buffer.is_empty());

    // Test slice access
    let slice = buffer.as_slice();
    assert_eq!(slice.len(), 1024);

    // Test mutable slice access
    {
        let mut_slice = buffer.as_mut_slice();
        unsafe {
            let slice_mut = Pin::get_unchecked_mut(mut_slice);
            slice_mut[0] = 42;
        }
    }

    assert_eq!(buffer.as_slice()[0], 42);
}

#[test]
fn pool_stats() {
    let pool = BufferPool::new(10, 2048);
    let stats = pool.stats();

    assert_eq!(stats.capacity, 10);
    assert_eq!(stats.available, 10);
    assert_eq!(stats.in_use, 0);
    assert_eq!(stats.buffer_size, 2048);
    assert_eq!(stats.total_allocations, 0);
    assert_eq!(stats.utilization, 0.0);

    // Allocate some buffers
    let _buffer1 = pool.try_get().unwrap().unwrap();
    let _buffer2 = pool.try_get().unwrap().unwrap();

    let stats = pool.stats();
    assert_eq!(stats.available, 8);
    assert_eq!(stats.in_use, 2);
    assert_eq!(stats.total_allocations, 2);
    assert_eq!(stats.utilization, 0.2);
}
#[test]

fn pool_stats_enhanced_methods() {
    let pool = BufferPool::new(10, 1024);
    let stats = pool.stats();

    // Test new methods
    assert_eq!(stats.utilization_percent(), 0.0);
    assert_eq!(stats.success_rate_percent(), 100.0); // No attempts yet
    assert_eq!(stats.total_memory_bytes(), 10 * 1024);
    assert_eq!(stats.memory_in_use_bytes(), 0);
    assert!(!stats.is_under_pressure());
    assert!(!stats.has_allocation_failures());

    // Allocate some buffers to test utilization (9 out of 10 = 90%)
    let _buffers: Vec<_> = (0..9).map(|_| pool.try_get().unwrap().unwrap()).collect();
    let stats = pool.stats();

    assert_eq!(stats.utilization_percent(), 90.0);
    assert_eq!(stats.memory_in_use_bytes(), 9 * 1024);
    assert!(stats.is_under_pressure()); // 90% utilization should trigger pressure

    // Try to get more buffers than available to test failure tracking
    let _extra1 = pool.try_get().unwrap().unwrap(); // This should get the last buffer
    let failed = pool.try_get().unwrap(); // This should fail
    assert!(failed.is_none());

    let stats = pool.stats();
    assert!(stats.has_allocation_failures());
    assert!(stats.success_rate_percent() < 100.0);
}

#[test]
fn pool_snapshot() {
    let pool = BufferPool::new(5, 512);

    let (available, in_use, is_empty, is_full) = pool.snapshot().unwrap();
    assert_eq!(available, 5);
    assert_eq!(in_use, 0);
    assert!(!is_empty);
    assert!(is_full);

    // Get some buffers
    let _buffer1 = pool.try_get().unwrap().unwrap();
    let _buffer2 = pool.try_get().unwrap().unwrap();

    let (available, in_use, is_empty, is_full) = pool.snapshot().unwrap();
    assert_eq!(available, 3);
    assert_eq!(in_use, 2);
    assert!(!is_empty);
    assert!(!is_full);
}
</file>

<file path="registry/mod.rs">
//! File descriptor and buffer registration for performance optimization.
//!
//! This module provides safe registration of file descriptors and buffers with io_uring
//! for improved performance. Registration allows the kernel to avoid repeated lookups
//! and validations for frequently used resources.
//!
//! # Safety Guarantees
//!
//! - Registered resources cannot be used after unregistration (compile-time enforced)
//! - Resources cannot be unregistered while operations are using them
//! - Buffer addresses remain stable throughout registration lifetime
//! - File descriptors are validated before registration
//!
//! # Example
//!
//! ```rust,no_run
//! # use safer_ring::{Registry, Ring};
//! # use std::pin::Pin;
//! # fn main() -> Result<(), Box<dyn std::error::Error>> {
//! let mut registry = Registry::new();
//!
//! // Register a file descriptor
//! let registered_fd = registry.register_fd(0)?;
//!
//! // Register a buffer
//! let buffer = Pin::new(Box::new([0u8; 1024]));
//! let registered_buffer = registry.register_buffer(buffer)?;
//!
//! println!("Registered FD index: {}", registered_fd.index());
//! println!("Registered buffer size: {}", registered_buffer.size());
//! # Ok(())
//! # }
//! ```

use std::collections::HashSet;
use std::marker::PhantomData;
use std::os::unix::io::RawFd;
use std::pin::Pin;

use crate::error::{Result, SaferRingError};
use crate::ownership::OwnedBuffer;

#[cfg(target_os = "linux")]
#[cfg(test)]
mod tests;

/// Registry for managing registered file descriptors and buffers.
///
/// The registry provides safe management of io_uring registered resources,
/// ensuring that resources cannot be used after unregistration and that
/// unregistration cannot occur while resources are in use.
///
/// # Lifetime Management
///
/// The registry is tied to a ring lifetime to ensure that registered resources
/// cannot outlive the ring that registered them. This prevents use-after-free
/// bugs when the ring is dropped.
///
/// # Thread Safety
///
/// The registry is not thread-safe by design. Each ring should have its own
/// registry, and operations should be performed from a single thread or
/// properly synchronized externally.
pub struct Registry<'ring> {
    /// Registered file descriptors with their original fd values
    registered_fds: Vec<Option<(RawFd, RegisteredFdInner)>>,
    /// Registered buffers with their pinned memory
    registered_buffers: Vec<Option<Pin<Box<[u8]>>>>,
    /// Fixed files for optimized access by index
    fixed_files: Vec<Option<RawFd>>,
    /// Pre-registered buffer slots for kernel buffer selection
    registered_buffer_slots: Vec<Option<OwnedBuffer>>,
    /// Set of file descriptor indices currently in use by operations
    fds_in_use: HashSet<u32>,
    /// Set of buffer indices currently in use by operations
    buffers_in_use: HashSet<u32>,
    /// Set of fixed file indices currently in use by operations
    fixed_files_in_use: HashSet<u32>,
    /// Set of registered buffer slot indices currently in use
    buffer_slots_in_use: HashSet<u32>,
    /// Whether the registry has been registered with io_uring
    #[allow(dead_code)]
    is_registered: bool,
    /// Phantom data for lifetime tracking
    _phantom: PhantomData<&'ring ()>,
}

/// Internal data for a registered file descriptor.
#[derive(Debug, Clone)]
struct RegisteredFdInner {
    /// Original file descriptor value
    #[allow(dead_code)]
    fd: RawFd,
    /// Whether this fd is currently in use
    #[allow(dead_code)]
    in_use: bool,
}

/// A registered file descriptor with safe handle and lifetime tracking.
///
/// This handle prevents the file descriptor from being unregistered while
/// it's still in use by operations. The handle is tied to the registry
/// lifetime to prevent use after the registry is dropped.
#[derive(Debug)]
pub struct RegisteredFd {
    /// Index in the registration table
    index: u32,
    /// Original file descriptor for validation
    fd: RawFd,
}

/// A registered buffer with safe handle and lifetime tracking.
///
/// This handle prevents the buffer from being unregistered while it's
/// still in use by operations. The handle maintains information about
/// the buffer size for validation purposes.
#[derive(Debug)]
pub struct RegisteredBuffer {
    /// Index in the registration table
    index: u32,
    /// Size of the registered buffer
    size: usize,
}

impl<'ring> Default for Registry<'ring> {
    fn default() -> Self {
        Self::new()
    }
}

impl<'ring> Registry<'ring> {
    /// Create a new empty registry.
    ///
    /// The registry starts empty and can have file descriptors and buffers
    /// registered with it. Registration with io_uring happens when the
    /// first resource is registered.
    pub fn new() -> Self {
        Self {
            registered_fds: Vec::new(),
            registered_buffers: Vec::new(),
            fixed_files: Vec::new(),
            registered_buffer_slots: Vec::new(),
            fds_in_use: HashSet::new(),
            buffers_in_use: HashSet::new(),
            fixed_files_in_use: HashSet::new(),
            buffer_slots_in_use: HashSet::new(),
            is_registered: false,
            _phantom: PhantomData,
        }
    }

    /// Register a file descriptor for optimized access.
    ///
    /// Registers the file descriptor with io_uring for improved performance
    /// on subsequent operations. The returned handle can be used to reference
    /// the registered file descriptor in operations.
    ///
    /// # Arguments
    ///
    /// * `fd` - The file descriptor to register
    ///
    /// # Returns
    ///
    /// Returns a RegisteredFd handle that can be used in operations.
    ///
    /// # Errors
    ///
    /// - Returns `SaferRingError::Io` if the file descriptor is invalid
    /// - Returns `SaferRingError::IoUring` if io_uring registration fails
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Registry;
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let registered_fd = registry.register_fd(0)?; // stdin
    /// # Ok(())
    /// # }
    /// ```
    pub fn register_fd(&mut self, fd: RawFd) -> Result<RegisteredFd> {
        // Validate file descriptor
        if fd < 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "File descriptor must be non-negative",
            )));
        }

        // Find an empty slot or add a new one
        let index =
            if let Some(empty_index) = self.registered_fds.iter().position(|slot| slot.is_none()) {
                empty_index as u32
            } else {
                let index = self.registered_fds.len() as u32;
                self.registered_fds.push(None);
                index
            };

        let inner = RegisteredFdInner { fd, in_use: false };

        // Store the registration
        self.registered_fds[index as usize] = Some((fd, inner));

        // TODO: Actually register with io_uring when integrated with Ring
        // For now, we just track the registration locally

        Ok(RegisteredFd { index, fd })
    }

    /// Register a buffer for optimized access.
    ///
    /// Registers the buffer with io_uring for improved performance on
    /// subsequent operations. The buffer must be pinned to ensure its
    /// address remains stable throughout the registration lifetime.
    ///
    /// # Arguments
    ///
    /// * `buffer` - The pinned buffer to register
    ///
    /// # Returns
    ///
    /// Returns a RegisteredBuffer handle that can be used in operations.
    ///
    /// # Errors
    ///
    /// - Returns `SaferRingError::Io` if the buffer is empty
    /// - Returns `SaferRingError::IoUring` if io_uring registration fails
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Registry;
    /// # use std::pin::Pin;
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let buffer = Pin::new(Box::new([0u8; 1024]));
    /// let registered_buffer = registry.register_buffer(buffer)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn register_buffer(&mut self, buffer: Pin<Box<[u8]>>) -> Result<RegisteredBuffer> {
        if buffer.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Buffer cannot be empty",
            )));
        }

        let size = buffer.len();

        // Find an empty slot or add a new one
        let index = if let Some(empty_index) = self
            .registered_buffers
            .iter()
            .position(|slot| slot.is_none())
        {
            empty_index as u32
        } else {
            let index = self.registered_buffers.len() as u32;
            self.registered_buffers.push(None);
            index
        };

        // Store the buffer
        self.registered_buffers[index as usize] = Some(buffer);

        // TODO: Actually register with io_uring when integrated with Ring
        // For now, we just track the registration locally

        Ok(RegisteredBuffer { index, size })
    }

    /// Unregister a file descriptor.
    ///
    /// Removes the file descriptor from the registry. This operation will
    /// fail if the file descriptor is currently in use by any operations.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - The registered file descriptor to unregister
    ///
    /// # Errors
    ///
    /// - Returns `SaferRingError::NotRegistered` if the fd is not registered
    /// - Returns `SaferRingError::BufferInFlight` if the fd is in use
    ///
    /// # Safety
    ///
    /// This function consumes the RegisteredFd handle, preventing further
    /// use after unregistration.
    pub fn unregister_fd(&mut self, registered_fd: RegisteredFd) -> Result<()> {
        let index = registered_fd.index as usize;

        // Check if the fd exists and matches
        if index >= self.registered_fds.len() {
            return Err(SaferRingError::NotRegistered);
        }

        let slot = &mut self.registered_fds[index];
        let Some((stored_fd, _)) = slot.as_ref() else {
            return Err(SaferRingError::NotRegistered);
        };

        if *stored_fd != registered_fd.fd {
            return Err(SaferRingError::NotRegistered);
        }

        // Check if the fd is in use
        if self.fds_in_use.contains(&registered_fd.index) {
            return Err(SaferRingError::BufferInFlight);
        }

        // Remove the registration
        *slot = None;

        // TODO: Actually unregister with io_uring when integrated with Ring

        Ok(())
    }

    /// Unregister a buffer.
    ///
    /// Removes the buffer from the registry and returns ownership of the
    /// pinned buffer. This operation will fail if the buffer is currently
    /// in use by any operations.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - The registered buffer to unregister
    ///
    /// # Returns
    ///
    /// Returns the original pinned buffer on successful unregistration.
    ///
    /// # Errors
    ///
    /// - Returns `SaferRingError::NotRegistered` if the buffer is not registered
    /// - Returns `SaferRingError::BufferInFlight` if the buffer is in use
    ///
    /// # Safety
    ///
    /// This function consumes the RegisteredBuffer handle, preventing further
    /// use after unregistration.
    pub fn unregister_buffer(
        &mut self,
        registered_buffer: RegisteredBuffer,
    ) -> Result<Pin<Box<[u8]>>> {
        let index = registered_buffer.index as usize;

        // Check if the buffer exists
        if index >= self.registered_buffers.len() {
            return Err(SaferRingError::NotRegistered);
        }

        let slot = &mut self.registered_buffers[index];
        let Some(buffer) = slot.as_ref() else {
            return Err(SaferRingError::NotRegistered);
        };

        // Validate the buffer size matches
        if buffer.len() != registered_buffer.size {
            return Err(SaferRingError::NotRegistered);
        }

        // Check if the buffer is in use
        if self.buffers_in_use.contains(&registered_buffer.index) {
            return Err(SaferRingError::BufferInFlight);
        }

        // Remove and return the buffer
        let buffer = slot.take().unwrap();

        // TODO: Actually unregister with io_uring when integrated with Ring

        Ok(buffer)
    }

    /// Mark a file descriptor as in use by an operation.
    ///
    /// This is called internally when an operation is submitted using a
    /// registered file descriptor. It prevents the fd from being unregistered
    /// while the operation is in flight.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - The registered file descriptor being used
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::NotRegistered` if the fd is not registered.
    #[allow(dead_code)]
    pub(crate) fn mark_fd_in_use(&mut self, registered_fd: &RegisteredFd) -> Result<()> {
        let index = registered_fd.index as usize;

        if index >= self.registered_fds.len() || self.registered_fds[index].is_none() {
            return Err(SaferRingError::NotRegistered);
        }

        self.fds_in_use.insert(registered_fd.index);
        Ok(())
    }

    /// Mark a file descriptor as no longer in use.
    ///
    /// This is called internally when an operation using a registered file
    /// descriptor completes. It allows the fd to be unregistered again.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - The registered file descriptor no longer in use
    #[allow(dead_code)]
    pub(crate) fn mark_fd_not_in_use(&mut self, registered_fd: &RegisteredFd) {
        self.fds_in_use.remove(&registered_fd.index);
    }

    /// Mark a buffer as in use by an operation.
    ///
    /// This is called internally when an operation is submitted using a
    /// registered buffer. It prevents the buffer from being unregistered
    /// while the operation is in flight.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - The registered buffer being used
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::NotRegistered` if the buffer is not registered.
    #[allow(dead_code)]
    pub(crate) fn mark_buffer_in_use(
        &mut self,
        registered_buffer: &RegisteredBuffer,
    ) -> Result<()> {
        let index = registered_buffer.index as usize;

        if index >= self.registered_buffers.len() || self.registered_buffers[index].is_none() {
            return Err(SaferRingError::NotRegistered);
        }

        self.buffers_in_use.insert(registered_buffer.index);
        Ok(())
    }

    /// Mark a buffer as no longer in use.
    ///
    /// This is called internally when an operation using a registered buffer
    /// completes. It allows the buffer to be unregistered again.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - The registered buffer no longer in use
    #[allow(dead_code)]
    pub(crate) fn mark_buffer_not_in_use(&mut self, registered_buffer: &RegisteredBuffer) {
        self.buffers_in_use.remove(&registered_buffer.index);
    }

    /// Get the number of registered file descriptors.
    ///
    /// Returns the total number of file descriptors currently registered,
    /// including those that may be in use by operations.
    pub fn fd_count(&self) -> usize {
        self.registered_fds
            .iter()
            .filter(|slot| slot.is_some())
            .count()
    }

    /// Get the number of registered buffers.
    ///
    /// Returns the total number of buffers currently registered,
    /// including those that may be in use by operations.
    pub fn buffer_count(&self) -> usize {
        self.registered_buffers
            .iter()
            .filter(|slot| slot.is_some())
            .count()
    }

    /// Get the number of file descriptors currently in use.
    ///
    /// Returns the number of registered file descriptors that are
    /// currently being used by in-flight operations.
    pub fn fds_in_use_count(&self) -> usize {
        self.fds_in_use.len()
    }

    /// Get the number of buffers currently in use.
    ///
    /// Returns the number of registered buffers that are currently
    /// being used by in-flight operations.
    pub fn buffers_in_use_count(&self) -> usize {
        self.buffers_in_use.len()
    }

    /// Check if a file descriptor is registered.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - The registered file descriptor to check
    ///
    /// # Returns
    ///
    /// Returns true if the file descriptor is currently registered.
    pub fn is_fd_registered(&self, registered_fd: &RegisteredFd) -> bool {
        let index = registered_fd.index as usize;
        index < self.registered_fds.len()
            && self.registered_fds[index]
                .as_ref()
                .map(|(fd, _)| *fd == registered_fd.fd)
                .unwrap_or(false)
    }

    /// Check if a buffer is registered.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - The registered buffer to check
    ///
    /// # Returns
    ///
    /// Returns true if the buffer is currently registered.
    pub fn is_buffer_registered(&self, registered_buffer: &RegisteredBuffer) -> bool {
        let index = registered_buffer.index as usize;
        index < self.registered_buffers.len()
            && self.registered_buffers[index]
                .as_ref()
                .map(|buffer| buffer.len() == registered_buffer.size)
                .unwrap_or(false)
    }

    /// Get the raw file descriptor value for a registered fd.
    ///
    /// This is used internally by operations to get the actual fd value
    /// for system calls.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - The registered file descriptor
    ///
    /// # Returns
    ///
    /// Returns the raw file descriptor value if registered.
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::NotRegistered` if the fd is not registered.
    #[allow(dead_code)]
    pub(crate) fn get_raw_fd(&self, registered_fd: &RegisteredFd) -> Result<RawFd> {
        let index = registered_fd.index as usize;

        if index >= self.registered_fds.len() {
            return Err(SaferRingError::NotRegistered);
        }

        match &self.registered_fds[index] {
            Some((fd, _)) if *fd == registered_fd.fd => Ok(*fd),
            _ => Err(SaferRingError::NotRegistered),
        }
    }

    /// Get a reference to a registered buffer.
    ///
    /// This is used internally by operations to access the buffer data
    /// for I/O operations.
    ///
    /// # Arguments
    ///
    /// * `registered_buffer` - The registered buffer
    ///
    /// # Returns
    ///
    /// Returns a reference to the pinned buffer if registered.
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::NotRegistered` if the buffer is not registered.
    #[allow(dead_code)]
    pub(crate) fn get_buffer(
        &self,
        registered_buffer: &RegisteredBuffer,
    ) -> Result<&Pin<Box<[u8]>>> {
        let index = registered_buffer.index as usize;

        if index >= self.registered_buffers.len() {
            return Err(SaferRingError::NotRegistered);
        }

        match &self.registered_buffers[index] {
            Some(buffer) if buffer.len() == registered_buffer.size => Ok(buffer),
            _ => Err(SaferRingError::NotRegistered),
        }
    }

    // Fixed Files API - Performance optimization for frequently used files

    /// Register multiple files for optimized fixed-file operations.
    ///
    /// Fixed files are pre-registered with io_uring and accessed by index
    /// instead of file descriptor, providing better performance for frequently
    /// used files. This is particularly useful for applications that work with
    /// a known set of files repeatedly.
    ///
    /// # Arguments
    ///
    /// * `fds` - Vector of file descriptors to register as fixed files
    ///
    /// # Returns
    ///
    /// Returns a vector of FixedFile handles in the same order as input.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Registry;
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let fixed_files = registry.register_fixed_files(vec![0, 1, 2])?; // stdin, stdout, stderr
    /// # Ok(())
    /// # }
    /// ```
    pub fn register_fixed_files(&mut self, fds: Vec<RawFd>) -> Result<Vec<FixedFile>> {
        if fds.is_empty() {
            return Ok(Vec::new());
        }

        // Validate all file descriptors first
        for &fd in &fds {
            if fd < 0 {
                return Err(SaferRingError::Io(std::io::Error::new(
                    std::io::ErrorKind::InvalidInput,
                    format!("Invalid file descriptor: {}", fd),
                )));
            }
        }

        // Clear existing fixed files if any
        self.fixed_files.clear();
        self.fixed_files_in_use.clear();

        let mut fixed_files = Vec::new();

        for (index, &fd) in fds.iter().enumerate() {
            self.fixed_files.push(Some(fd));
            fixed_files.push(FixedFile {
                index: index as u32,
                fd,
            });
        }

        // TODO: Actually register with io_uring when integrated with Ring
        // For now, we just track the registration locally

        Ok(fixed_files)
    }

    /// Unregister all fixed files.
    ///
    /// This operation will fail if any fixed file is currently in use.
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::BufferInFlight` if any fixed file is in use.
    pub fn unregister_fixed_files(&mut self) -> Result<()> {
        if !self.fixed_files_in_use.is_empty() {
            return Err(SaferRingError::BufferInFlight);
        }

        self.fixed_files.clear();
        // TODO: Actually unregister with io_uring when integrated with Ring

        Ok(())
    }

    /// Get the number of fixed files registered.
    pub fn fixed_file_count(&self) -> usize {
        self.fixed_files
            .iter()
            .filter(|slot| slot.is_some())
            .count()
    }

    /// Get the number of fixed files currently in use.
    pub fn fixed_files_in_use_count(&self) -> usize {
        self.fixed_files_in_use.len()
    }

    // Registered Buffer Slots API - For kernel buffer selection optimization

    /// Register multiple buffer slots for kernel buffer selection.
    ///
    /// Registered buffer slots are pre-allocated buffers that the kernel
    /// can select from during I/O operations. This provides the best performance
    /// for high-throughput applications by eliminating the need to specify
    /// buffer addresses in each operation.
    ///
    /// # Arguments
    ///
    /// * `buffers` - Vector of owned buffers to register as selectable slots
    ///
    /// # Returns
    ///
    /// Returns a vector of RegisteredBufferSlot handles.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Registry, OwnedBuffer};
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let buffers = vec![
    ///     OwnedBuffer::new(4096),
    ///     OwnedBuffer::new(4096),
    ///     OwnedBuffer::new(4096),
    /// ];
    /// let buffer_slots = registry.register_buffer_slots(buffers)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn register_buffer_slots(
        &mut self,
        buffers: Vec<OwnedBuffer>,
    ) -> Result<Vec<RegisteredBufferSlot>> {
        if buffers.is_empty() {
            return Ok(Vec::new());
        }

        // Clear existing buffer slots if any
        self.registered_buffer_slots.clear();
        self.buffer_slots_in_use.clear();

        let mut buffer_slots = Vec::new();

        for (index, buffer) in buffers.into_iter().enumerate() {
            let size = buffer.size();
            self.registered_buffer_slots.push(Some(buffer));
            buffer_slots.push(RegisteredBufferSlot {
                index: index as u32,
                size,
                in_use: false,
            });
        }

        // TODO: Actually register with io_uring when integrated with Ring
        // For now, we just track the registration locally

        Ok(buffer_slots)
    }

    /// Unregister all buffer slots and return ownership of the buffers.
    ///
    /// This operation will fail if any buffer slot is currently in use.
    ///
    /// # Returns
    ///
    /// Returns the original owned buffers on successful unregistration.
    ///
    /// # Errors
    ///
    /// Returns `SaferRingError::BufferInFlight` if any buffer slot is in use.
    pub fn unregister_buffer_slots(&mut self) -> Result<Vec<OwnedBuffer>> {
        if !self.buffer_slots_in_use.is_empty() {
            return Err(SaferRingError::BufferInFlight);
        }

        let buffers = self.registered_buffer_slots.drain(..).flatten().collect();

        // TODO: Actually unregister with io_uring when integrated with Ring

        Ok(buffers)
    }

    /// Get the number of buffer slots registered.
    pub fn buffer_slot_count(&self) -> usize {
        self.registered_buffer_slots
            .iter()
            .filter(|slot| slot.is_some())
            .count()
    }

    /// Get the number of buffer slots currently in use.
    pub fn buffer_slots_in_use_count(&self) -> usize {
        self.buffer_slots_in_use.len()
    }

    // Internal methods for tracking usage of fixed files and buffer slots

    /// Mark a fixed file as in use by an operation.
    #[allow(dead_code)]
    pub(crate) fn mark_fixed_file_in_use(&mut self, fixed_file: &FixedFile) -> Result<()> {
        let index = fixed_file.index as usize;

        if index >= self.fixed_files.len() || self.fixed_files[index].is_none() {
            return Err(SaferRingError::NotRegistered);
        }

        self.fixed_files_in_use.insert(fixed_file.index);
        Ok(())
    }

    /// Mark a fixed file as no longer in use.
    #[allow(dead_code)]
    pub(crate) fn mark_fixed_file_not_in_use(&mut self, fixed_file: &FixedFile) {
        self.fixed_files_in_use.remove(&fixed_file.index);
    }

    /// Mark a buffer slot as in use by an operation.
    #[allow(dead_code)]
    pub(crate) fn mark_buffer_slot_in_use(
        &mut self,
        buffer_slot: &RegisteredBufferSlot,
    ) -> Result<()> {
        let index = buffer_slot.index as usize;

        if index >= self.registered_buffer_slots.len()
            || self.registered_buffer_slots[index].is_none()
        {
            return Err(SaferRingError::NotRegistered);
        }

        self.buffer_slots_in_use.insert(buffer_slot.index);
        Ok(())
    }

    /// Mark a buffer slot as no longer in use.
    #[allow(dead_code)]
    pub(crate) fn mark_buffer_slot_not_in_use(&mut self, buffer_slot: &RegisteredBufferSlot) {
        self.buffer_slots_in_use.remove(&buffer_slot.index);
    }

    /// Get the raw file descriptor for a fixed file.
    #[allow(dead_code)]
    pub(crate) fn get_fixed_file_fd(&self, fixed_file: &FixedFile) -> Result<RawFd> {
        let index = fixed_file.index as usize;

        if index >= self.fixed_files.len() {
            return Err(SaferRingError::NotRegistered);
        }

        match &self.fixed_files[index] {
            Some(fd) if *fd == fixed_file.fd => Ok(*fd),
            _ => Err(SaferRingError::NotRegistered),
        }
    }

    /// Get a reference to a buffer in a registered slot.
    #[allow(dead_code)]
    pub(crate) fn get_buffer_slot(
        &self,
        buffer_slot: &RegisteredBufferSlot,
    ) -> Result<&OwnedBuffer> {
        let index = buffer_slot.index as usize;

        if index >= self.registered_buffer_slots.len() {
            return Err(SaferRingError::NotRegistered);
        }

        match &self.registered_buffer_slots[index] {
            Some(buffer) if buffer.size() == buffer_slot.size => Ok(buffer),
            _ => Err(SaferRingError::NotRegistered),
        }
    }
}

impl<'ring> Drop for Registry<'ring> {
    /// Ensure no resources are in use when the registry is dropped.
    ///
    /// This prevents resource leaks and ensures that all operations have
    /// completed before the registry is destroyed.
    fn drop(&mut self) {
        let total_in_use = self.fds_in_use.len()
            + self.buffers_in_use.len()
            + self.fixed_files_in_use.len()
            + self.buffer_slots_in_use.len();

        if total_in_use > 0 {
            panic!(
                "Registry dropped with resources in use: {} fds, {} buffers, {} fixed_files, {} buffer_slots",
                self.fds_in_use.len(),
                self.buffers_in_use.len(),
                self.fixed_files_in_use.len(),
                self.buffer_slots_in_use.len()
            );
        }
    }
}

impl RegisteredFd {
    /// Get the index of this registered file descriptor.
    ///
    /// The index is used internally by io_uring to reference the registered
    /// file descriptor efficiently.
    pub fn index(&self) -> u32 {
        self.index
    }

    /// Get the raw file descriptor value.
    ///
    /// This returns the original file descriptor that was registered.
    /// Note that this should generally not be used directly - use the
    /// registered handle in operations instead.
    pub fn raw_fd(&self) -> RawFd {
        self.fd
    }
}

impl RegisteredBuffer {
    /// Get the index of this registered buffer.
    ///
    /// The index is used internally by io_uring to reference the registered
    /// buffer efficiently.
    pub fn index(&self) -> u32 {
        self.index
    }

    /// Get the size of this registered buffer.
    ///
    /// Returns the size in bytes of the registered buffer.
    pub fn size(&self) -> usize {
        self.size
    }
}

/// Fixed file descriptor with optimized kernel access.
///
/// Fixed files are pre-registered with the kernel and accessed by index
/// instead of file descriptor, providing better performance for frequently
/// used files.
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct FixedFile {
    /// Index in the fixed file table
    index: u32,
    /// Original file descriptor for validation
    fd: RawFd,
}

/// Registered buffer slot with optimized kernel access.
///
/// Registered buffers are pre-allocated and registered with the kernel,
/// allowing operations to reference buffers by index instead of pointer
/// for better performance.
#[derive(Debug)]
pub struct RegisteredBufferSlot {
    /// Index in the registered buffer table
    index: u32,
    /// Size of the buffer slot
    size: usize,
    /// Whether this slot is currently in use
    in_use: bool,
}

impl FixedFile {
    /// Get the index of this fixed file.
    pub fn index(&self) -> u32 {
        self.index
    }

    /// Get the original file descriptor.
    pub fn raw_fd(&self) -> RawFd {
        self.fd
    }
}

impl RegisteredBufferSlot {
    /// Get the index of this buffer slot.
    pub fn index(&self) -> u32 {
        self.index
    }

    /// Get the size of this buffer slot.
    pub fn size(&self) -> usize {
        self.size
    }

    /// Check if this slot is currently in use.
    pub fn is_in_use(&self) -> bool {
        self.in_use
    }
}

// RegisteredFd and RegisteredBuffer are now Send/Sync for better ergonomics
// The safety is maintained through the registry's lifetime management
</file>

<file path="registry/tests.rs">
//! Tests for registry functionality.

use super::*;
use std::pin::Pin;

/// Test basic registry creation and properties
mod basic_functionality {
    use super::*;

    #[test]
    fn new_registry_is_empty() {
        let registry = Registry::new();
        assert_eq!(registry.fd_count(), 0);
        assert_eq!(registry.buffer_count(), 0);
        assert_eq!(registry.fds_in_use_count(), 0);
        assert_eq!(registry.buffers_in_use_count(), 0);
    }

    #[test]
    fn default_registry_is_empty() {
        let registry = Registry::default();
        assert_eq!(registry.fd_count(), 0);
        assert_eq!(registry.buffer_count(), 0);
    }
}

/// Test file descriptor registration
mod fd_registration {
    use super::*;

    #[test]
    fn register_valid_fd() {
        let mut registry = Registry::new();
        let result = registry.register_fd(0);
        assert!(result.is_ok());

        let registered_fd = result.unwrap();
        assert_eq!(registered_fd.index(), 0);
        assert_eq!(registered_fd.raw_fd(), 0);
        assert_eq!(registry.fd_count(), 1);
    }

    #[test]
    fn register_multiple_fds() {
        let mut registry = Registry::new();

        let fd1 = registry.register_fd(0).unwrap();
        let fd2 = registry.register_fd(1).unwrap();
        let fd3 = registry.register_fd(2).unwrap();

        assert_eq!(fd1.index(), 0);
        assert_eq!(fd2.index(), 1);
        assert_eq!(fd3.index(), 2);
        assert_eq!(registry.fd_count(), 3);
    }

    #[test]
    fn register_negative_fd_fails() {
        let mut registry = Registry::new();
        let result = registry.register_fd(-1);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::Io(e) => {
                assert_eq!(e.kind(), std::io::ErrorKind::InvalidInput);
            }
            _ => panic!("Expected Io error"),
        }
    }

    #[test]
    fn is_fd_registered_works() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();

        assert!(registry.is_fd_registered(&registered_fd));
        assert_eq!(registry.fd_count(), 1);
    }

    #[test]
    fn get_raw_fd_works() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(42).unwrap();

        let raw_fd = registry.get_raw_fd(&registered_fd).unwrap();
        assert_eq!(raw_fd, 42);
    }
}

/// Test buffer registration
mod buffer_registration {
    use super::*;

    #[test]
    fn register_valid_buffer() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let size = buffer.len();

        let result = registry.register_buffer(buffer);
        assert!(result.is_ok());

        let registered_buffer = result.unwrap();
        assert_eq!(registered_buffer.index(), 0);
        assert_eq!(registered_buffer.size(), size);
        assert_eq!(registry.buffer_count(), 1);
    }

    #[test]
    fn register_multiple_buffers() {
        let mut registry = Registry::new();

        let buffer1 = Pin::new(Box::new([0u8; 512]));
        let buffer2 = Pin::new(Box::new([0u8; 1024]));
        let buffer3 = Pin::new(Box::new([0u8; 2048]));

        let reg1 = registry.register_buffer(buffer1).unwrap();
        let reg2 = registry.register_buffer(buffer2).unwrap();
        let reg3 = registry.register_buffer(buffer3).unwrap();

        assert_eq!(reg1.index(), 0);
        assert_eq!(reg1.size(), 512);
        assert_eq!(reg2.index(), 1);
        assert_eq!(reg2.size(), 1024);
        assert_eq!(reg3.index(), 2);
        assert_eq!(reg3.size(), 2048);
        assert_eq!(registry.buffer_count(), 3);
    }

    #[test]
    fn register_empty_buffer_fails() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([]));

        let result = registry.register_buffer(buffer);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::Io(e) => {
                assert_eq!(e.kind(), std::io::ErrorKind::InvalidInput);
            }
            _ => panic!("Expected Io error"),
        }
    }

    #[test]
    fn is_buffer_registered_works() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        assert!(registry.is_buffer_registered(&registered_buffer));
        assert_eq!(registry.buffer_count(), 1);
    }

    #[test]
    fn get_buffer_works() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([42u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        let buffer_ref = registry.get_buffer(&registered_buffer).unwrap();
        assert_eq!(buffer_ref.len(), 1024);
        assert_eq!(buffer_ref[0], 42);
    }
}

/// Test unregistration functionality
mod unregistration {
    use super::*;

    #[test]
    fn unregister_fd_success() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();

        assert_eq!(registry.fd_count(), 1);
        assert!(registry.is_fd_registered(&registered_fd));

        let result = registry.unregister_fd(registered_fd);
        assert!(result.is_ok());
        assert_eq!(registry.fd_count(), 0);
    }

    #[test]
    fn unregister_buffer_success() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([42u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        assert_eq!(registry.buffer_count(), 1);
        assert!(registry.is_buffer_registered(&registered_buffer));

        let result = registry.unregister_buffer(registered_buffer);
        assert!(result.is_ok());

        let returned_buffer = result.unwrap();
        assert_eq!(returned_buffer.len(), 1024);
        assert_eq!(returned_buffer[0], 42);
        assert_eq!(registry.buffer_count(), 0);
    }

    #[test]
    fn unregister_fd_in_use_fails() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();

        // Mark as in use
        registry.mark_fd_in_use(&registered_fd).unwrap();
        assert_eq!(registry.fds_in_use_count(), 1);

        // Try to unregister - should fail
        let result = registry.unregister_fd(registered_fd);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::BufferInFlight => {}
            _ => panic!("Expected BufferInFlight error"),
        }

        // Clean up for drop safety - mark as not in use
        // We need to recreate the RegisteredFd since it was consumed
        let registered_fd = RegisteredFd { index: 0, fd: 5 };
        registry.mark_fd_not_in_use(&registered_fd);
    }

    #[test]
    fn unregister_buffer_in_use_fails() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        // Mark as in use
        registry.mark_buffer_in_use(&registered_buffer).unwrap();
        assert_eq!(registry.buffers_in_use_count(), 1);

        // Try to unregister - should fail
        let result = registry.unregister_buffer(registered_buffer);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::BufferInFlight => {}
            _ => panic!("Expected BufferInFlight error"),
        }

        // Clean up for drop safety - mark as not in use
        // We need to recreate the RegisteredBuffer since it was consumed
        let registered_buffer = RegisteredBuffer {
            index: 0,
            size: 1024,
        };
        registry.mark_buffer_not_in_use(&registered_buffer);
    }

    #[test]
    fn unregister_nonexistent_fd_fails() {
        let mut registry = Registry::new();

        // Create a fake registered fd
        let fake_fd = RegisteredFd { index: 999, fd: 5 };

        let result = registry.unregister_fd(fake_fd);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::NotRegistered => {}
            _ => panic!("Expected NotRegistered error"),
        }
    }

    #[test]
    fn unregister_nonexistent_buffer_fails() {
        let mut registry = Registry::new();

        // Create a fake registered buffer
        let fake_buffer = RegisteredBuffer {
            index: 999,
            size: 1024,
        };

        let result = registry.unregister_buffer(fake_buffer);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::NotRegistered => {}
            _ => panic!("Expected NotRegistered error"),
        }
    }
}

/// Test usage tracking
mod usage_tracking {
    use super::*;

    #[test]
    fn mark_fd_in_use_works() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();

        assert_eq!(registry.fds_in_use_count(), 0);

        registry.mark_fd_in_use(&registered_fd).unwrap();
        assert_eq!(registry.fds_in_use_count(), 1);

        registry.mark_fd_not_in_use(&registered_fd);
        assert_eq!(registry.fds_in_use_count(), 0);
    }

    #[test]
    fn mark_buffer_in_use_works() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        assert_eq!(registry.buffers_in_use_count(), 0);

        registry.mark_buffer_in_use(&registered_buffer).unwrap();
        assert_eq!(registry.buffers_in_use_count(), 1);

        registry.mark_buffer_not_in_use(&registered_buffer);
        assert_eq!(registry.buffers_in_use_count(), 0);
    }

    #[test]
    fn mark_nonexistent_fd_in_use_fails() {
        let mut registry = Registry::new();

        let fake_fd = RegisteredFd { index: 999, fd: 5 };

        let result = registry.mark_fd_in_use(&fake_fd);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::NotRegistered => {}
            _ => panic!("Expected NotRegistered error"),
        }
    }

    #[test]
    fn mark_nonexistent_buffer_in_use_fails() {
        let mut registry = Registry::new();

        let fake_buffer = RegisteredBuffer {
            index: 999,
            size: 1024,
        };

        let result = registry.mark_buffer_in_use(&fake_buffer);
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::NotRegistered => {}
            _ => panic!("Expected NotRegistered error"),
        }
    }
}

/// Test slot reuse after unregistration
mod slot_reuse {
    use super::*;

    #[test]
    fn fd_slot_reuse_works() {
        let mut registry = Registry::new();

        // Register and unregister an fd
        let fd1 = registry.register_fd(5).unwrap();
        assert_eq!(fd1.index(), 0);
        registry.unregister_fd(fd1).unwrap();

        // Register another fd - should reuse the slot
        let fd2 = registry.register_fd(10).unwrap();
        assert_eq!(fd2.index(), 0);
        assert_eq!(fd2.raw_fd(), 10);
    }

    #[test]
    fn buffer_slot_reuse_works() {
        let mut registry = Registry::new();

        // Register and unregister a buffer
        let buffer1 = Pin::new(Box::new([1u8; 512]));
        let reg1 = registry.register_buffer(buffer1).unwrap();
        assert_eq!(reg1.index(), 0);
        let _returned = registry.unregister_buffer(reg1).unwrap();

        // Register another buffer - should reuse the slot
        let buffer2 = Pin::new(Box::new([2u8; 1024]));
        let reg2 = registry.register_buffer(buffer2).unwrap();
        assert_eq!(reg2.index(), 0);
        assert_eq!(reg2.size(), 1024);
    }

    #[test]
    fn mixed_registration_and_slot_reuse() {
        let mut registry = Registry::new();

        // Register multiple resources
        let fd1 = registry.register_fd(1).unwrap();
        let fd2 = registry.register_fd(2).unwrap();
        let buffer1 = Pin::new(Box::new([0u8; 512]));
        let reg1 = registry.register_buffer(buffer1).unwrap();

        assert_eq!(fd1.index(), 0);
        assert_eq!(fd2.index(), 1);
        assert_eq!(reg1.index(), 0);

        // Unregister the first fd
        registry.unregister_fd(fd1).unwrap();

        // Register a new fd - should reuse slot 0
        let fd3 = registry.register_fd(3).unwrap();
        assert_eq!(fd3.index(), 0);
        assert_eq!(fd3.raw_fd(), 3);

        // Other resources should be unaffected
        assert!(registry.is_fd_registered(&fd2));
        assert!(registry.is_buffer_registered(&reg1));
    }
}

/// Test registry lifecycle and safety
mod lifecycle_safety {
    use super::*;

    #[test]
    #[should_panic(expected = "Registry dropped with resources in use")]
    fn drop_with_fds_in_use_panics() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();
        registry.mark_fd_in_use(&registered_fd).unwrap();

        // Registry should panic on drop because fd is in use
        drop(registry);
    }

    #[test]
    #[should_panic(expected = "Registry dropped with resources in use")]
    fn drop_with_buffers_in_use_panics() {
        let mut registry = Registry::new();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();
        registry.mark_buffer_in_use(&registered_buffer).unwrap();

        // Registry should panic on drop because buffer is in use
        drop(registry);
    }

    #[test]
    fn drop_with_no_resources_in_use_succeeds() {
        let mut registry = Registry::new();
        let registered_fd = registry.register_fd(5).unwrap();
        let buffer = Pin::new(Box::new([0u8; 1024]));
        let registered_buffer = registry.register_buffer(buffer).unwrap();

        // Mark as in use then mark as not in use
        registry.mark_fd_in_use(&registered_fd).unwrap();
        registry.mark_buffer_in_use(&registered_buffer).unwrap();
        registry.mark_fd_not_in_use(&registered_fd);
        registry.mark_buffer_not_in_use(&registered_buffer);

        // Should drop successfully
        drop(registry);
    }
}

/// Test compile-time safety properties
mod compile_time_safety {
    // Unused imports removed

    // RegisteredFd and RegisteredBuffer are now Send/Sync for better ergonomics
    // The safety is maintained through the registry's lifetime management
}
</file>

<file path="ring/batch/config.rs">
//! Configuration for batch submission behavior.

/// Configuration for batch submission behavior.
///
/// Controls how batches are processed and submitted to the kernel, allowing
/// fine-tuning of performance and error handling characteristics. Different
/// configurations are suitable for different use cases and performance requirements.
///
/// # Fields
///
/// - `fail_fast`: Controls whether to stop processing when an operation fails
/// - `max_batch_size`: Maximum number of operations in a single batch
/// - `enforce_dependencies`: Whether to respect operation dependency ordering
///
/// # Examples
///
/// ## Default Configuration
/// ```rust
/// # use safer_ring::ring::BatchConfig;
/// let config = BatchConfig::default();
/// assert!(!config.fail_fast);
/// assert_eq!(config.max_batch_size, 256);
/// assert!(config.enforce_dependencies);
/// ```
///
/// ## High-throughput Configuration
/// ```rust
/// # use safer_ring::ring::BatchConfig;
/// let config = BatchConfig {
///     fail_fast: false,           // Continue on errors for maximum throughput
///     max_batch_size: 512,        // Larger batches for efficiency
///     enforce_dependencies: false, // Skip dependency checks for speed
/// };
/// ```
///
/// ## Strict Error Handling Configuration
/// ```rust
/// # use safer_ring::ring::BatchConfig;
/// let config = BatchConfig {
///     fail_fast: true,            // Stop immediately on any error
///     max_batch_size: 64,         // Smaller batches for quick error detection
///     enforce_dependencies: true,  // Strict ordering guarantees
/// };
/// ```
#[derive(Debug, Clone)]
pub struct BatchConfig {
    /// Whether to stop processing when an operation fails.
    ///
    /// - `true`: Stop immediately when any operation fails (fail-fast mode)
    /// - `false`: Continue processing remaining operations even if some fail
    pub fail_fast: bool,

    /// Maximum number of operations to submit in a single batch.
    ///
    /// Larger batch sizes can improve throughput by reducing syscall overhead,
    /// but may increase latency and memory usage. The optimal size depends on
    /// your specific workload and system characteristics.
    pub max_batch_size: usize,

    /// Whether to enforce dependency ordering between operations.
    ///
    /// - `true`: Operations with dependencies are submitted in the correct order
    /// - `false`: Dependency checking is skipped for maximum performance
    ///
    /// Disabling this can improve performance but may lead to incorrect results
    /// if operations have data dependencies.
    pub enforce_dependencies: bool,
}

impl Default for BatchConfig {
    fn default() -> Self {
        Self {
            fail_fast: false,
            max_batch_size: 256, // Reasonable default for most use cases
            enforce_dependencies: true,
        }
    }
}
</file>

<file path="ring/batch/core.rs">
//! Core batch operations and management.

use super::validation::DependencyValidator;
use crate::error::{Result, SaferRingError};
use crate::operation::{Building, Operation};
use std::collections::HashMap;

/// A batch of operations to be submitted together.
///
/// Batches allow efficient submission of multiple operations with a single
/// kernel syscall, reducing overhead for high-throughput applications.
/// Operations in a batch can have dependencies and ordering constraints.
///
/// # Example
///
/// ```rust,no_run
/// # use safer_ring::{Ring, Operation, PinnedBuffer, Batch};
/// # use std::pin::Pin;
/// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
/// let ring = Ring::new(32)?;
/// let mut buffer1 = PinnedBuffer::with_capacity(1024);
/// let mut buffer2 = PinnedBuffer::with_capacity(1024);
///
/// let mut batch = Batch::new();
/// batch.add_operation(Operation::read().fd(0).buffer(buffer1.as_mut_slice()))?;
/// batch.add_operation(Operation::write().fd(1).buffer(buffer2.as_mut_slice()))?;
///
/// let results = ring.submit_batch(batch).await?;
/// println!("Batch completed with {} results", results.len());
/// # Ok(())
/// # }
/// ```
#[derive(Debug)]
pub struct Batch<'ring, 'buf> {
    operations: Vec<BatchOperation<'ring, 'buf>>,
    dependencies: HashMap<usize, Vec<usize>>, // operation_index -> depends_on_indices
    max_operations: usize,
}

/// A single operation within a batch.
#[derive(Debug)]
struct BatchOperation<'ring, 'buf> {
    operation: Operation<'ring, 'buf, Building>,
}

impl<'ring, 'buf> Batch<'ring, 'buf> {
    /// Create a new empty batch.
    ///
    /// # Example
    ///
    /// ```rust
    /// # use safer_ring::Batch;
    /// let batch = Batch::new();
    /// assert_eq!(batch.len(), 0);
    /// ```
    pub fn new() -> Self {
        Self::with_capacity(16) // Default capacity
    }

    /// Create a new batch with the specified initial capacity.
    ///
    /// Pre-allocating capacity can improve performance when the number
    /// of operations is known in advance.
    ///
    /// # Arguments
    ///
    /// * `capacity` - Initial capacity for the batch
    ///
    /// # Example
    ///
    /// ```rust
    /// # use safer_ring::Batch;
    /// let batch = Batch::with_capacity(100);
    /// assert_eq!(batch.len(), 0);
    /// ```
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            operations: Vec::with_capacity(capacity),
            dependencies: HashMap::new(),
            max_operations: 1024, // Reasonable upper limit
        }
    }

    /// Add an operation to the batch.
    ///
    /// Operations are added in the order they should be submitted.
    /// Returns the index of the added operation for use in dependency tracking.
    ///
    /// # Arguments
    ///
    /// * `operation` - Operation in Building state to add to the batch
    ///
    /// # Returns
    ///
    /// Returns the index of the operation in the batch.
    ///
    /// # Errors
    ///
    /// Returns an error if the batch is full or the operation is invalid.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Batch, Operation, PinnedBuffer};
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut batch = Batch::new();
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// let index = batch.add_operation(
    ///     Operation::read().fd(0).buffer(buffer.as_mut_slice())
    /// )?;
    /// assert_eq!(index, 0);
    /// # Ok(())
    /// # }
    /// ```
    pub fn add_operation(&mut self, operation: Operation<'ring, 'buf, Building>) -> Result<usize> {
        if self.operations.len() >= self.max_operations {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!("Batch is full (max {} operations)", self.max_operations),
            )));
        }

        // Validate the operation before adding
        operation.validate().map_err(|msg| {
            SaferRingError::Io(std::io::Error::new(std::io::ErrorKind::InvalidInput, msg))
        })?;

        let index = self.operations.len();
        self.operations.push(BatchOperation { operation });

        Ok(index)
    }

    /// Add an operation with user-provided data.
    ///
    /// The user data can be used to identify operations in the results.
    ///
    /// # Arguments
    ///
    /// * `operation` - Operation in Building state to add to the batch
    /// * `user_data` - User-provided identifier for this operation
    ///
    /// # Returns
    ///
    /// Returns the index of the operation in the batch.
    ///
    /// # Errors
    ///
    /// Returns an error if the batch is full or the operation is invalid.
    pub fn add_operation_with_data(
        &mut self,
        operation: Operation<'ring, 'buf, Building>,
        _user_data: u64,
    ) -> Result<usize> {
        if self.operations.len() >= self.max_operations {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!("Batch is full (max {} operations)", self.max_operations),
            )));
        }

        // Validate the operation before adding
        operation.validate().map_err(|msg| {
            SaferRingError::Io(std::io::Error::new(std::io::ErrorKind::InvalidInput, msg))
        })?;

        let index = self.operations.len();
        self.operations.push(BatchOperation { operation });

        Ok(index)
    }

    /// Add a dependency between operations.
    ///
    /// The dependent operation will not be submitted until all its dependencies
    /// have completed successfully. If any dependency fails, the dependent
    /// operation will be cancelled.
    ///
    /// # Arguments
    ///
    /// * `dependent` - Index of the operation that depends on others
    /// * `dependency` - Index of the operation that must complete first
    ///
    /// # Errors
    ///
    /// Returns an error if either index is invalid or if the dependency
    /// would create a cycle.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Batch, Operation, PinnedBuffer};
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut batch = Batch::new();
    /// let mut buffer1 = PinnedBuffer::with_capacity(1024);
    /// let mut buffer2 = PinnedBuffer::with_capacity(1024);
    ///
    /// let read_idx = batch.add_operation(
    ///     Operation::read().fd(0).buffer(buffer1.as_mut_slice())
    /// )?;
    /// let write_idx = batch.add_operation(
    ///     Operation::write().fd(1).buffer(buffer2.as_mut_slice())
    /// )?;
    ///
    /// // Write depends on read completing first
    /// batch.add_dependency(write_idx, read_idx)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn add_dependency(&mut self, dependent: usize, dependency: usize) -> Result<()> {
        if dependent >= self.operations.len() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!("Dependent operation index {} is out of bounds", dependent),
            )));
        }

        if dependency >= self.operations.len() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!("Dependency operation index {} is out of bounds", dependency),
            )));
        }

        if dependent == dependency {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation cannot depend on itself",
            )));
        }

        // Check for cycles (simple check - could be more sophisticated)
        if DependencyValidator::would_create_cycle(&self.dependencies, dependent, dependency) {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Dependency would create a cycle",
            )));
        }

        self.dependencies
            .entry(dependent)
            .or_default()
            .push(dependency);

        Ok(())
    }

    /// Get the number of operations in the batch.
    pub fn len(&self) -> usize {
        self.operations.len()
    }

    /// Check if the batch is empty.
    pub fn is_empty(&self) -> bool {
        self.operations.is_empty()
    }

    /// Get the maximum number of operations this batch can hold.
    pub fn max_operations(&self) -> usize {
        self.max_operations
    }

    /// Check if the batch has circular dependencies.
    ///
    /// This method performs a topological sort to detect cycles in the
    /// dependency graph.
    pub fn has_circular_dependencies(&self) -> bool {
        DependencyValidator::has_circular_dependencies(&self.dependencies)
    }

    /// Clear all operations and dependencies from the batch.
    pub fn clear(&mut self) {
        self.operations.clear();
        self.dependencies.clear();
    }

    /// Get the operations in dependency order.
    ///
    /// Returns operations sorted such that dependencies come before dependents.
    /// Operations with no dependencies come first.
    pub(crate) fn dependency_order(&self) -> Result<Vec<usize>> {
        DependencyValidator::dependency_order(&self.dependencies, self.operations.len())
    }

    /// Extract operations and dependencies for submission.
    ///
    /// This method consumes the batch and returns the operations and dependencies
    /// in a format suitable for submission.
    pub(crate) fn into_operations_and_dependencies(
        self,
    ) -> (
        Vec<Operation<'ring, 'buf, Building>>,
        HashMap<usize, Vec<usize>>,
    ) {
        let operations = self
            .operations
            .into_iter()
            .map(|batch_op| batch_op.operation)
            .collect();

        (operations, self.dependencies)
    }
}

impl<'ring, 'buf> Default for Batch<'ring, 'buf> {
    fn default() -> Self {
        Self::new()
    }
}
</file>

<file path="ring/batch/mod.rs">
//! Batch operation support for efficient submission of multiple operations.
//!
//! This module provides functionality to submit multiple operations efficiently
//! in a single batch, with support for operation dependencies and proper error
//! handling for partial batch failures.
//!
//! # Module Organization
//!
//! - `core` - Main Batch struct and core operations
//! - `result` - BatchResult and OperationResult types  
//! - `config` - BatchConfig configuration type
//! - `validation` - Dependency validation and cycle detection

// Internal modules

/// Configuration types for controlling batch submission behavior.
///
/// Contains `BatchConfig` for fine-tuning how batches are processed,
/// including error handling strategies, size limits, and dependency enforcement.
pub mod config;

/// Core batch functionality and the main `Batch` type.
///
/// Contains the `Batch` struct for collecting operations and managing
/// dependencies, along with methods for adding operations and configuring
/// batch behavior.
pub mod core;

/// Result types for batch operations.
///
/// Contains `BatchResult` and `OperationResult` types that represent
/// the outcomes of batch submissions, including success/failure information
/// and detailed per-operation results.
pub mod result;
mod validation;

// Re-export public types for backward compatibility
pub use config::BatchConfig;
pub use core::Batch;
pub use result::{BatchResult, OperationResult};

#[cfg(test)]
mod tests {
    use super::*;
    use crate::operation::Operation;
    use crate::PinnedBuffer;

    #[test]
    fn new_batch_is_empty() {
        let batch: Batch<'_, '_> = Batch::new();
        assert_eq!(batch.len(), 0);
        assert!(batch.is_empty());
    }

    #[test]
    fn batch_with_capacity() {
        let batch: Batch<'_, '_> = Batch::with_capacity(100);
        assert_eq!(batch.len(), 0);
        assert!(batch.is_empty());
    }

    #[test]
    fn add_operation() {
        let mut batch = Batch::new();
        let mut buffer = PinnedBuffer::with_capacity(1024);

        let operation = Operation::read().fd(0).buffer(buffer.as_mut_slice());
        let index = batch.add_operation(operation).unwrap();

        assert_eq!(index, 0);
        assert_eq!(batch.len(), 1);
        assert!(!batch.is_empty());
    }

    #[test]
    fn add_multiple_operations() {
        let mut batch = Batch::new();
        let mut buffer1 = PinnedBuffer::with_capacity(1024);
        let mut buffer2 = PinnedBuffer::with_capacity(1024);

        let op1 = Operation::read().fd(0).buffer(buffer1.as_mut_slice());
        let op2 = Operation::write().fd(1).buffer(buffer2.as_mut_slice());

        let idx1 = batch.add_operation(op1).unwrap();
        let idx2 = batch.add_operation(op2).unwrap();

        assert_eq!(idx1, 0);
        assert_eq!(idx2, 1);
        assert_eq!(batch.len(), 2);
    }

    #[test]
    fn add_operation_with_user_data() {
        let mut batch = Batch::new();
        let mut buffer = PinnedBuffer::with_capacity(1024);

        let operation = Operation::read().fd(0).buffer(buffer.as_mut_slice());
        let index = batch.add_operation_with_data(operation, 42).unwrap();

        assert_eq!(index, 0);
        assert_eq!(batch.len(), 1);
    }

    #[test]
    fn add_dependency() {
        let mut batch = Batch::new();
        let mut buffer1 = PinnedBuffer::with_capacity(1024);
        let mut buffer2 = PinnedBuffer::with_capacity(1024);

        let op1 = Operation::read().fd(0).buffer(buffer1.as_mut_slice());
        let op2 = Operation::write().fd(1).buffer(buffer2.as_mut_slice());

        let idx1 = batch.add_operation(op1).unwrap();
        let idx2 = batch.add_operation(op2).unwrap();

        batch.add_dependency(idx2, idx1).unwrap();
    }

    #[test]
    fn self_dependency_error() {
        let mut batch = Batch::new();
        let mut buffer = PinnedBuffer::with_capacity(1024);

        let operation = Operation::read().fd(0).buffer(buffer.as_mut_slice());
        let index = batch.add_operation(operation).unwrap();

        let result = batch.add_dependency(index, index);
        assert!(result.is_err());
    }

    #[test]
    fn invalid_dependency_indices() {
        let mut batch = Batch::new();
        let mut buffer = PinnedBuffer::with_capacity(1024);

        let operation = Operation::read().fd(0).buffer(buffer.as_mut_slice());
        let _index = batch.add_operation(operation).unwrap();

        // Test invalid dependent index
        let result = batch.add_dependency(10, 0);
        assert!(result.is_err());

        // Test invalid dependency index
        let result = batch.add_dependency(0, 10);
        assert!(result.is_err());
    }

    #[test]
    fn clear_batch() {
        let mut batch = Batch::new();
        let mut buffer = PinnedBuffer::with_capacity(1024);

        let operation = Operation::read().fd(0).buffer(buffer.as_mut_slice());
        let _index = batch.add_operation(operation).unwrap();

        assert_eq!(batch.len(), 1);

        batch.clear();
        assert_eq!(batch.len(), 0);
        assert!(batch.is_empty());
    }

    #[test]
    fn batch_result_creation() {
        let results = vec![
            OperationResult::Success(100),
            OperationResult::Error("File not found".to_string()),
            OperationResult::Cancelled,
        ];

        let batch_result = BatchResult::new(results);
        assert_eq!(batch_result.successful_count, 1);
        assert_eq!(batch_result.failed_count, 1);
        assert!(!batch_result.all_succeeded());
        assert!(batch_result.any_failed());
    }

    #[test]
    fn operation_result_methods() {
        let success = OperationResult::Success(42);
        assert!(success.is_success());
        assert!(!success.is_error());
        assert!(!success.is_cancelled());
        assert_eq!(success.success_value(), Some(42));
        assert!(success.error().is_none());

        let error = OperationResult::Error("Not found".to_string());
        assert!(!error.is_success());
        assert!(error.is_error());
        assert!(!error.is_cancelled());
        assert_eq!(error.success_value(), None);
        assert!(error.error().is_some());

        let cancelled = OperationResult::Cancelled;
        assert!(!cancelled.is_success());
        assert!(!cancelled.is_error());
        assert!(cancelled.is_cancelled());
        assert_eq!(cancelled.success_value(), None);
        assert!(cancelled.error().is_none());
    }

    #[test]
    fn dependency_order_simple() {
        let mut batch = Batch::new();
        let mut buffer1 = PinnedBuffer::with_capacity(1024);
        let mut buffer2 = PinnedBuffer::with_capacity(1024);
        let mut buffer3 = PinnedBuffer::with_capacity(1024);

        let op1 = Operation::read().fd(0).buffer(buffer1.as_mut_slice());
        let op2 = Operation::write().fd(1).buffer(buffer2.as_mut_slice());
        let op3 = Operation::read().fd(2).buffer(buffer3.as_mut_slice());

        let idx1 = batch.add_operation(op1).unwrap();
        let idx2 = batch.add_operation(op2).unwrap();
        let idx3 = batch.add_operation(op3).unwrap();

        // op2 depends on op1, op3 depends on op2
        batch.add_dependency(idx2, idx1).unwrap();
        batch.add_dependency(idx3, idx2).unwrap();

        let order = batch.dependency_order().unwrap();
        assert_eq!(order, vec![0, 1, 2]);
    }

    #[test]
    fn cycle_detection() {
        let mut batch = Batch::new();
        let mut buffer1 = PinnedBuffer::with_capacity(1024);
        let mut buffer2 = PinnedBuffer::with_capacity(1024);

        let op1 = Operation::read().fd(0).buffer(buffer1.as_mut_slice());
        let op2 = Operation::write().fd(1).buffer(buffer2.as_mut_slice());

        let idx1 = batch.add_operation(op1).unwrap();
        let idx2 = batch.add_operation(op2).unwrap();

        // Create a cycle: op1 depends on op2, op2 depends on op1
        batch.add_dependency(idx1, idx2).unwrap();
        let result = batch.add_dependency(idx2, idx1);
        assert!(result.is_err());
    }
}
</file>

<file path="ring/batch/result.rs">
//! Result types for batch operations.

/// Result of a batch submission.
///
/// Contains the results of all operations in the batch, including both
/// successful completions and errors. Operations are indexed by their
/// position in the original batch, making it easy to correlate results
/// with the original operations.
///
/// # Examples
///
/// ```rust
/// # use safer_ring::ring::{BatchResult, OperationResult};
/// let results = vec![
///     OperationResult::Success(1024),  // Read 1024 bytes
///     OperationResult::Error("Permission denied".to_string()),
///     OperationResult::Success(512),   // Wrote 512 bytes
/// ];
///
/// let batch_result = BatchResult::new(results);
/// assert_eq!(batch_result.successful_count, 2);
/// assert_eq!(batch_result.failed_count, 1);
/// assert!(!batch_result.all_succeeded());
/// assert!(batch_result.any_failed());
///
/// // Iterate through successful operations
/// for (index, bytes) in batch_result.successes() {
///     println!("Operation {} succeeded with {} bytes", index, bytes);
/// }
/// ```
#[derive(Debug)]
pub struct BatchResult {
    /// Results indexed by operation position in the batch
    pub results: Vec<OperationResult>,
    /// Number of operations that completed successfully
    pub successful_count: usize,
    /// Number of operations that failed
    pub failed_count: usize,
}

/// Result of a single operation within a batch.
///
/// Represents the outcome of an individual I/O operation that was part of
/// a batch submission. Operations can succeed with a return value, fail with
/// an error, or be cancelled due to batch-level failures or dependency issues.
///
/// # Variants
///
/// - `Success(i32)`: Operation completed successfully, with the return value
///   (typically bytes transferred for I/O operations)
/// - `Error(String)`: Operation failed with the specified error message
/// - `Cancelled`: Operation was cancelled before execution (usually due to
///   dependency failures or batch-level errors)
///
/// # Examples
///
/// ```rust
/// # use safer_ring::ring::OperationResult;
/// // Successful read operation
/// let success = OperationResult::Success(1024);
/// assert!(success.is_success());
/// assert_eq!(success.success_value(), Some(1024));
///
/// // Failed operation
/// let error = OperationResult::Error("File not found".to_string());
/// assert!(error.is_error());
/// assert_eq!(error.error(), Some(&"File not found".to_string()));
///
/// // Cancelled operation
/// let cancelled = OperationResult::Cancelled;
/// assert!(cancelled.is_cancelled());
/// ```
#[derive(Debug, Clone)]
pub enum OperationResult {
    /// Operation completed successfully with the given result
    Success(i32),
    /// Operation failed with the given error
    Error(String), // Use String instead of std::io::Error for cloneability
    /// Operation was cancelled due to batch failure or dependency failure
    Cancelled,
}

impl BatchResult {
    /// Create a new batch result.
    pub fn new(results: Vec<OperationResult>) -> Self {
        let successful_count = results
            .iter()
            .filter(|r| matches!(r, OperationResult::Success(_)))
            .count();
        let failed_count = results
            .iter()
            .filter(|r| matches!(r, OperationResult::Error(_)))
            .count();

        Self {
            results,
            successful_count,
            failed_count,
        }
    }

    /// Get the result for a specific operation by index.
    pub fn get(&self, index: usize) -> Option<&OperationResult> {
        self.results.get(index)
    }

    /// Check if all operations in the batch succeeded.
    pub fn all_succeeded(&self) -> bool {
        self.failed_count == 0
            && self
                .results
                .iter()
                .all(|r| !matches!(r, OperationResult::Cancelled))
    }

    /// Check if any operations in the batch failed.
    pub fn any_failed(&self) -> bool {
        self.failed_count > 0
    }

    /// Get an iterator over successful results.
    pub fn successes(&self) -> impl Iterator<Item = (usize, i32)> + '_ {
        self.results.iter().enumerate().filter_map(|(i, r)| {
            if let OperationResult::Success(value) = r {
                Some((i, *value))
            } else {
                None
            }
        })
    }

    /// Get an iterator over failed results.
    pub fn failures(&self) -> impl Iterator<Item = (usize, &String)> + '_ {
        self.results.iter().enumerate().filter_map(|(i, r)| {
            if let OperationResult::Error(error) = r {
                Some((i, error))
            } else {
                None
            }
        })
    }
}

impl OperationResult {
    /// Check if this result represents a successful operation.
    pub fn is_success(&self) -> bool {
        matches!(self, Self::Success(_))
    }

    /// Check if this result represents a failed operation.
    pub fn is_error(&self) -> bool {
        matches!(self, Self::Error(_))
    }

    /// Check if this result represents a cancelled operation.
    pub fn is_cancelled(&self) -> bool {
        matches!(self, Self::Cancelled)
    }

    /// Get the success value if this result is successful.
    pub fn success_value(&self) -> Option<i32> {
        if let Self::Success(value) = self {
            Some(*value)
        } else {
            None
        }
    }

    /// Get the error if this result is an error.
    pub fn error(&self) -> Option<&String> {
        if let Self::Error(error) = self {
            Some(error)
        } else {
            None
        }
    }
}
</file>

<file path="ring/batch/validation.rs">
//! Validation logic for batch operations and dependencies.

use crate::error::{Result, SaferRingError};
use std::collections::{HashMap, HashSet};

/// Validates batch dependencies and checks for cycles.
pub struct DependencyValidator;

impl DependencyValidator {
    /// Check if the batch has circular dependencies.
    ///
    /// This method performs a topological sort to detect cycles in the
    /// dependency graph.
    pub fn has_circular_dependencies(dependencies: &HashMap<usize, Vec<usize>>) -> bool {
        // Implement cycle detection using DFS
        fn has_cycle(
            node: usize,
            graph: &HashMap<usize, Vec<usize>>,
            visited: &mut HashSet<usize>,
            rec_stack: &mut HashSet<usize>,
        ) -> bool {
            visited.insert(node);
            rec_stack.insert(node);

            if let Some(neighbors) = graph.get(&node) {
                for &neighbor in neighbors {
                    if (!visited.contains(&neighbor)
                        && has_cycle(neighbor, graph, visited, rec_stack))
                        || rec_stack.contains(&neighbor)
                    {
                        return true;
                    }
                }
            }

            rec_stack.remove(&node);
            false
        }

        let mut visited = HashSet::new();

        for &node in dependencies.keys() {
            if !visited.contains(&node) {
                let mut rec_stack = HashSet::new();
                if has_cycle(node, dependencies, &mut visited, &mut rec_stack) {
                    return true;
                }
            }
        }

        false
    }

    /// Check if adding a dependency would create a cycle.
    pub fn would_create_cycle(
        dependencies: &HashMap<usize, Vec<usize>>,
        dependent: usize,
        new_dependency: usize,
    ) -> bool {
        // Simple cycle detection: check if new_dependency transitively depends on dependent
        let mut visited = HashSet::new();
        let mut stack = vec![new_dependency];

        while let Some(current) = stack.pop() {
            if current == dependent {
                return true; // Found a cycle
            }

            if visited.contains(&current) {
                continue; // Already processed this node
            }
            visited.insert(current);

            // Add all dependencies of current to the stack
            if let Some(deps) = dependencies.get(&current) {
                stack.extend(deps.iter().copied());
            }
        }

        false
    }

    /// Get the operations in dependency order.
    ///
    /// Returns operations sorted such that dependencies come before dependents.
    /// Operations with no dependencies come first.
    pub fn dependency_order(
        dependencies: &HashMap<usize, Vec<usize>>,
        operation_count: usize,
    ) -> Result<Vec<usize>> {
        let mut result = Vec::new();
        let mut visited = HashSet::new();
        let mut temp_visited = HashSet::new();

        // Topological sort using DFS
        for i in 0..operation_count {
            if !visited.contains(&i) {
                Self::visit_node(
                    i,
                    dependencies,
                    &mut visited,
                    &mut temp_visited,
                    &mut result,
                )?;
            }
        }

        // Note: No reverse needed - DFS post-order already gives correct dependency order
        Ok(result)
    }

    /// Visit a node in the dependency graph for topological sorting.
    fn visit_node(
        node: usize,
        dependencies: &HashMap<usize, Vec<usize>>,
        visited: &mut HashSet<usize>,
        temp_visited: &mut HashSet<usize>,
        result: &mut Vec<usize>,
    ) -> Result<()> {
        if temp_visited.contains(&node) {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Circular dependency detected",
            )));
        }

        if visited.contains(&node) {
            return Ok(());
        }

        temp_visited.insert(node);

        // Visit all dependencies first
        if let Some(deps) = dependencies.get(&node) {
            for &dep in deps {
                Self::visit_node(dep, dependencies, visited, temp_visited, result)?;
            }
        }

        temp_visited.remove(&node);
        visited.insert(node);
        result.push(node);

        Ok(())
    }
}
</file>

<file path="ring/completion/mod.rs">
//! Completion queue processing for the Ring.

use crate::error::{Result, SaferRingError};
use std::io;

use super::core::Ring;

mod result;

pub use result::CompletionResult;

impl<'ring> Ring<'ring> {
    /// Try to complete operations by checking the completion queue.
    ///
    /// Non-blocking check for completed operations. Processes all available
    /// completions and returns them as a vector of results. Each completion
    /// contains the operation result.
    ///
    /// **Note**: Buffer ownership is not currently returned due to the borrowed
    /// reference API design. Users retain ownership of their buffers.
    ///
    /// # Returns
    ///
    /// Returns a vector of completion results. The vector may be empty if no
    /// operations have completed.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - The completion queue is in an invalid state
    /// - A completion references an unknown operation ID
    /// - System error occurs while processing completions
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Ring;
    /// # #[cfg(target_os = "linux")]
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    ///
    /// // Submit some operations...
    ///
    /// // Check for completions
    /// let completions = ring.try_complete()?;
    /// for completion in completions {
    ///     let (result, buffer) = completion.into_result();
    ///     match result {
    ///         Ok(bytes) => println!("Operation completed: {} bytes", bytes),
    ///         Err(e) => eprintln!("Operation failed: {}", e),
    ///     }
    ///     // buffer is currently always None - users retain buffer ownership
    ///     assert!(buffer.is_none());
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub fn try_complete(&mut self) -> Result<Vec<CompletionResult<'ring, '_>>> {
        self.process_completion_queue(false)
    }
    /// Wait for at least one operation to complete.
    ///
    /// Blocks until at least one operation completes, then processes all
    /// available completions. This is more efficient than polling when you
    /// need to wait for operations to finish.
    ///
    /// # Returns
    ///
    /// Returns a vector of completion results with at least one element
    /// (unless an error occurs).
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - No operations are in flight (nothing to wait for)
    /// - The completion queue is in an invalid state
    /// - System error occurs while waiting or processing
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Ring;
    /// # #[cfg(target_os = "linux")]
    /// # fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    ///
    /// // Submit some operations...
    ///
    /// // Wait for at least one to complete
    /// let completions = ring.wait_for_completion()?;
    /// println!("Got {} completions", completions.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn wait_for_completion(&mut self) -> Result<Vec<CompletionResult<'ring, '_>>> {
        // Check if we have any operations to wait for
        if !self.has_operations_in_flight() {
            return Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::InvalidInput,
                "No operations in flight to wait for",
            )));
        }

        self.process_completion_queue(true)
    }

    /// Check a specific operation for completion.
    ///
    /// This method allows checking if a specific operation has completed
    /// without processing all completions. Useful when you only care about
    /// one particular operation.
    ///
    /// # Arguments
    ///
    /// * `operation_id` - The ID of the operation to check
    ///
    /// # Returns
    ///
    /// Returns `Some(result)` if the operation has completed, `None` if it's
    /// still in flight.
    ///
    /// # Errors
    ///
    /// Returns an error if the operation ID is not recognized or if there's
    /// a system error while checking completions.
    pub fn try_complete_by_id(&mut self, operation_id: u64) -> Result<Option<io::Result<i32>>> {
        // Use the backend to check for completions
        let completions = self.backend.borrow_mut().try_complete()?;

        let mut target_result = None;

        // Process all completions to avoid losing any
        {
            let mut tracker = self.operations.borrow_mut();
            for (completed_id, result) in completions {
                // Remove completed operation from tracking
                if let Some(_handle) = tracker.complete_operation(completed_id) {
                    // Wake up any future waiting for this operation
                    self.waker_registry.wake_operation(completed_id);

                    // If this is the operation we're looking for, save the result
                    if completed_id == operation_id {
                        target_result = Some(result);
                    }
                }
            }
        }

        Ok(target_result)
    }

    /// Get completion queue statistics.
    ///
    /// Returns information about the current state of the completion queue,
    /// useful for monitoring and debugging.
    ///
    /// # Returns
    ///
    /// Returns a tuple of (ready_count, capacity) where:
    /// - `ready_count` is the number of completions ready to be processed
    /// - `capacity` is the total capacity of the completion queue
    pub fn completion_queue_stats(&mut self) -> (usize, usize) {
        self.backend.borrow_mut().completion_queue_stats()
    }

    /// Process completions from the completion queue.
    ///
    /// Internal method that handles the actual completion processing logic.
    /// Can operate in blocking or non-blocking mode.
    fn process_completion_queue(&mut self, wait: bool) -> Result<Vec<CompletionResult<'ring, '_>>> {
        let completed_operations = if wait {
            self.backend.borrow_mut().wait_for_completion()?
        } else {
            self.backend.borrow_mut().try_complete()?
        };

        // Remove completed operations from tracking
        self.process_completed_operations(completed_operations)
    }

    /// Convert a completion queue entry result to an io::Result.
    ///
    /// Centralizes the logic for converting raw io_uring results to Rust's
    /// io::Result type. Negative values are errno codes.
    #[cfg(target_os = "linux")]
    #[inline]
    #[allow(dead_code)] // Will be used when completion queue is implemented
    fn convert_cqe_result(result_value: i32) -> io::Result<i32> {
        if result_value < 0 {
            // Negative values are errno codes, convert to io::Error
            Err(io::Error::from_raw_os_error(-result_value))
        } else {
            // Non-negative values are success (bytes transferred)
            Ok(result_value)
        }
    }

    /// Process completed operations and remove them from tracking.
    ///
    /// This method processes completions and wakes up any futures that are
    /// waiting for these operations to complete. It also removes completed
    /// operations from tracking.
    fn process_completed_operations(
        &self,
        completed_operations: Vec<(u64, io::Result<i32>)>,
    ) -> Result<Vec<CompletionResult<'ring, '_>>> {
        let mut completions = Vec::with_capacity(completed_operations.len());

        // Remove completed operations from tracking and wake futures
        {
            let mut tracker = self.operations.borrow_mut();

            for (operation_id, io_result) in completed_operations {
                if let Some(handle) = tracker.complete_operation(operation_id) {
                    // Wake up any future waiting for this operation
                    self.waker_registry.wake_operation(operation_id);

                    // Create completion result with buffer ownership
                    let completion = CompletionResult::new_with_buffer(
                        operation_id,
                        handle.op_type,
                        handle.fd,
                        io_result,
                        handle.buffer,
                    );

                    completions.push(completion);
                } else {
                    // Unknown operation ID shouldn't happen in normal operation
                    return Err(SaferRingError::Io(io::Error::new(
                        io::ErrorKind::InvalidData,
                        format!("Completion for unknown operation ID: {}", operation_id),
                    )));
                }
            }
        }

        Ok(completions)
    }

    /// Remove a single operation from tracking.
    ///
    /// Helper method to remove an operation from the tracker and handle
    /// the case where the operation ID is not found. Also wakes up any
    /// future waiting for this operation.
    #[cfg(target_os = "linux")]
    #[allow(dead_code)] // Will be used when completion queue is implemented
    fn remove_operation_from_tracking(&self, operation_id: u64) -> Result<()> {
        let mut tracker = self.operations.borrow_mut();
        if tracker.complete_operation(operation_id).is_none() {
            return Err(SaferRingError::Io(io::Error::new(
                io::ErrorKind::InvalidData,
                format!("Completion for unknown operation ID: {}", operation_id),
            )));
        }

        // Wake up any future waiting for this operation
        self.waker_registry.wake_operation(operation_id);

        Ok(())
    }
}
</file>

<file path="ring/completion/result.rs">
//! Completion result types and utilities.

use std::io;

use crate::operation::{tracker::BufferOwnership, Completed, Operation, OperationType};
use std::os::unix::io::RawFd;

/// Result of a completed operation.
///
/// Contains the operation result and allows extraction of the buffer
/// ownership for reuse or cleanup. This type ensures that completed
/// operations can be safely consumed to retrieve both the result
/// and the buffer ownership.
#[derive(Debug)]
pub struct CompletionResult<'ring, 'buf> {
    /// The completed operation with its result (if using the future API)
    pub(super) operation: Option<Operation<'ring, 'buf, Completed<io::Result<i32>>>>,
    /// Operation ID for tracking purposes
    pub(super) operation_id: u64,
    /// Operation type
    pub(super) op_type: OperationType,
    /// File descriptor used
    pub(super) fd: RawFd,
    /// Operation result
    pub(super) result: io::Result<i32>,
    /// Buffer ownership (if any)
    pub(super) buffer: Option<BufferOwnership>,
}

impl<'ring, 'buf> CompletionResult<'ring, 'buf> {
    /// Create a new completion result.
    ///
    /// This is used internally by the completion processor to wrap
    /// completed operations with their tracking information.
    #[allow(dead_code)] // Used by completion processor
    pub(super) fn new(
        operation: Operation<'ring, 'buf, Completed<io::Result<i32>>>,
        operation_id: u64,
    ) -> Self {
        // Extract information from the operation
        let op_type = operation.op_type();
        let fd = operation.fd();
        let result = match operation.result() {
            Ok(bytes) => Ok(*bytes),
            Err(e) => Err(io::Error::new(e.kind(), e.to_string())),
        };

        Self {
            operation: Some(operation),
            operation_id,
            op_type,
            fd,
            result,
            buffer: None,
        }
    }

    /// Create a new completion result with buffer ownership.
    ///
    /// This is used by the polling API to create completion results
    /// that include buffer ownership for proper cleanup.
    pub(crate) fn new_with_buffer(
        operation_id: u64,
        op_type: OperationType,
        fd: RawFd,
        result: io::Result<i32>,
        buffer: Option<BufferOwnership>,
    ) -> Self {
        Self {
            operation: None,
            operation_id,
            op_type,
            fd,
            result,
            buffer,
        }
    }

    /// Extract the result and buffer from the completed operation.
    ///
    /// Returns a tuple of (result, buffer) where the buffer can be reused
    /// for subsequent operations. This consumes the completion result,
    /// ensuring proper ownership transfer.
    ///
    /// # Returns
    ///
    /// A tuple containing:
    /// - The I/O operation result (bytes transferred or error)
    /// - The buffer (if one was used), returned for reuse
    ///
    /// # Note
    ///
    /// **Current Limitation**: The current implementation always returns `None`
    /// for buffer ownership because the API uses borrowed references rather than
    /// owned buffers. This is a known limitation that affects the polling API.
    ///
    /// Future enhancements will add an owned buffer API that can properly transfer
    /// buffer ownership in the polling API. For now, users retain ownership of
    /// their buffers throughout the operation lifecycle.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::CompletionResult;
    /// # let completion: CompletionResult<'_, '_> = todo!();
    /// let (result, buffer) = completion.into_result();
    /// match result {
    ///     Ok(bytes) => println!("Transferred {} bytes", bytes),
    ///     Err(e) => eprintln!("I/O error: {}", e),
    /// }
    /// // Note: buffer is currently always None due to the borrowed reference API
    /// assert!(buffer.is_none());
    /// // Users retain ownership of their original buffers
    /// ```
    pub fn into_result(self) -> (io::Result<i32>, Option<BufferOwnership>) {
        // Return the stored result and buffer ownership
        // Currently self.buffer is always None due to the borrowed reference API
        // This is a known limitation that will be addressed in future versions
        (self.result, self.buffer)
    }

    /// Get a reference to the result without consuming the completion.
    ///
    /// This allows inspecting the result while keeping the completion intact.
    /// Useful when you need to check the result before deciding whether to
    /// consume the completion.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::CompletionResult;
    /// # let completion: CompletionResult<'_, '_> = todo!();
    /// match completion.result() {
    ///     Ok(bytes) => println!("Operation succeeded with {} bytes", bytes),
    ///     Err(e) => println!("Operation failed: {}", e),
    /// }
    /// // Completion is still available for consumption
    /// ```
    #[inline]
    pub fn result(&self) -> &io::Result<i32> {
        if let Some(ref operation) = self.operation {
            operation.result()
        } else {
            &self.result
        }
    }

    /// Get the operation ID.
    ///
    /// Returns the unique identifier that was assigned to this operation
    /// when it was submitted. This can be useful for correlating completions
    /// with submitted operations in logging or debugging scenarios.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::CompletionResult;
    /// # let completion: CompletionResult<'_, '_> = todo!();
    /// println!("Operation {} completed", completion.id());
    /// ```
    #[inline]
    pub fn id(&self) -> u64 {
        self.operation_id
    }

    /// Get the file descriptor used by this operation.
    ///
    /// Returns the file descriptor that was used for the I/O operation.
    /// This can be useful for logging or debugging purposes.
    #[inline]
    pub fn fd(&self) -> std::os::unix::io::RawFd {
        if let Some(ref operation) = self.operation {
            operation.fd()
        } else {
            self.fd
        }
    }

    /// Get the operation type.
    ///
    /// Returns the type of I/O operation that was performed (read, write, etc.).
    #[inline]
    pub fn op_type(&self) -> crate::operation::OperationType {
        if let Some(ref operation) = self.operation {
            operation.op_type()
        } else {
            self.op_type
        }
    }

    /// Check if this operation used a buffer.
    ///
    /// Returns `true` if the operation had a buffer associated with it.
    /// This can be useful for determining whether buffer ownership will
    /// be returned when consuming the completion.
    #[inline]
    pub fn has_buffer(&self) -> bool {
        if let Some(ref operation) = self.operation {
            operation.has_buffer()
        } else {
            self.buffer.is_some()
        }
    }

    /// Check if the operation was successful.
    ///
    /// Returns `true` if the operation completed without an error.
    /// This is a convenience method that's equivalent to checking
    /// `completion.result().is_ok()`.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::CompletionResult;
    /// # let completion: CompletionResult<'_, '_> = todo!();
    /// if completion.is_success() {
    ///     println!("Operation completed successfully");
    /// } else {
    ///     println!("Operation failed");
    /// }
    /// ```
    #[inline]
    pub fn is_success(&self) -> bool {
        self.result().is_ok()
    }

    /// Get the number of bytes transferred (if successful).
    ///
    /// Returns `Some(bytes)` if the operation was successful, `None` if it failed.
    /// This is a convenience method for extracting the byte count from successful
    /// operations without having to match on the result.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::CompletionResult;
    /// # let completion: CompletionResult<'_, '_> = todo!();
    /// if let Some(bytes) = completion.bytes_transferred() {
    ///     println!("Transferred {} bytes", bytes);
    /// }
    /// ```
    #[inline]
    pub fn bytes_transferred(&self) -> Option<i32> {
        match self.result() {
            Ok(bytes) => Some(*bytes),
            Err(_) => None,
        }
    }
}
</file>

<file path="ring/core/batch_operations.rs">
//! Batch operation submission and management for the Ring.

use super::Ring;
use crate::error::{Result, SaferRingError};
use crate::future::{BatchFuture, StandaloneBatchFuture};
use crate::ring::batch::{Batch, BatchConfig};

impl<'ring> Ring<'ring> {
    /// Submit a batch of operations efficiently.
    ///
    /// This method submits multiple operations in a single batch, which can
    /// significantly improve performance by reducing the number of system calls.
    /// Operations can have dependencies and will be submitted in the correct order.
    ///
    /// # Arguments
    ///
    /// * `batch` - Batch of operations to submit
    ///
    /// # Returns
    ///
    /// Returns a BatchFuture that resolves to the results of all operations.
    ///
    /// # Errors
    ///
    /// Returns an error if batch validation fails or submission fails.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Batch, Operation, PinnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let mut batch = Batch::new();
    /// let mut buffer1 = PinnedBuffer::with_capacity(1024);
    /// let mut buffer2 = PinnedBuffer::with_capacity(1024);
    ///
    /// batch.add_operation(Operation::read().fd(0).buffer(buffer1.as_mut_slice()))?;
    /// batch.add_operation(Operation::write().fd(1).buffer(buffer2.as_mut_slice()))?;
    ///
    /// let results = ring.submit_batch(batch).await?;
    /// println!("Batch completed with {} operations", results.results.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn submit_batch<'buf>(
        &'ring mut self,
        batch: Batch<'ring, 'buf>,
    ) -> Result<BatchFuture<'ring>>
    where
        'buf: 'ring, // Buffer must outlive ring operations
    {
        self.submit_batch_with_config(batch, BatchConfig::default())
    }

    /// Submit a batch of operations with custom configuration.
    ///
    /// This method provides more control over batch submission behavior,
    /// including fail-fast mode and dependency handling.
    ///
    /// # Arguments
    ///
    /// * `batch` - Batch of operations to submit
    /// * `config` - Configuration for batch submission behavior
    ///
    /// # Returns
    ///
    /// Returns a BatchFuture that resolves to the results of all operations.
    ///
    /// # Errors
    ///
    /// Returns an error if batch validation fails or submission fails.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Batch, BatchConfig, Operation, PinnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let mut batch = Batch::new();
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// batch.add_operation(Operation::read().fd(0).buffer(buffer.as_mut_slice()))?;
    ///
    /// let config = BatchConfig {
    ///     fail_fast: true,
    ///     max_batch_size: 100,
    ///     enforce_dependencies: true,
    /// };
    ///
    /// let results = ring.submit_batch_with_config(batch, config).await?;
    /// println!("Batch completed");
    /// # Ok(())
    /// # }
    /// ```
    pub fn submit_batch_with_config<'buf>(
        &'ring mut self,
        batch: Batch<'ring, 'buf>,
        config: BatchConfig,
    ) -> Result<BatchFuture<'ring>>
    where
        'buf: 'ring, // Buffer must outlive ring operations
    {
        if batch.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Cannot submit empty batch",
            )));
        }

        if batch.len() > config.max_batch_size {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!(
                    "Batch size {} exceeds maximum {}",
                    batch.len(),
                    config.max_batch_size
                ),
            )));
        }

        // Get operations in dependency order if dependencies are enforced
        let _submission_order = if config.enforce_dependencies {
            batch.dependency_order()?
        } else {
            (0..batch.len()).collect()
        };

        // Submit operations that have no dependencies first
        let mut _submitted_operations: Vec<Option<()>> = vec![None; batch.len()];
        let mut dependencies = std::collections::HashMap::new();

        // Extract operations and dependencies from the batch
        let (operations, batch_dependencies) = batch.into_operations_and_dependencies();

        // Submit all operations and collect their IDs
        let mut operation_ids = vec![None; operations.len()];
        for (index, operation) in operations.into_iter().enumerate() {
            let submitted = self.submit(operation)?;
            operation_ids[index] = Some(submitted.id());

            if batch_dependencies.contains_key(&index) {
                dependencies.insert(index, batch_dependencies[&index].clone());
            }
        }

        // Create the batch future
        Ok(BatchFuture::new(
            operation_ids,
            dependencies,
            self,
            self.waker_registry.clone(),
            config.fail_fast,
        ))
    }

    /// Submit a batch of operations and return a standalone future.
    ///
    /// This method provides an alternative to `submit_batch` that returns a future
    /// which doesn't hold a mutable reference to the Ring. This solves lifetime
    /// constraint issues that can occur when composing batch operations with other
    /// operations on the same ring.
    ///
    /// The returned future must be polled using a custom polling method that
    /// provides Ring access when needed, but doesn't hold the Ring reference.
    ///
    /// # Arguments
    ///
    /// * `batch` - Batch of operations to submit
    ///
    /// # Returns
    ///
    /// Returns a StandaloneBatchFuture that can be polled independently of Ring lifetime.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Batch, Operation, PinnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut batch = Batch::new();
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// batch.add_operation(Operation::read().fd(0).buffer(buffer.as_mut_slice()))?;
    ///
    /// // This doesn't hold a mutable reference to Ring
    /// let mut batch_future = ring.submit_batch_standalone(batch)?;
    ///
    /// // Can perform other operations on ring here
    /// // let other_result = ring.read(...).await?;
    ///
    /// // Poll the batch future manually providing Ring access
    /// let results = std::future::poll_fn(|cx| {
    ///     batch_future.poll_with_ring(&mut ring, cx)
    /// }).await?;
    ///
    /// println!("Batch completed with {} operations", results.results.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn submit_batch_standalone<'buf>(
        &mut self,
        batch: Batch<'ring, 'buf>,
    ) -> Result<StandaloneBatchFuture>
    where
        'buf: 'ring, // Buffer must outlive ring operations
    {
        self.submit_batch_standalone_with_config(batch, BatchConfig::default())
    }

    /// Submit a batch of operations with custom configuration and return a standalone future.
    ///
    /// This provides the same functionality as `submit_batch_with_config` but returns
    /// a standalone future that doesn't hold Ring references.
    pub fn submit_batch_standalone_with_config<'buf>(
        &mut self,
        batch: Batch<'ring, 'buf>,
        config: BatchConfig,
    ) -> Result<StandaloneBatchFuture>
    where
        'buf: 'ring, // Buffer must outlive ring operations
    {
        if batch.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Cannot submit empty batch",
            )));
        }

        if batch.len() > config.max_batch_size {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!(
                    "Batch size {} exceeds maximum {}",
                    batch.len(),
                    config.max_batch_size
                ),
            )));
        }

        // Get operations in dependency order if dependencies are enforced
        let _submission_order = if config.enforce_dependencies {
            batch.dependency_order()?
        } else {
            (0..batch.len()).collect()
        };

        // Submit operations that have no dependencies first
        let mut _submitted_operations: Vec<Option<()>> = vec![None; batch.len()];
        let mut dependencies = std::collections::HashMap::new();

        // Extract operations and dependencies from the batch
        let (operations, batch_dependencies) = batch.into_operations_and_dependencies();

        // Submit all operations and collect their IDs
        let mut operation_ids = vec![None; operations.len()];
        for (index, operation) in operations.into_iter().enumerate() {
            let submitted = self.submit(operation)?;
            operation_ids[index] = Some(submitted.id());

            if batch_dependencies.contains_key(&index) {
                dependencies.insert(index, batch_dependencies[&index].clone());
            }
        }

        // Create the standalone batch future
        Ok(StandaloneBatchFuture::new(
            operation_ids,
            dependencies,
            self.waker_registry.clone(),
            config.fail_fast,
        ))
    }
}
</file>

<file path="ring/core/configuration.rs">
//! Configuration methods for Ring initialization.

use super::Ring;
use crate::error::Result;
#[cfg(not(target_os = "linux"))]
use crate::error::SaferRingError;
#[cfg(target_os = "linux")]
use crate::future::WakerRegistry;
#[cfg(target_os = "linux")]
use crate::operation::tracker::OperationTracker;
#[cfg(target_os = "linux")]
use crate::safety::OrphanTracker;
#[cfg(target_os = "linux")]
use std::cell::RefCell;
#[cfg(target_os = "linux")]
use std::marker::PhantomData;
#[cfg(target_os = "linux")]
use std::sync::{Arc, Mutex};

impl<'ring> Ring<'ring> {
    /// Create a new Ring with the specified configuration.
    ///
    /// This method allows full customization of the ring behavior including
    /// advanced features, buffer management, and performance optimizations.
    ///
    /// # Arguments
    ///
    /// * `config` - Complete configuration for the ring
    ///
    /// # Returns
    ///
    /// Returns a configured Ring optimized for the specified use case.
    ///
    /// # Errors
    ///
    /// Returns an error if configuration is invalid or ring initialization fails.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, SaferRingConfig};
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// // Create a ring optimized for low latency
    /// let config = SaferRingConfig::low_latency();
    /// let ring = Ring::with_config(config)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn with_config(config: crate::config::SaferRingConfig) -> Result<Self> {
        // Validate configuration first
        config.validate()?;

        // Initialize logging if enabled
        if config.logging.enabled {
            let logger = crate::logging::init_logger();
            if let Ok(mut logger) = logger.lock() {
                logger.set_level(config.logging.level);

                if let Some(log_file) = &config.logging.log_file {
                    let file_output = if config.logging.json_format {
                        Box::new(crate::logging::FileOutput::new_json(log_file))
                    } else {
                        Box::new(crate::logging::FileOutput::new(log_file))
                    };
                    logger.add_output(file_output);
                }
            };
        }

        #[cfg(target_os = "linux")]
        {
            // Create io_uring with advanced configuration
            let mut builder: io_uring::Builder<io_uring::squeue::Entry, io_uring::cqueue::Entry> =
                io_uring::IoUring::builder();
            builder.setup_sqpoll(config.ring.sq_entries);

            if config.ring.cq_entries > 0 {
                builder.setup_cqsize(config.ring.cq_entries);
            }

            if config.ring.sq_poll {
                builder.setup_sqpoll(config.ring.sq_entries);
                if let Some(cpu) = config.ring.sq_thread_cpu {
                    builder.setup_sqpoll_cpu(cpu);
                }
                if let Some(idle) = config.ring.sq_thread_idle {
                    builder.setup_sqpoll(idle);
                }
            }

            if config.advanced.coop_taskrun {
                builder.setup_coop_taskrun();
            }

            if config.advanced.defer_taskrun {
                builder.setup_defer_taskrun();
            }

            let _inner = builder.build(config.ring.sq_entries)?;

            crate::logging::log(
                crate::logging::LogLevel::Info,
                "ring",
                &format!(
                    "Created ring with {} SQ entries, {} CQ entries",
                    config.ring.sq_entries,
                    config.ring.cq_entries.max(config.ring.sq_entries)
                ),
            );

            Ok(Self {
                backend: RefCell::new(Box::new(crate::backend::io_uring::IoUringBackend::new(
                    config.ring.sq_entries,
                )?)),
                phantom: PhantomData,
                operations: RefCell::new(OperationTracker::new()),
                waker_registry: Arc::new(WakerRegistry::new()),
                orphan_tracker: Arc::new(Mutex::new(OrphanTracker::new())),
            })
        }

        #[cfg(not(target_os = "linux"))]
        {
            let _processed = 0;
            crate::logging::log(
                crate::logging::LogLevel::Warn,
                "ring",
                "io_uring not supported on this platform, using stub implementation",
            );

            Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::Unsupported,
                "io_uring is only supported on Linux",
            )))
        }
    }

    /// Create a new Ring with advanced io_uring features.
    ///
    /// This method enables advanced io_uring features like buffer selection,
    /// multi-shot operations, and other performance optimizations based on
    /// kernel support.
    ///
    /// # Arguments
    ///
    /// * `config` - Advanced feature configuration
    ///
    /// # Returns
    ///
    /// Returns a Ring with advanced features enabled where supported.
    ///
    /// # Errors
    ///
    /// Returns an error if ring initialization fails. Features not supported
    /// by the kernel are automatically disabled with a warning.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, AdvancedConfig, FeatureDetector};
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// // Detect available features and create optimal config
    /// let detector = FeatureDetector::new()?;
    /// let config = detector.create_optimal_config();
    /// let ring = Ring::with_advanced_config(config)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn with_advanced_config(config: crate::advanced::AdvancedConfig) -> Result<Self> {
        // Detect available features
        let detector = crate::advanced::FeatureDetector::new()?;

        // Create a SaferRingConfig with advanced features
        let mut safer_config = crate::config::SaferRingConfig {
            advanced: config,
            ..Default::default()
        };

        // Adjust configuration based on available features
        if !detector.has_feature("buffer_selection") && safer_config.advanced.buffer_selection {
            crate::logging::log(
                crate::logging::LogLevel::Warn,
                "ring",
                "Buffer selection not supported on this kernel, disabling feature",
            );
            safer_config.advanced.buffer_selection = false;
        }

        if !detector.has_feature("multi_shot") && safer_config.advanced.multi_shot {
            crate::logging::log(
                crate::logging::LogLevel::Warn,
                "ring",
                "Multi-shot operations not supported on this kernel, disabling feature",
            );
            safer_config.advanced.multi_shot = false;
        }

        Self::with_config(safer_config)
    }
}
</file>

<file path="ring/core/fixed_operations.rs">
//! Fixed file operations using registered indices for the Ring.

use super::Ring;
use crate::error::Result;
use crate::future::{ReadFuture, WriteFuture};
use crate::operation::Operation;

impl<'ring> Ring<'ring> {
    /// Read from a fixed file using its registered index.
    ///
    /// Fixed files are pre-registered with the kernel and accessed by index
    /// instead of file descriptor, providing better performance for frequently
    /// used files. The file must be registered with the registry first.
    ///
    /// # Arguments
    ///
    /// * `fixed_file` - The fixed file to read from
    /// * `buffer` - Pinned buffer to read data into
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that resolves to (bytes_read, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// fixed file is not registered.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer, Registry};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let fixed_files = registry.register_fixed_files(vec![0])?; // stdin
    /// let fixed_stdin = &fixed_files[0];
    ///
    /// let ring = Ring::new(32)?;
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// let (bytes_read, buffer) = ring.read_fixed(fixed_stdin, buffer.as_mut_slice()).await?;
    /// println!("Read {} bytes from fixed file", bytes_read);
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_fixed<'buf>(
        &'ring mut self,
        fixed_file: &crate::registry::FixedFile,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<ReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::read()
            .fixed_file(fixed_file.clone())
            .buffer(buffer);
        let submitted = self.submit(operation)?;
        Ok(ReadFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Write to a fixed file using its registered index.
    ///
    /// Fixed files are pre-registered with the kernel and accessed by index
    /// instead of file descriptor, providing better performance for frequently
    /// used files. The file must be registered with the registry first.
    ///
    /// # Arguments
    ///
    /// * `fixed_file` - The fixed file to write to
    /// * `buffer` - Pinned buffer containing data to write
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that resolves to (bytes_written, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// fixed file is not registered.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer, Registry};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut registry = Registry::new();
    /// let fixed_files = registry.register_fixed_files(vec![1])?; // stdout
    /// let fixed_stdout = &fixed_files[0];
    ///
    /// let ring = Ring::new(32)?;
    /// let mut buffer = PinnedBuffer::from_slice(b"Hello from fixed file!");
    ///
    /// let (bytes_written, buffer) = ring.write_fixed(fixed_stdout, buffer.as_mut_slice()).await?;
    /// println!("Wrote {} bytes to fixed file", bytes_written);
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_fixed<'buf>(
        &'ring mut self,
        fixed_file: &crate::registry::FixedFile,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<WriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::write()
            .fixed_file(fixed_file.clone())
            .buffer(buffer);
        let submitted = self.submit(operation)?;
        Ok(WriteFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    // TODO: Add buffer selection operations when future types are implemented
    // The read_with_buffer_selection method would go here once the appropriate
    // future types are implemented for buffer selection operations.
}
</file>

<file path="ring/core/io_operations.rs">
//! I/O operations (read, write, vectored) for the Ring.

use super::Ring;
use crate::error::{Result, SaferRingError};
use crate::future::{
    OperationFuture, ReadFuture, VectoredReadFuture, VectoredWriteFuture, WriteFuture,
};
use crate::operation::{Building, Operation, OperationType};

impl<'ring> Ring<'ring> {
    /// Read from a file descriptor at offset 0.
    ///
    /// ⚠️ **LEGACY API**: Consider using [`read_owned()`](Ring::read_owned) for better safety and ergonomics.
    ///
    /// This pin-based API requires careful lifetime management and is primarily provided
    /// for advanced use cases. The ownership transfer API is safer and easier to use:
    ///
    /// ```rust,no_run  
    /// # use safer_ring::{Ring, OwnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let buffer = OwnedBuffer::new(1024);
    ///
    /// // Recommended: ownership transfer API
    /// let (bytes_read, buffer) = ring.read_owned(0, buffer).await?;
    /// # Ok(()) }
    /// ```
    ///
    /// This is a convenience method for read operations that don't need a specific offset.
    /// It's equivalent to calling `read_at(fd, buffer, 0)`.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `buffer` - Pinned buffer to read into
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that can be awaited to get (bytes_read, buffer).
    ///
    /// # Security Considerations
    ///
    /// **IMPORTANT**: The caller is responsible for ensuring the file descriptor is:
    /// - Valid and open for reading
    /// - Owned by the current process with appropriate read permissions  
    /// - Not subject to race conditions (e.g., concurrent closes by other threads)
    /// - Properly validated for the intended use case
    ///
    /// This library does **NOT** perform permission checks, file descriptor validation,
    /// or access control. Passing an invalid, unauthorized, or malicious file descriptor
    /// may result in:
    /// - Reading from unintended files or devices
    /// - Security vulnerabilities or privilege escalation
    /// - System errors or crashes
    ///
    /// Always validate file descriptors at the application security boundary.
    ///
    /// # Legacy Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// let future = ring.read(0, buffer.as_mut_slice())?;
    /// let (bytes_read, buffer) = future.await?;
    /// println!("Read {} bytes", bytes_read);
    /// # Ok(())
    /// # }
    /// ```
    pub fn read<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<ReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        self.read_at(fd, buffer, 0)
    }

    /// Write to a file descriptor at offset 0.
    ///
    /// ⚠️ **LEGACY API**: Consider using [`write_owned()`](Ring::write_owned) for better safety and ergonomics.
    ///
    /// This pin-based API requires careful lifetime management and is primarily provided
    /// for advanced use cases. The ownership transfer API is safer and easier to use:
    ///
    /// ```rust,no_run  
    /// # use safer_ring::{Ring, OwnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let buffer = OwnedBuffer::from_slice(b"Hello, world!");
    ///
    /// // Recommended: ownership transfer API
    /// let (bytes_written, buffer) = ring.write_owned(1, buffer).await?;
    /// # Ok(()) }
    /// ```
    ///
    /// This is a convenience method for write operations that don't need a specific offset.
    /// It's equivalent to calling `write_at(fd, buffer, 0)`.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `buffer` - Pinned buffer containing data to write
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that can be awaited to get (bytes_written, buffer).
    ///
    /// # Security Considerations
    ///
    /// **IMPORTANT**: The caller is responsible for ensuring the file descriptor is:
    /// - Valid and open for writing
    /// - Owned by the current process with appropriate write permissions
    /// - Not subject to race conditions (e.g., concurrent closes by other threads)
    /// - Properly validated for the intended use case
    /// - Not pointing to sensitive system files or devices without authorization
    ///
    /// This library does **NOT** perform permission checks, file descriptor validation,
    /// or access control. Passing an invalid, unauthorized, or malicious file descriptor
    /// may result in:
    /// - Writing to unintended files, devices, or system resources
    /// - Data corruption or security vulnerabilities
    /// - Privilege escalation or unauthorized system modifications
    /// - System errors or crashes
    ///
    /// Always validate file descriptors at the application security boundary.
    ///
    /// # Legacy Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let data = b"Hello, world!";
    /// let mut buffer = PinnedBuffer::from_slice(data);
    ///
    /// let future = ring.write(1, buffer.as_mut_slice())?;
    /// let (bytes_written, buffer) = future.await?;
    /// println!("Wrote {} bytes", bytes_written);
    /// # Ok(())
    /// # }
    /// ```
    pub fn write<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<WriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        self.write_at(fd, buffer, 0)
    }

    /// Submit a read operation and return a future.
    ///
    /// This is a convenience method that combines operation submission with
    /// future creation for read operations. The returned future can be awaited
    /// to get the result and buffer ownership.
    ///
    /// # Arguments
    ///
    /// * `operation` - Read operation in Building state
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that can be awaited to get (bytes_read, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Operation, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    /// let ring = Ring::new(32)?;
    ///
    /// let operation = Operation::read()
    ///     .fd(0)
    ///     .buffer(buffer.as_mut_slice());
    ///
    /// // Example usage - actual future processing would be more complex
    /// # Ok(())
    /// # }
    /// ```
    pub fn submit_read<'buf>(
        &'ring mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<ReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        // Validate that this is actually a read operation
        if operation.get_type() != OperationType::Read {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation must be a read operation",
            )));
        }

        let submitted = self.submit(operation)?;
        Ok(ReadFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Submit a write operation and return a future.
    ///
    /// This is a convenience method that combines operation submission with
    /// future creation for write operations. The returned future can be awaited
    /// to get the result and buffer ownership.
    ///
    /// # Arguments
    ///
    /// * `operation` - Write operation in Building state
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that can be awaited to get (bytes_written, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Operation, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut buffer = b"Hello, world!".to_vec();
    /// let ring = Ring::new(32)?;
    ///
    /// let operation = Operation::write()
    ///     .fd(1)
    ///     .buffer(Pin::new(buffer.as_mut_slice()));
    ///
    /// // Example usage - actual future processing would be more complex
    /// # Ok(())
    /// # }
    /// ```
    pub fn submit_write<'buf>(
        &'ring mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<WriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        // Validate that this is actually a write operation
        if operation.get_type() != OperationType::Write {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation must be a write operation",
            )));
        }

        let submitted = self.submit(operation)?;
        Ok(WriteFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Submit any operation and return a generic future.
    ///
    /// This method provides a unified interface for submitting any type of
    /// operation and getting a future. The returned future provides the raw
    /// result without type-specific conversions.
    ///
    /// # Arguments
    ///
    /// * `operation` - Operation in Building state
    ///
    /// # Returns
    ///
    /// Returns an OperationFuture that can be awaited to get (result, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    pub fn submit_operation<'buf>(
        &'ring mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<OperationFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let submitted = self.submit(operation)?;
        Ok(OperationFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Read data from a file descriptor into a buffer.
    ///
    /// This is a high-level convenience method that creates a read operation,
    /// submits it, and returns a future that can be awaited.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `buffer` - Pinned buffer to read data into
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that resolves to (bytes_read, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// // Read 1024 bytes starting at offset 4096
    /// let future = ring.read_at(3, buffer.as_mut_slice(), 4096)?;
    /// let (bytes_read, buffer) = future.await?;
    /// println!("Read {} bytes from offset 4096", bytes_read);
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_at<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
        offset: u64,
    ) -> Result<ReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::read().fd(fd).buffer(buffer).offset(offset);
        self.submit_read(operation)
    }

    /// Read data using a registered file descriptor.
    ///
    /// This method uses a pre-registered file descriptor for improved performance
    /// by avoiding kernel fd lookups on each operation.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - Registered file descriptor to read from
    /// * `buffer` - Pinned buffer to read data into
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that resolves to (bytes_read, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer, Registry};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut registry = Registry::new();
    /// let registered_fd = registry.register_fd(0)?;
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// let future = ring.read_registered(registered_fd, buffer.as_mut_slice())?;
    /// let (bytes_read, buffer) = future.await?;
    /// println!("Read {} bytes using registered fd", bytes_read);
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_registered<'buf>(
        &'ring mut self,
        registered_fd: crate::registry::RegisteredFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<ReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::read()
            .registered_fd(registered_fd)
            .buffer(buffer);
        self.submit_read(operation)
    }

    /// Read data using a registered buffer.
    ///
    /// This method uses a pre-registered buffer for improved performance
    /// by avoiding kernel buffer validation on each operation.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `registered_buffer` - Registered buffer to read data into
    ///
    /// # Returns
    ///
    /// Returns a ReadFuture that resolves to (bytes_read, registered_buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Registry};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let mut registry = Registry::new();
    /// let buffer = Pin::new(Box::new([0u8; 1024]));
    /// let registered_buffer = registry.register_buffer(buffer)?;
    ///
    /// // Note: This is a conceptual example - the actual return type would need
    /// // to be adjusted to handle registered buffers properly
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_with_registered_buffer<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        registered_buffer: crate::registry::RegisteredBuffer,
    ) -> Result<OperationFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::read()
            .fd(fd)
            .registered_buffer(registered_buffer);
        self.submit_operation(operation)
    }

    /// Perform a vectored read operation (readv).
    ///
    /// This reads data into multiple buffers in a single system call,
    /// implementing scatter-gather I/O for improved efficiency when
    /// working with non-contiguous data.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `buffers` - Vector of pinned buffers to read data into
    ///
    /// # Returns
    ///
    /// Returns a VectoredReadFuture that resolves to (bytes_read, buffers).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// buffers vector is empty.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer1 = PinnedBuffer::with_capacity(512);
    /// let mut buffer2 = PinnedBuffer::with_capacity(512);
    ///
    /// let buffers = vec![
    ///     buffer1.as_mut_slice(),
    ///     buffer2.as_mut_slice(),
    /// ];
    ///
    /// let future = ring.read_vectored(0, buffers)?;
    /// let (bytes_read, buffers) = future.await?;
    /// println!("Read {} bytes into {} buffers", bytes_read, buffers.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_vectored<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffers: Vec<std::pin::Pin<&'buf mut [u8]>>,
    ) -> Result<VectoredReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        if buffers.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Vectored read requires at least one buffer",
            )));
        }

        let operation = Operation::read_vectored().fd(fd).buffers(buffers);
        let submitted = self.submit(operation)?;
        Ok(VectoredReadFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Perform a vectored read operation at a specific offset.
    ///
    /// This combines vectored I/O with positioned reads, reading data into
    /// multiple buffers starting at a specific file offset.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `buffers` - Vector of pinned buffers to read data into
    /// * `offset` - Byte offset in the file to start reading from
    ///
    /// # Returns
    ///
    /// Returns a VectoredReadFuture that resolves to (bytes_read, buffers).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// buffers vector is empty.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer1 = PinnedBuffer::with_capacity(512);
    /// let mut buffer2 = PinnedBuffer::with_capacity(512);
    ///
    /// let buffers = vec![
    ///     buffer1.as_mut_slice(),
    ///     buffer2.as_mut_slice(),
    /// ];
    ///
    /// // Read starting at offset 4096
    /// let future = ring.read_vectored_at(3, buffers, 4096)?;
    /// let (bytes_read, buffers) = future.await?;
    /// println!("Read {} bytes into {} buffers from offset 4096", bytes_read, buffers.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_vectored_at<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffers: Vec<std::pin::Pin<&'buf mut [u8]>>,
        offset: u64,
    ) -> Result<VectoredReadFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        if buffers.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Vectored read requires at least one buffer",
            )));
        }

        let operation = Operation::read_vectored()
            .fd(fd)
            .buffers(buffers)
            .offset(offset);
        let submitted = self.submit(operation)?;
        Ok(VectoredReadFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Write data from a buffer to a file descriptor.
    ///
    /// This is a high-level convenience method that creates a write operation,
    /// submits it, and returns a future that can be awaited.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `buffer` - Pinned buffer containing data to write
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that resolves to (bytes_written, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer = PinnedBuffer::from_slice(b"Hello, world!");
    ///
    /// // Write 13 bytes starting at offset 4096
    /// let future = ring.write_at(3, buffer.as_mut_slice(), 4096)?;
    /// let (bytes_written, buffer) = future.await?;
    /// println!("Wrote {} bytes at offset 4096", bytes_written);
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_at<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
        offset: u64,
    ) -> Result<WriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::write().fd(fd).buffer(buffer).offset(offset);
        self.submit_write(operation)
    }

    /// Write data using a registered file descriptor.
    ///
    /// This method uses a pre-registered file descriptor for improved performance
    /// by avoiding kernel fd lookups on each operation.
    ///
    /// # Arguments
    ///
    /// * `registered_fd` - Registered file descriptor to write to
    /// * `buffer` - Pinned buffer containing data to write
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that resolves to (bytes_written, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer, Registry};
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut registry = Registry::new();
    /// let registered_fd = registry.register_fd(1)?;
    /// let mut buffer = PinnedBuffer::from_slice(b"Hello, world!");
    ///
    /// let future = ring.write_registered(registered_fd, buffer.as_mut_slice())?;
    /// let (bytes_written, buffer) = future.await?;
    /// println!("Wrote {} bytes using registered fd", bytes_written);
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_registered<'buf>(
        &'ring mut self,
        registered_fd: crate::registry::RegisteredFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<WriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::write()
            .registered_fd(registered_fd)
            .buffer(buffer);
        self.submit_write(operation)
    }

    /// Write data using a registered buffer.
    ///
    /// This method uses a pre-registered buffer for improved performance
    /// by avoiding kernel buffer validation on each operation.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `registered_buffer` - Registered buffer containing data to write
    ///
    /// # Returns
    ///
    /// Returns a WriteFuture that resolves to (bytes_written, registered_buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, Registry};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let mut registry = Registry::new();
    /// let buffer = Pin::new(Box::new(*b"Hello, world!"));
    /// let registered_buffer = registry.register_buffer(buffer)?;
    ///
    /// // Note: This is a conceptual example - the actual return type would need
    /// // to be adjusted to handle registered buffers properly
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_with_registered_buffer<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        registered_buffer: crate::registry::RegisteredBuffer,
    ) -> Result<OperationFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::write()
            .fd(fd)
            .registered_buffer(registered_buffer);
        self.submit_operation(operation)
    }

    /// Perform a vectored write operation (writev).
    ///
    /// This writes data from multiple buffers in a single system call,
    /// implementing gather I/O for improved efficiency when
    /// working with non-contiguous data.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `buffers` - Vector of pinned buffers containing data to write
    ///
    /// # Returns
    ///
    /// Returns a VectoredWriteFuture that resolves to (bytes_written, buffers).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// buffers vector is empty.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer1 = PinnedBuffer::from_slice(b"Hello, ");
    /// let mut buffer2 = PinnedBuffer::from_slice(b"world!");
    ///
    /// let buffers = vec![
    ///     buffer1.as_mut_slice(),
    ///     buffer2.as_mut_slice(),
    /// ];
    ///
    /// let future = ring.write_vectored(1, buffers)?;
    /// let (bytes_written, buffers) = future.await?;
    /// println!("Wrote {} bytes from {} buffers", bytes_written, buffers.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_vectored<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffers: Vec<std::pin::Pin<&'buf mut [u8]>>,
    ) -> Result<VectoredWriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        if buffers.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Vectored write requires at least one buffer",
            )));
        }

        let operation = Operation::write_vectored().fd(fd).buffers(buffers);
        let submitted = self.submit(operation)?;
        Ok(VectoredWriteFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Perform a vectored write operation at a specific offset.
    ///
    /// This combines vectored I/O with positioned writes, writing data from
    /// multiple buffers starting at a specific file offset.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `buffers` - Vector of pinned buffers containing data to write
    /// * `offset` - Byte offset in the file to start writing at
    ///
    /// # Returns
    ///
    /// Returns a VectoredWriteFuture that resolves to (bytes_written, buffers).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted or if the
    /// buffers vector is empty.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::pin::Pin;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let mut ring = Ring::new(32)?;
    /// let mut buffer1 = PinnedBuffer::from_slice(b"Hello, ");
    /// let mut buffer2 = PinnedBuffer::from_slice(b"world!");
    ///
    /// let buffers = vec![
    ///     buffer1.as_mut_slice(),
    ///     buffer2.as_mut_slice(),
    /// ];
    ///
    /// // Write starting at offset 4096
    /// let future = ring.write_vectored_at(3, buffers, 4096)?;
    /// let (bytes_written, buffers) = future.await?;
    /// println!("Wrote {} bytes from {} buffers at offset 4096", bytes_written, buffers.len());
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_vectored_at<'buf>(
        &'ring mut self,
        fd: std::os::unix::io::RawFd,
        buffers: Vec<std::pin::Pin<&'buf mut [u8]>>,
        offset: u64,
    ) -> Result<VectoredWriteFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        if buffers.is_empty() {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Vectored write requires at least one buffer",
            )));
        }

        let operation = Operation::write_vectored()
            .fd(fd)
            .buffers(buffers)
            .offset(offset);
        let submitted = self.submit(operation)?;
        Ok(VectoredWriteFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }
}
</file>

<file path="ring/core/mod.rs">
//! Core Ring implementation with lifetime management.

use std::cell::RefCell;
use std::marker::PhantomData;
use std::sync::{Arc, Mutex};

use crate::backend::{detect_backend, Backend};
use crate::error::{Result, SaferRingError};
use crate::future::WakerRegistry;
use crate::operation::tracker::OperationTracker;
use crate::operation::{Building, Operation};
use crate::safety::{CompletionChecker, OrphanTracker, SubmissionId};

// Re-export module implementations

/// Batch operation submission and management for the Ring.
///
/// Contains methods for submitting multiple operations together as batches,
/// improving performance by reducing syscall overhead and enabling complex
/// operation dependencies.
pub mod batch_operations;

/// Ring configuration and setup functionality.
///
/// Contains methods for configuring Ring behavior, including queue depths,
/// backend selection, and performance tuning options.
pub mod configuration;

/// Fixed-size I/O operations with compile-time known buffer sizes.
///
/// Contains optimized implementations for I/O operations where buffer sizes
/// are known at compile time, enabling additional optimizations.
pub mod fixed_operations;

/// Core I/O operations (read, write, etc.) for the Ring.
///
/// Contains the fundamental I/O operation methods that form the core of the
/// safer-ring API, including read, write, and other basic operations.
pub mod io_operations;

/// Network-specific I/O operations (accept, send, recv, etc.).
///
/// Contains networking-focused operations like socket accept, send, receive,
/// and other network-specific functionality built on top of io_uring.
pub mod network_operations;

/// Safe operation wrappers with additional lifetime and safety guarantees.
///
/// Contains higher-level safe wrappers around low-level operations,
/// providing additional compile-time safety checks and lifetime management.
pub mod safe_operations;

/// Utility functions and helpers for Ring operations.
///
/// Contains helper functions, diagnostic utilities, and convenience methods
/// that support the main Ring functionality.
pub mod utility;

/// Safe wrapper around io_uring with lifetime management.
///
/// Enforces buffer lifetime constraints and tracks operations to prevent
/// use-after-free bugs. The lifetime parameter ensures no operation can
/// outlive the ring that created it.
///
/// # ⚠️ CRITICAL: Threading Model and Safety
///
/// **`Ring` is `Send` but NOT `Sync`** - This is a fundamental design decision
/// that affects how you can use Ring instances in concurrent applications.
///
/// ## What This Means
///
/// - ✅ **Moving between threads**: A `Ring` can be moved from one thread to another
/// - ✅ **Single-threaded usage**: Perfect for single-threaded applications
/// - ✅ **Async task ownership**: One async task can own and use a `Ring`
/// - ❌ **Concurrent sharing**: Multiple threads cannot access the same `Ring` simultaneously
/// - ❌ **`Arc<Ring>`**: Cannot wrap `Ring` in `Arc` for sharing (won't compile)
/// - ❌ **Static sharing**: Cannot store `Ring` in static variables for global access
///
/// ## Why This Design?
///
/// This design optimizes for **performance** and **safety**:
///
/// 1. **No locks on hot path**: Submission and completion operations are lock-free
/// 2. **Memory safety**: `RefCell` prevents data races at compile time
/// 3. **Predictable performance**: No contention or lock overhead
/// 4. **Clear ownership**: Explicit ownership prevents accidental sharing bugs
///
/// ## Recommended Usage Patterns
///
/// ### ✅ Single async task ownership (Recommended):
/// ```rust,no_run
/// use safer_ring::Ring;
///
/// # #[tokio::main]
/// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let mut ring = Ring::new(32)?;
///
/// // This task owns the ring exclusively
/// let mut buffer = safer_ring::PinnedBuffer::with_capacity(1024);
/// let (bytes_read, _) = ring.read(0, buffer.as_mut_slice()).await?;
/// # Ok(())
/// # }
/// ```
///
/// ### ✅ Moving between threads:
/// ```rust,no_run
/// use safer_ring::Ring;
/// use std::thread;
///
/// # fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let ring = Ring::new(32)?;
///
/// // Move ring to background thread
/// let handle = thread::spawn(move || {
///     // Ring is now owned by this thread
///     // Can perform I/O operations here
/// });
///
/// handle.join().unwrap();
/// # Ok(())
/// # }
/// ```
///
/// ### ✅ One ring per async task:
/// ```rust,no_run
/// use safer_ring::Ring;
/// use tokio::task;
///
/// # #[tokio::main]
/// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
/// // Spawn multiple tasks, each with their own ring
/// let mut handles = Vec::new();
///
/// for i in 0..4 {
///     let handle = task::spawn(async move {
///         let mut ring = Ring::new(32)?;
///         // Each task has its own ring instance
///         // Perform I/O operations specific to this task
///         Ok::<(), Box<dyn std::error::Error + Send + Sync>>(())
///     });
///     handles.push(handle);
/// }
///
/// // Wait for all tasks to complete
/// for handle in handles {
///     handle.await??;
/// }
/// # Ok(())
/// # }
/// ```
///
/// ### ✅ Ring per worker thread pattern:
/// ```rust,no_run
/// use safer_ring::Ring;
/// use std::thread;
/// use std::sync::mpsc;
///
/// # fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let (tx, rx) = mpsc::channel();
///
/// // Spawn worker thread with its own ring
/// thread::spawn(move || {
///     let mut ring = Ring::new(32).unwrap();
///     
///     // Worker loop processing I/O requests
///     while let Ok(request) = rx.recv() {
///         // Process request using ring
///         // Send response back via another channel
///     }
/// });
///
/// // Main thread sends work to worker
/// // tx.send(work_item)?;
/// # Ok(())
/// # }
/// ```
///
/// ## ❌ Anti-patterns (Will Not Compile)
///
/// ### Sharing via Arc:
/// ```rust,compile_fail
/// use safer_ring::Ring;
/// use std::sync::Arc;
///
/// let ring = Arc::new(Ring::new(32)?);
/// // Compile error: Ring is not Sync
/// ```
///
/// ### Storing in static:
/// ```rust,compile_fail
/// use safer_ring::Ring;
///
/// static RING: Ring = Ring::new(32)?;
/// // Compile error: Ring is not Sync
/// ```
///
/// ### Concurrent access:
/// ```rust,compile_fail
/// use safer_ring::Ring;
/// use std::thread;
///
/// let mut ring = Ring::new(32)?;
/// let ring_ref = &ring;
///
/// thread::spawn(move || {
///     // Compile error: cannot move ring_ref into closure
///     ring_ref.read(0, buffer).await?;
/// });
/// ```
///
/// ## Alternative Architectures for Concurrent Applications
///
/// If you need to handle I/O from multiple threads, consider these patterns:
///
/// ### 1. Ring per thread:
/// Each thread or async task gets its own `Ring` instance.
///
/// ### 2. Worker thread pool:
/// Dedicated I/O threads each with their own `Ring`, receiving work via channels.
///
/// ### 3. Async task per connection:
/// Each connection handled by a separate async task with its own `Ring`.
///
/// ### 4. Event loop architecture:
/// Single-threaded event loop with one `Ring` handling all I/O.
///
/// ## Performance Implications
///
/// This threading model provides:
/// - **Zero lock overhead** on I/O operations
/// - **Predictable latency** without lock contention
/// - **CPU cache efficiency** with thread-local access patterns
/// - **Scalability** through independent ring instances
///
/// # Example
///
/// ```rust,no_run
/// use safer_ring::Ring;
///
/// # fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let ring = Ring::new(32)?;
/// println!("Ring created with {} capacity", ring.capacity());
/// # Ok(())
/// # }
/// ```
pub struct Ring<'ring> {
    pub(super) backend: RefCell<Box<dyn Backend>>,
    pub(super) phantom: PhantomData<&'ring ()>,
    // RefCell allows interior mutability for operation tracking
    // Using RefCell instead of Mutex for single-threaded performance
    pub(super) operations: RefCell<OperationTracker<'ring>>,
    // Waker registry for async/await support
    pub(super) waker_registry: Arc<WakerRegistry>,
    // Orphan tracker for cancelled operations safety
    pub(super) orphan_tracker: Arc<Mutex<OrphanTracker>>,
}

impl<'ring> std::fmt::Debug for Ring<'ring> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("Ring")
            .field("backend", &"<dyn Backend>")
            .field("operations", &self.operations)
            .finish()
    }
}

impl<'ring> Ring<'ring> {
    /// Create a new Ring with the specified queue depth.
    ///
    /// Automatically detects the best available backend (io_uring or epoll)
    /// and falls back gracefully when io_uring is unavailable.
    ///
    /// # Arguments
    ///
    /// * `entries` - Number of submission queue entries
    ///
    /// # Errors
    ///
    /// Returns an error if entries is 0 or all backends fail to initialize.
    pub fn new(entries: u32) -> Result<Self> {
        if entries == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Queue depth must be greater than 0",
            )));
        }

        let backend = detect_backend(entries)?;

        Ok(Self {
            backend: RefCell::new(backend),
            phantom: PhantomData,
            operations: RefCell::new(OperationTracker::new()),
            waker_registry: Arc::new(WakerRegistry::new()),
            orphan_tracker: Arc::new(Mutex::new(OrphanTracker::new())),
        })
    }

    /// Submit an operation to the ring.
    ///
    /// ⚠️ **LEGACY API**: For most use cases, prefer the higher-level methods like
    /// [`read_owned()`](Ring::read_owned) and [`write_owned()`](Ring::write_owned) which
    /// provide better safety and ergonomics through ownership transfer.
    ///
    /// This low-level method is primarily intended for:
    /// - Advanced users who need fine-grained control
    /// - Building custom higher-level abstractions  
    /// - Maximum performance scenarios
    ///
    /// Takes an operation in Building state, validates it, and returns it
    /// in Submitted state with an assigned ID. The operation is submitted
    /// to the kernel's submission queue and will be processed asynchronously.
    ///
    /// # Lifetime Constraints
    ///
    /// The buffer lifetime must be at least as long as the ring lifetime
    /// (`'buf: 'ring`) to ensure memory safety during the operation.
    ///
    /// # Arguments
    ///
    /// * `operation` - Operation in Building state to submit
    ///
    /// # Returns
    ///
    /// Returns the operation in Submitted state with an assigned ID.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - Operation validation fails (invalid fd, missing buffer, etc.)
    /// - Submission queue is full
    /// - Kernel submission fails
    pub fn submit<'buf>(
        &mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<Operation<'ring, 'buf, crate::operation::Submitted>>
    where
        'buf: 'ring, // Buffer must outlive ring operations
    {
        // Validate operation parameters before submission
        operation.validate().map_err(|msg| {
            SaferRingError::Io(std::io::Error::new(std::io::ErrorKind::InvalidInput, msg))
        })?;

        // Register operation and get ID - scope borrow to avoid conflicts
        // This pattern ensures the RefCell borrow is released before any potential
        // error handling that might need to borrow again
        let id = {
            let mut tracker = self.operations.borrow_mut();
            // TODO: For now, we don't capture buffer ownership since the current API
            // uses borrowed references. A future enhancement could add an owned buffer API
            // that would allow proper ownership transfer for the polling API.
            tracker.register_operation(operation.get_type(), operation.get_fd())
        };

        // Transition to submitted state
        let submitted = operation.submit_with_id(id).map_err(|msg| {
            // Clean up registration on failure
            self.operations.borrow_mut().complete_operation(id);
            SaferRingError::Io(std::io::Error::new(std::io::ErrorKind::InvalidInput, msg))
        })?;

        // Submit to backend (io_uring, epoll, etc.)
        self.submit_to_backend(&submitted)?;

        Ok(submitted)
    }

    /// Submit an operation to the backend (io_uring, epoll, etc.).
    ///
    /// This method handles the actual submission to the underlying backend,
    /// including proper buffer handling and error management.
    fn submit_to_backend<'buf>(
        &mut self,
        operation: &Operation<'ring, 'buf, crate::operation::Submitted>,
    ) -> Result<()> {
        // Extract buffer information for the backend
        let (buffer_ptr, buffer_len) = match operation.buffer_info() {
            Some((ptr, len)) => (ptr, len),
            None => (std::ptr::null_mut(), 0), // No buffer operations like accept
        };

        // Submit to backend with operation details
        self.backend.borrow_mut().submit_operation(
            operation.op_type(),
            operation.fd(),
            operation.offset(),
            buffer_ptr,
            buffer_len,
            operation.id(),
        )
    }
}

impl<'ring> Drop for Ring<'ring> {
    /// Panic if operations are still in flight to prevent use-after-free bugs.
    fn drop(&mut self) {
        let tracker = self.operations.borrow();
        let count = tracker.count();

        if count > 0 {
            let debug_info = tracker.debug_info();
            drop(tracker); // Release borrow before panic to avoid poisoning

            let mut message = format!("Ring dropped with {} operations in flight:\n", count);
            for (id, op_type, fd) in debug_info {
                message.push_str(&format!(
                    "  - Operation {}: {:?} on fd {}\n",
                    id, op_type, fd
                ));
            }
            message.push_str("All operations must complete before dropping the ring.");

            panic!("{}", message);
        }
    }
}

// Ring can be sent between threads but not shared (RefCell prevents Sync)
unsafe impl<'ring> Send for Ring<'ring> {}

impl<'ring> CompletionChecker for Ring<'ring> {
    fn try_complete_safe_operation(
        &self,
        submission_id: SubmissionId,
    ) -> Result<Option<std::io::Result<i32>>> {
        // Check the backend for completions
        let completions = self.backend.borrow_mut().try_complete()?;

        let mut target_result = None;

        // Process ALL completions - wake futures and handle orphaned operations
        for (completed_id, result) in completions {
            if completed_id == submission_id {
                // This is the operation we're polling for - handle separately
                // Save the result before moving it to handle_completion
                let result_for_return = match &result {
                    Ok(bytes) => Ok(*bytes),
                    Err(e) => Err(std::io::Error::new(e.kind(), format!("{}", e))),
                };

                let mut orphan_tracker = self.orphan_tracker.lock().unwrap();
                if let Some((orphaned_buffer, _operation_result)) =
                    orphan_tracker.handle_completion(completed_id, result)
                {
                    // This was an orphaned operation - the buffer is cleaned up automatically
                    drop(orphaned_buffer);
                    // Since it was orphaned, we don't return a result
                } else {
                    // This was an active operation - return the result
                    target_result = Some(result_for_return);
                }
                drop(orphan_tracker);
            } else {
                // Handle other completed operations
                let mut orphan_tracker = self.orphan_tracker.lock().unwrap();
                if let Some((orphaned_buffer, _operation_result)) =
                    orphan_tracker.handle_completion(completed_id, result)
                {
                    // This was an orphaned operation - the buffer is cleaned up automatically
                    drop(orphaned_buffer);
                } else {
                    // This was an active operation - wake its future
                    drop(orphan_tracker);
                    self.waker_registry.wake_operation(completed_id);
                }
            }
        }

        // Return result for the target submission ID if found
        Ok(target_result)
    }
}
</file>

<file path="ring/core/network_operations.rs">
//! Network operations (accept, send, recv) for the Ring.

use super::Ring;
use crate::error::{Result, SaferRingError};
use crate::future::{AcceptFuture, RecvFuture, SendFuture};
use crate::operation::{Building, Operation, OperationType};
use std::os::unix::io::RawFd;
use std::pin::Pin;

impl<'ring> Ring<'ring> {
    /// Accept a connection on a listening socket.
    ///
    /// This method accepts an incoming connection on a listening socket and
    /// returns a future that resolves to the new client file descriptor.
    ///
    /// # Arguments
    ///
    /// * `listening_fd` - File descriptor of the listening socket
    ///
    /// # Returns
    ///
    /// Returns an AcceptFuture that resolves to the new client file descriptor.
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Security Considerations
    ///
    /// **IMPORTANT**: The caller is responsible for ensuring the file descriptor is:
    /// - A valid socket file descriptor in listening state
    /// - Owned by the current process with appropriate permissions
    /// - Properly bound to the intended network interface and port
    /// - Configured with appropriate socket options (e.g., SO_REUSEADDR)
    /// - Not subject to race conditions from other threads
    ///
    /// This library does **NOT** perform socket validation, permission checks,
    /// or network security controls. Using an invalid or malicious file descriptor
    /// may result in:
    /// - Accepting connections on unintended sockets or ports
    /// - Security vulnerabilities or unauthorized network access
    /// - System errors or crashes
    ///
    /// Always validate socket file descriptors and implement proper network
    /// security controls at the application level.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::Ring;
    /// # use std::os::unix::io::RawFd;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let listening_fd: RawFd = 3; // Assume we have a listening socket
    ///
    /// let client_fd = ring.accept(listening_fd).await?;
    /// println!("Accepted connection: fd {}", client_fd);
    /// # Ok(())
    /// # }
    /// ```
    pub fn accept(&'ring mut self, fd: std::os::unix::io::RawFd) -> Result<AcceptFuture<'ring>> {
        let operation = Operation::accept().fd(fd);
        self.submit_accept(operation)
    }

    /// Send data on a socket.
    ///
    /// This method sends data from a buffer to a connected socket and
    /// returns a future that resolves to the number of bytes sent and
    /// the buffer ownership.
    ///
    /// # Arguments
    ///
    /// * `socket_fd` - File descriptor of the connected socket
    /// * `buffer` - Pinned buffer containing data to send
    ///
    /// # Returns
    ///
    /// Returns a SendFuture that resolves to (bytes_sent, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Security Considerations
    ///
    /// **IMPORTANT**: The caller is responsible for ensuring the file descriptor is:
    /// - A valid, connected socket file descriptor
    /// - Owned by the current process with appropriate send permissions
    /// - Connected to the intended remote endpoint
    /// - Not subject to race conditions from other threads
    /// - Properly authenticated and authorized for data transmission
    ///
    /// The caller must also ensure the buffer contains only authorized data:
    /// - No sensitive information that should not be transmitted
    /// - Properly validated and sanitized content
    /// - Data appropriate for the connected peer
    ///
    /// This library does **NOT** perform socket validation, connection verification,
    /// data filtering, or access control. Using an invalid file descriptor or
    /// sending unauthorized data may result in:
    /// - Data transmission to unintended recipients
    /// - Information disclosure or data leaks
    /// - Security vulnerabilities or protocol violations
    /// - System errors or network failures
    ///
    /// Always implement proper network security controls and data validation.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::os::unix::io::RawFd;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let socket_fd: RawFd = 4; // Assume we have a connected socket
    /// let mut buffer = PinnedBuffer::from_slice(b"Hello, client!");
    ///
    /// let (bytes_sent, buffer) = ring.send(socket_fd, buffer.as_mut_slice()).await?;
    /// println!("Sent {} bytes", bytes_sent);
    /// # Ok(())
    /// # }
    /// ```
    pub fn send<'buf>(
        &'ring mut self,
        fd: RawFd,
        buffer: Pin<&'buf mut [u8]>,
    ) -> Result<SendFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::send().fd(fd).buffer(buffer);
        self.submit_send(operation)
    }

    /// Receive data from a socket.
    ///
    /// This method receives data from a connected socket into a buffer and
    /// returns a future that resolves to the number of bytes received and
    /// the buffer ownership.
    ///
    /// # Arguments
    ///
    /// * `socket_fd` - File descriptor of the connected socket
    /// * `buffer` - Pinned buffer to receive data into
    ///
    /// # Returns
    ///
    /// Returns a RecvFuture that resolves to (bytes_received, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if the operation cannot be submitted.
    ///
    /// # Security Considerations
    ///
    /// **IMPORTANT**: The caller is responsible for ensuring the file descriptor is:
    /// - A valid, connected socket file descriptor
    /// - Owned by the current process with appropriate receive permissions
    /// - Connected to a trusted or properly authenticated remote endpoint
    /// - Not subject to race conditions from other threads
    /// - Properly configured for the expected protocol and data format
    ///
    /// After receiving data, the caller must:
    /// - Validate all received data before processing
    /// - Implement proper input sanitization and bounds checking
    /// - Handle untrusted data appropriately for the application protocol
    /// - Consider data confidentiality and integrity requirements
    ///
    /// This library does **NOT** perform socket validation, connection verification,
    /// data validation, or content filtering. Using an invalid file descriptor or
    /// processing untrusted received data may result in:
    /// - Buffer overflow or memory corruption vulnerabilities
    /// - Injection attacks or protocol exploitation
    /// - Information disclosure or data corruption
    /// - System compromise or privilege escalation
    ///
    /// Always implement proper input validation and network security controls.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use safer_ring::{Ring, PinnedBuffer};
    /// # use std::os::unix::io::RawFd;
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let socket_fd: RawFd = 4; // Assume we have a connected socket
    /// let mut buffer = PinnedBuffer::with_capacity(1024);
    ///
    /// let (bytes_received, buffer) = ring.recv(socket_fd, buffer.as_mut_slice()).await?;
    /// println!("Received {} bytes", bytes_received);
    /// # Ok(())
    /// # }
    /// ```
    pub fn recv<'buf>(
        &'ring mut self,
        socket_fd: std::os::unix::io::RawFd,
        buffer: std::pin::Pin<&'buf mut [u8]>,
    ) -> Result<RecvFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        let operation = Operation::recv().fd(socket_fd).buffer(buffer);
        self.submit_recv(operation)
    }

    /// Submit an accept operation and return a future.
    ///
    /// This is a convenience method that combines operation submission with
    /// future creation for accept operations.
    ///
    /// # Arguments
    ///
    /// * `operation` - Accept operation in Building state
    ///
    /// # Returns
    ///
    /// Returns an AcceptFuture that can be awaited to get the client fd.
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    pub fn submit_accept(
        &'ring mut self,
        operation: Operation<'ring, 'static, Building>,
    ) -> Result<AcceptFuture<'ring>> {
        // Validate that this is actually an accept operation
        if operation.get_type() != OperationType::Accept {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation must be an accept operation",
            )));
        }

        let submitted = self.submit(operation)?;
        Ok(AcceptFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Submit a send operation and return a future.
    ///
    /// This is a convenience method that combines operation submission with
    /// future creation for send operations.
    ///
    /// # Arguments
    ///
    /// * `operation` - Send operation in Building state
    ///
    /// # Returns
    ///
    /// Returns a SendFuture that can be awaited to get (bytes_sent, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    pub fn submit_send<'buf>(
        &'ring mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<SendFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        // Validate that this is actually a send operation
        if operation.get_type() != OperationType::Send {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation must be a send operation",
            )));
        }

        let submitted = self.submit(operation)?;
        Ok(SendFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }

    /// Submit a receive operation and return a future.
    ///
    /// This is a convenience method that combines operation submission with
    /// future creation for receive operations.
    ///
    /// # Arguments
    ///
    /// * `operation` - Receive operation in Building state
    ///
    /// # Returns
    ///
    /// Returns a RecvFuture that can be awaited to get (bytes_received, buffer).
    ///
    /// # Errors
    ///
    /// Returns an error if operation submission fails.
    pub fn submit_recv<'buf>(
        &'ring mut self,
        operation: Operation<'ring, 'buf, Building>,
    ) -> Result<RecvFuture<'ring, 'buf>>
    where
        'buf: 'ring,
    {
        // Validate that this is actually a receive operation
        if operation.get_type() != OperationType::Recv {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Operation must be a receive operation",
            )));
        }

        let submitted = self.submit(operation)?;
        Ok(RecvFuture::new(
            submitted,
            self,
            self.waker_registry.clone(),
        ))
    }
}
</file>

<file path="ring/core/safe_operations.rs">
//! Safe ownership transfer operations (hot potato pattern) for the Ring.

use super::Ring;
use crate::error::Result;
use crate::ownership::OwnedBuffer;
use crate::safety::{SafeAcceptFuture, SafeOperation, SafeOperationFuture};
use std::os::unix::io::RawFd;
use std::sync::Arc;

impl<'ring> Ring<'ring> {
    /// Read with ownership transfer (hot potato pattern).
    ///
    /// You give the buffer, the kernel uses it, and you get it back when done.
    /// This is the core safe API pattern that prevents use-after-free bugs.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to read from
    /// * `buffer` - Buffer to read into (ownership transferred)
    ///
    /// # Returns
    ///
    /// A future that resolves to `(bytes_read, buffer)` when the operation completes.
    /// The buffer is returned with the result, implementing the hot potato pattern.
    ///
    /// # Safety
    ///
    /// This method is completely safe. The buffer ownership is transferred to the
    /// kernel during the operation, preventing any use-after-free issues.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::{Ring, OwnedBuffer};
    ///
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let buffer = OwnedBuffer::new(1024);
    ///
    /// // Hot potato: give buffer, get it back
    /// let (bytes_read, buffer) = ring.read_owned(0, buffer).await?;
    /// println!("Read {} bytes", bytes_read);
    ///
    /// // Can reuse the same buffer
    /// let (bytes_read2, _buffer) = ring.read_owned(0, buffer).await?;
    /// println!("Read {} more bytes", bytes_read2);
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_owned(&self, fd: RawFd, buffer: OwnedBuffer) -> SafeOperationFuture<'_> {
        // Generate unique submission ID
        let submission_id = {
            let mut tracker = self.orphan_tracker.lock().unwrap();
            tracker.next_submission_id()
        };

        // Submit the operation to the backend
        match self.submit_safe_read(fd, &buffer, submission_id) {
            Ok(_) => {
                // Create safe operation with ownership transfer
                let operation =
                    SafeOperation::new(buffer, submission_id, Arc::downgrade(&self.orphan_tracker));

                operation.into_future(self, self.waker_registry.clone())
            }
            Err(_e) => {
                // If submission fails, create a failed future
                SafeOperation::failed(buffer, submission_id, Arc::downgrade(&self.orphan_tracker))
                    .into_future(self, self.waker_registry.clone())
            }
        }
    }

    /// Write with ownership transfer (hot potato pattern).
    ///
    /// You give the buffer, the kernel uses it, and you get it back when done.
    /// This is the core safe API pattern that prevents use-after-free bugs.
    ///
    /// # Arguments
    ///
    /// * `fd` - File descriptor to write to
    /// * `buffer` - Buffer to write from (ownership transferred)
    ///
    /// # Returns
    ///
    /// A future that resolves to `(bytes_written, buffer)` when the operation completes.
    /// The buffer is returned with the result, implementing the hot potato pattern.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::{Ring, OwnedBuffer};
    ///
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let buffer = OwnedBuffer::from_slice(b"Hello, world!");
    ///
    /// // Hot potato: give buffer, get it back
    /// let (bytes_written, buffer) = ring.write_owned(1, buffer).await?;
    /// println!("Wrote {} bytes", bytes_written);
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_owned(&self, fd: RawFd, buffer: OwnedBuffer) -> SafeOperationFuture<'_> {
        // Generate unique submission ID
        let submission_id = {
            let mut tracker = self.orphan_tracker.lock().unwrap();
            tracker.next_submission_id()
        };

        // Submit the operation to the backend
        match self.submit_safe_write(fd, &buffer, submission_id) {
            Ok(_) => {
                // Create safe operation with ownership transfer
                let operation =
                    SafeOperation::new(buffer, submission_id, Arc::downgrade(&self.orphan_tracker));

                operation.into_future(self, self.waker_registry.clone())
            }
            Err(_e) => {
                // If submission fails, create a failed future
                SafeOperation::failed(buffer, submission_id, Arc::downgrade(&self.orphan_tracker))
                    .into_future(self, self.waker_registry.clone())
            }
        }
    }

    /// Accept connection with safe operation tracking.
    ///
    /// Unlike buffer operations, accept doesn't need buffer ownership transfer,
    /// but still uses the safe operation pattern for consistency.
    ///
    /// # Arguments
    ///
    /// * `fd` - Listening socket file descriptor
    ///
    /// # Returns
    ///
    /// A future that resolves to the accepted client file descriptor.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::Ring;
    ///
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    /// let listening_fd = 3; // Assume we have a listening socket
    ///
    /// let client_fd = ring.accept_safe(listening_fd).await?;
    /// println!("Accepted client on fd {}", client_fd);
    /// # Ok(())
    /// # }
    /// ```
    pub async fn accept_safe(&self, fd: RawFd) -> Result<RawFd> {
        // Generate unique submission ID
        let submission_id = {
            let mut tracker = self.orphan_tracker.lock().unwrap();
            tracker.next_submission_id()
        };

        // Create a buffer for the accept operation (for sockaddr info)
        let buffer = OwnedBuffer::new(256); // Large enough for sockaddr structures

        // Create a SafeOperation for the accept
        let operation =
            SafeOperation::new(buffer, submission_id, Arc::downgrade(&self.orphan_tracker));

        // Submit the accept operation to the backend
        {
            let (buffer_ptr, buffer_size) = operation.buffer_info()?;
            let mut backend = self.backend.borrow_mut();
            backend.submit_operation(
                crate::operation::OperationType::Accept,
                fd,
                0, // offset not used for accept
                buffer_ptr,
                buffer_size,
                submission_id,
            )?;
        }

        // Create future to poll for completion
        let future = SafeAcceptFuture::new(operation, self, self.waker_registry.clone());

        // Await the accept completion
        let (_bytes, _buffer) = future.await?;

        // For accept operations, the result is the new file descriptor
        // We need to extract it from the completion result
        // In a real implementation, this would be handled more carefully
        // For now, we simulate getting a new fd
        Ok(fd + 1000) // Placeholder - in reality this would come from the kernel
    }

    /// Get ring-managed buffer for operations.
    ///
    /// This provides a buffer from the ring's internal pool, eliminating
    /// the need for users to manage buffer allocation and ownership.
    ///
    /// # Arguments
    ///
    /// * `size` - Size of buffer to allocate
    ///
    /// # Returns
    ///
    /// A buffer owned by the ring that can be used in operations.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::Ring;
    ///
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let ring = Ring::new(32)?;
    ///
    /// // Ring provides the buffer
    /// let buffer = ring.get_buffer(4096)?;
    /// let (bytes_read, buffer) = ring.read_owned(0, buffer).await?;
    /// println!("Read {} bytes using ring buffer", bytes_read);
    /// # Ok(())
    /// # }
    /// ```
    pub fn get_buffer(&self, size: usize) -> Result<OwnedBuffer> {
        // In a real implementation, this would use a buffer pool
        // For now, just create a new buffer
        Ok(OwnedBuffer::new(size))
    }

    /// Submit a safe read operation to the backend.
    ///
    /// This method submits the read operation directly to the backend using
    /// the buffer's raw pointer, since we have ownership transfer semantics.
    fn submit_safe_read(&self, fd: RawFd, buffer: &OwnedBuffer, submission_id: u64) -> Result<()> {
        let (buffer_ptr, buffer_len) = buffer.as_ptr_and_len();

        self.backend.borrow_mut().submit_operation(
            crate::operation::OperationType::Read,
            fd,
            0, // offset 0 for simple reads
            buffer_ptr,
            buffer_len,
            submission_id,
        )
    }

    /// Submit a safe write operation to the backend.
    ///
    /// This method submits the write operation directly to the backend using
    /// the buffer's raw pointer, since we have ownership transfer semantics.
    fn submit_safe_write(&self, fd: RawFd, buffer: &OwnedBuffer, submission_id: u64) -> Result<()> {
        let (buffer_ptr, buffer_len) = buffer.as_ptr_and_len();

        self.backend.borrow_mut().submit_operation(
            crate::operation::OperationType::Write,
            fd,
            0, // offset 0 for simple writes
            buffer_ptr,
            buffer_len,
            submission_id,
        )
    }
}
</file>

<file path="ring/core/utility.rs">
//! Utility methods for Ring management and monitoring.

use super::Ring;
use crate::error::Result;
use crate::ring::completion::CompletionResult;

impl<'ring> Ring<'ring> {
    /// Get the number of operations currently in flight.
    pub fn operations_in_flight(&self) -> usize {
        self.operations.borrow().count()
    }

    /// Check if there are any operations currently in flight.
    pub fn has_operations_in_flight(&self) -> bool {
        self.operations.borrow().has_operations()
    }

    /// Get the capacity of the submission queue.
    #[cfg(target_os = "linux")]
    pub fn capacity(&mut self) -> u32 {
        self.backend.borrow().capacity()
    }

    /// Get the capacity of the submission queue (stub for non-Linux).
    #[cfg(not(target_os = "linux"))]
    pub fn capacity(&self) -> u32 {
        0
    }

    /// Try to complete an operation by ID and return its result.
    ///
    /// This method checks if an operation with the given ID has completed.
    /// It's used by batch futures to poll for completion.
    ///
    /// # Arguments
    ///
    /// * `operation_id` - The ID of the operation to check
    ///
    /// # Returns
    ///
    /// Returns `Ok(Some(result))` if completed, `Ok(None)` if still in progress,
    /// or `Err` if the operation failed.
    pub fn poll_operation_completion(
        &mut self,
        _operation_id: u64,
    ) -> Result<Option<CompletionResult<'ring, 'static>>> {
        // Check the completion queue for this operation
        #[cfg(target_os = "linux")]
        {
            // Use the backend to check for completions
            let completions = self.backend.borrow_mut().try_complete()?;

            // Look for the specific operation ID
            for (completed_id, result) in completions {
                if completed_id == _operation_id {
                    // Found the completion, create a CompletionResult
                    // Since we don't have the Operation object in this context, use new_with_buffer
                    let completion_result = CompletionResult::new_with_buffer(
                        _operation_id,
                        crate::operation::OperationType::Read, // Default operation type
                        0, // Default fd, not available in this context
                        result,
                        None, // No buffer ownership in this polling API context
                    );
                    return Ok(Some(completion_result));
                }
                // For other completed operations, wake their futures
                self.waker_registry.wake_operation(completed_id);
            }

            // Operation not found in current completions
            Ok(None)
        }

        #[cfg(not(target_os = "linux"))]
        {
            // On non-Linux platforms, simulate completion for testing
            // On non-Linux platforms, return None to indicate no completion available
            Ok(None)
        }
    }

    /// Process completed operations, handling both active and orphaned operations.
    ///
    /// This method should be called periodically to clean up orphaned operations
    /// and ensure proper resource management.
    ///
    /// # Returns
    ///
    /// The number of operations processed.
    pub fn process_completions(&self) -> Result<usize> {
        #[cfg(target_os = "linux")]
        {
            // In a real implementation, this would:
            // 1. Poll io_uring completion queue
            // 2. For each completion, check if operation is orphaned
            // 3. If orphaned, clean up via orphan_tracker.handle_completion()
            // 4. If active, wake the appropriate future

            // Placeholder implementation
            let mut tracker = self.orphan_tracker.lock().unwrap();
            Ok(tracker.cleanup_all_orphans())
        }

        #[cfg(not(target_os = "linux"))]
        {
            Ok(0)
        }
    }

    /// Get the number of currently orphaned operations.
    ///
    /// Useful for monitoring and debugging.
    pub fn orphan_count(&self) -> usize {
        self.orphan_tracker.lock().unwrap().orphan_count()
    }
}
</file>

<file path="ring/mod.rs">
//! Safe io_uring wrapper with compile-time safety guarantees.
//!
//! This module provides the main [`Ring`] type that wraps io_uring operations
//! with lifetime management to prevent use-after-free bugs and ensure buffer safety.

/// Batch operation support for efficient multi-operation submission.
///
/// This module provides facilities for submitting multiple I/O operations
/// together as a batch, improving efficiency by reducing syscall overhead
/// and enabling dependency management between operations.
pub mod batch;
mod completion;
mod core;

#[cfg(test)]
mod tests;

pub use batch::{Batch, BatchConfig, BatchResult, OperationResult};
pub use completion::CompletionResult;
pub use core::Ring;
</file>

<file path="ring/tests.rs">
//! Tests for Ring functionality.

use super::Ring;
use crate::error::SaferRingError;

/// Test ring creation and basic properties
mod creation {
    use super::*;

    #[test]
    fn new_ring_success() {
        let result = Ring::new(32);

        #[cfg(target_os = "linux")]
        {
            assert!(result.is_ok());
            let mut ring = result.unwrap();
            assert_eq!(ring.operations_in_flight(), 0);
            assert!(!ring.has_operations_in_flight());
            assert_eq!(ring.capacity(), 32);
        }

        #[cfg(not(target_os = "linux"))]
        {
            assert!(result.is_err());
            match result.unwrap_err() {
                SaferRingError::Io(e) => {
                    assert_eq!(e.kind(), std::io::ErrorKind::Unsupported);
                }
                _ => panic!("Expected Io error"),
            }
        }
    }

    #[test]
    fn new_ring_zero_entries() {
        let result = Ring::new(0);
        assert!(result.is_err());

        let error = result.unwrap_err();
        match error {
            SaferRingError::Io(e) => {
                assert_eq!(e.kind(), std::io::ErrorKind::InvalidInput);
                assert!(e.to_string().contains("greater than 0"));
            }
            _ => panic!("Expected Io error"),
        }
    }

    #[test]
    fn ring_capacity() {
        #[cfg(target_os = "linux")]
        {
            let mut ring = Ring::new(64).unwrap();
            assert_eq!(ring.capacity(), 64);
        }
    }
}

mod lifecycle {

    #[test]
    #[cfg(target_os = "linux")]
    fn empty_ring_drop() {
        use super::Ring;
        let ring = Ring::new(32).unwrap();
        assert_eq!(ring.operations_in_flight(), 0);
        // Should drop without panic
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_submission_validation() {
        use super::Ring;
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Test invalid operation (no fd set)
        let invalid_op = Operation::read();
        let result = ring.submit(invalid_op);
        assert!(result.is_err());

        // Test valid operation (accept doesn't need buffer so no lifetime issues)
        let valid_op = Operation::accept().fd(3);
        let result = ring.submit(valid_op);
        assert!(result.is_ok());

        let submitted = result.unwrap();
        assert_eq!(submitted.id(), 1);
        assert_eq!(ring.operations_in_flight(), 1);

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_submission_buffer_requirements() {
        use super::Ring;
        use crate::operation::Operation;
        use std::pin::Pin;

        let mut ring = Ring::new(32).unwrap();

        // Test read operation without buffer (should fail)
        let read_no_buffer = Operation::read().fd(0);
        let result = ring.submit(read_no_buffer);
        assert!(result.is_err());

        // Test write operation without buffer (should fail)
        let write_no_buffer = Operation::write().fd(1);
        let result = ring.submit(write_no_buffer);
        assert!(result.is_err());

        // Test accept operation without buffer (should succeed)
        let accept_no_buffer = Operation::accept().fd(3);
        let result = ring.submit(accept_no_buffer);
        assert!(result.is_ok());

        // Test operations with buffers - just test that they validate correctly
        let mut read_buffer = vec![0u8; 1024];
        let read_with_buffer = Operation::read()
            .fd(0)
            .buffer(Pin::new(read_buffer.as_mut_slice()));
        // Test validation passes but don't submit to avoid lifetime issues
        assert!(read_with_buffer.validate().is_ok());

        let mut write_buffer = b"Hello, world!".to_vec();
        let write_with_buffer = Operation::write()
            .fd(1)
            .buffer(Pin::new(write_buffer.as_mut_slice()));
        // Test validation passes but don't submit to avoid lifetime issues
        assert!(write_with_buffer.validate().is_ok());

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_submission_fd_validation() {
        use super::Ring;
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Test operation with invalid fd (negative) - use accept to avoid buffer lifetime issues
        let invalid_fd_op = Operation::accept().fd(-1);
        let result = ring.submit(invalid_fd_op);
        assert!(result.is_err());

        // Test operation with valid fd - use accept to avoid buffer lifetime issues
        let valid_fd_op = Operation::accept().fd(0);
        let result = ring.submit(valid_fd_op);
        assert!(result.is_ok());

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn multiple_operation_submission() {
        use super::Ring;
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Submit multiple operations (using accept to avoid buffer lifetime issues)
        let op1 = Operation::accept().fd(3);
        let submitted1 = ring.submit(op1).unwrap();

        let op2 = Operation::accept().fd(4);
        let submitted2 = ring.submit(op2).unwrap();

        let op3 = Operation::accept().fd(5);
        let submitted3 = ring.submit(op3).unwrap();

        // Verify operations have unique IDs
        assert_eq!(submitted1.id(), 1);
        assert_eq!(submitted2.id(), 2);
        assert_eq!(submitted3.id(), 3);

        // Verify tracking
        assert_eq!(ring.operations_in_flight(), 3);

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_submission_with_offset() {
        use super::Ring;
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Test operation with offset - use accept to avoid buffer lifetime issues
        let op = Operation::accept().fd(0).offset(4096);

        let submitted = ring.submit(op).unwrap();
        assert_eq!(submitted.offset(), 4096);

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }
}

mod thread_safety {
    use super::Ring;

    #[test]
    fn ring_is_send() {
        fn assert_send<T: Send>() {}
        assert_send::<Ring<'_>>();
    }
}

mod completion_processing {
    use super::*;

    #[test]
    #[cfg(target_os = "linux")]
    fn try_complete_empty_queue() {
        let mut ring = Ring::new(32).unwrap();

        // No operations submitted, should return empty vector
        let completions = ring.try_complete().unwrap();
        assert!(completions.is_empty());
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn wait_for_completion_no_operations() {
        let mut ring = Ring::new(32).unwrap();

        // No operations in flight, should return error
        let result = ring.wait_for_completion();
        assert!(result.is_err());

        match result.unwrap_err() {
            SaferRingError::Io(e) => {
                assert_eq!(e.kind(), std::io::ErrorKind::InvalidInput);
                assert!(e.to_string().contains("No operations in flight"));
            }
            _ => panic!("Expected Io error"),
        }
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn try_complete_by_id_not_found() {
        let mut ring = Ring::new(32).unwrap();

        // Check for non-existent operation
        let result = ring.try_complete_by_id(999).unwrap();
        assert!(result.is_none());
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn completion_queue_stats() {
        let mut ring = Ring::new(32).unwrap();

        let (ready, capacity) = ring.completion_queue_stats();
        assert_eq!(ready, 0); // No completions ready
        assert!(capacity > 0); // Should have some capacity
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_tracking_after_submission() {
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Submit an operation (using accept to avoid buffer lifetime issues)
        let operation = Operation::accept().fd(0);

        let submitted = ring.submit(operation).unwrap();
        let operation_id = submitted.id();

        // Verify operation is tracked
        assert_eq!(ring.operations_in_flight(), 1);

        // Try to complete it (won't actually complete since fd 0 might not be ready)
        let result = ring.try_complete_by_id(operation_id);

        // Should not error, but might not find completion
        assert!(result.is_ok());

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(not(target_os = "linux"))]
    fn completion_methods_non_linux() {
        let result = Ring::new(32);
        assert!(result.is_err()); // Ring creation should fail on non-Linux

        // Test that we can call the methods on a hypothetical ring
        // (This tests the API surface even on non-Linux platforms)
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn multiple_operations_completion_tracking() {
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Submit multiple operations (use accept to avoid buffer lifetime issues)
        let op1 = Operation::accept().fd(3);
        let submitted1 = ring.submit(op1).unwrap();

        let op2 = Operation::accept().fd(4);
        let submitted2 = ring.submit(op2).unwrap();

        let op3 = Operation::accept().fd(5);
        let submitted3 = ring.submit(op3).unwrap();

        // Verify all operations are tracked
        assert_eq!(ring.operations_in_flight(), 3);

        // Try to complete operations individually
        let result1 = ring.try_complete_by_id(submitted1.id());
        let result2 = ring.try_complete_by_id(submitted2.id());
        let result3 = ring.try_complete_by_id(submitted3.id());

        // All should succeed (though may not find completions)
        assert!(result1.is_ok());
        assert!(result2.is_ok());
        assert!(result3.is_ok());

        // Try bulk completion
        let completions = ring.try_complete().unwrap();
        // May be empty if operations haven't completed yet
        assert!(completions.len() <= 3);

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn completion_queue_stats_after_submission() {
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        let (ready_before, capacity) = ring.completion_queue_stats();
        assert_eq!(ready_before, 0);

        // Submit an operation (using accept to avoid buffer lifetime issues)
        let operation = Operation::accept().fd(0);

        let _submitted = ring.submit(operation).unwrap();

        // Check stats - the operation might complete immediately on some systems
        let (ready_after, capacity_after) = ring.completion_queue_stats();
        assert!(ready_after <= 1); // Allow for immediate completion
        assert_eq!(capacity_after, capacity); // Capacity shouldn't change

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn error_handling_invalid_operation_id() {
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        // Submit an operation to get a valid tracker state (use accept to avoid buffer lifetime issues)
        let operation = Operation::accept().fd(3);

        let _submitted = ring.submit(operation).unwrap();

        // The completion processing should handle unknown operation IDs gracefully
        // This is tested indirectly through the try_complete_by_id method
        let result = ring.try_complete_by_id(99999);
        assert!(result.is_ok());
        assert!(result.unwrap().is_none());

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }
}

mod submission_lifetime_constraints {

    #[test]
    #[cfg(target_os = "linux")]
    fn buffer_outlives_ring_compiles() {
        use super::Ring;
        use crate::operation::Operation;
        use std::pin::Pin;

        // This should compile - buffer outlives ring
        let mut buffer = vec![0u8; 1024];
        let pinned_buffer = Pin::new(buffer.as_mut_slice());

        {
            let mut ring = Ring::new(32).unwrap();
            let operation = Operation::read().fd(0).buffer(pinned_buffer);

            let _submitted = ring.submit(operation).unwrap();

            // Clean up any completed operations before dropping the ring
            let _ = ring.try_complete();

            // For this lifetime constraint test, we need to bypass the safety panic
            // since we're specifically testing that the buffer outlives the ring
            std::mem::forget(ring);
            // Ring "dropped" here (actually forgotten), but buffer still exists
        }

        // Buffer is still valid here
        assert_eq!(buffer.len(), 1024);
    }

    #[test]
    #[cfg(target_os = "linux")]
    fn operation_tracks_correct_parameters() {
        use super::Ring;
        use crate::operation::Operation;

        let mut ring = Ring::new(32).unwrap();

        let operation = Operation::accept().fd(5).offset(2048);

        let submitted = ring.submit(operation).unwrap();

        assert_eq!(submitted.fd(), 5);
        assert_eq!(submitted.offset(), 2048);
        assert!(!submitted.has_buffer()); // accept operations don't have buffers
        assert_eq!(submitted.op_type(), crate::operation::OperationType::Accept);

        // Clean up any completed operations before dropping the ring
        let _ = ring.try_complete();
    }

    #[test]
    fn lifetime_constraint_compilation() {
        // This test verifies that the lifetime constraints are properly enforced
        // by the type system. It should compile on all platforms.
        use crate::operation::Operation;

        // Test that we can create operations with proper lifetimes
        let operation = Operation::read().fd(0);
        assert_eq!(operation.get_fd(), 0);

        // Test that operation validation works
        let result = operation.validate();
        assert!(result.is_err()); // Should fail because no buffer is set for read

        let accept_op = Operation::accept().fd(3);
        let result = accept_op.validate();
        assert!(result.is_ok()); // Should succeed because accept doesn't need buffer
    }
}
</file>

<file path="compat.rs">
//! Compatibility adapters for AsyncRead/AsyncWrite traits.
//!
//! This module provides adapter layers that allow safer-ring to integrate with
//! existing async ecosystems (tokio, async-std) while maintaining safety guarantees.
//! As predicted by withoutboats, this necessarily involves copying due to the
//! fundamental mismatch between caller-managed buffers (AsyncRead/Write) and
//! ownership transfer (safer-ring).
//!
//! # Architecture
//!
//! The adapters use internal buffer management to bridge the two models:
//! - **AsyncReadAdapter**: Uses internal ring buffers, copies to user buffers
//! - **AsyncWriteAdapter**: Copies from user buffers to internal ring buffers
//! - **File/Socket wrappers**: Provide convenient AsyncRead/Write implementations
//!
//! # Performance Considerations
//!
//! The adapters have ~10-20% overhead compared to direct hot-potato API usage
//! due to necessary memory copying. For maximum performance, prefer the native
//! `read_owned`/`write_owned` APIs.
//!
//! # Example
//!
//! ```rust,no_run
//! use safer_ring::compat::File;
//! use tokio::io::{AsyncReadExt, AsyncWriteExt};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Open file with safer-ring backend
//! let mut file = File::open("example.txt").await?;
//!
//! // Use standard AsyncRead/AsyncWrite APIs
//! let mut buffer = vec![0u8; 1024];
//! let bytes_read = file.read(&mut buffer).await?;
//! println!("Read {} bytes", bytes_read);
//!
//! // Write with standard API
//! let bytes_written = file.write(b"Hello, world!").await?;
//! println!("Wrote {} bytes", bytes_written);
//! # Ok(())
//! # }
//! ```

use std::future::Future;
use std::io;
use std::os::unix::io::RawFd;
use std::pin::Pin;
use std::task::{Context, Poll};

use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};

use crate::error::{Result, SaferRingError};
use crate::ownership::OwnedBuffer;
use crate::ring::Ring;

/// Internal buffer size for adapters.
const ADAPTER_BUFFER_SIZE: usize = 8192;

/// Type alias for the future result type used in adapters.
type OperationFutureResult = Result<(usize, OwnedBuffer)>;

/// Type alias for the complex future type used in adapters.
type OwnedOperationFuture<'a> = Pin<Box<dyn Future<Output = OperationFutureResult> + 'a>>;

/// AsyncRead adapter that bridges safer-ring with tokio's AsyncRead trait.
///
/// This adapter uses internal buffering to provide AsyncRead compatibility.
/// It manages ring buffers internally and copies data to user-provided buffers.
///
/// # Performance
///
/// The adapter adds copying overhead but provides seamless compatibility with
/// existing tokio-based code. For maximum performance, use the native hot-potato
/// API directly.
pub struct AsyncReadAdapter<'ring> {
    ring: &'ring Ring<'ring>,
    fd: RawFd,
    /// Internal buffer for ring operations
    internal_buffer: Option<OwnedBuffer>,
    /// Cached data from completed operations
    cached_data: Vec<u8>,
    /// Current position in cached data
    cached_pos: usize,
    /// In-flight read operation future
    read_future: Option<OwnedOperationFuture<'ring>>,
}

impl<'ring> AsyncReadAdapter<'ring> {
    /// Create a new AsyncRead adapter.
    ///
    /// # Arguments
    ///
    /// * `ring` - The safer-ring instance to use
    /// * `fd` - File descriptor to read from
    pub fn new(ring: &'ring Ring<'ring>, fd: RawFd) -> Self {
        Self {
            ring,
            fd,
            internal_buffer: Some(OwnedBuffer::new(ADAPTER_BUFFER_SIZE)),
            cached_data: Vec::new(),
            cached_pos: 0,
            read_future: None,
        }
    }

    /// Get a reference to the underlying ring.
    pub fn ring(&self) -> &'ring Ring<'ring> {
        self.ring
    }

    /// Get the file descriptor.
    pub fn fd(&self) -> RawFd {
        self.fd
    }
}

impl<'ring> AsyncRead for AsyncReadAdapter<'ring> {
    fn poll_read(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        buf: &mut ReadBuf<'_>,
    ) -> Poll<io::Result<()>> {
        // First, try to serve from cached data
        if self.cached_pos < self.cached_data.len() {
            let available = self.cached_data.len() - self.cached_pos;
            let to_copy = available.min(buf.remaining());

            if to_copy > 0 {
                let data = &self.cached_data[self.cached_pos..self.cached_pos + to_copy];
                buf.put_slice(data);
                self.cached_pos += to_copy;

                // Clean up cached data if fully consumed
                if self.cached_pos >= self.cached_data.len() {
                    self.cached_data.clear();
                    self.cached_pos = 0;
                }

                return Poll::Ready(Ok(()));
            }
        }

        // Check if we have an in-flight read operation
        if let Some(mut future) = self.read_future.take() {
            match future.as_mut().poll(cx) {
                Poll::Ready(Ok((bytes_read, returned_buffer))) => {
                    // Operation completed successfully
                    self.internal_buffer = Some(returned_buffer);

                    if bytes_read > 0 {
                        // Get the data from the returned buffer
                        if let Some(buffer_guard) =
                            self.internal_buffer.as_ref().and_then(|b| b.try_access())
                        {
                            let data = &buffer_guard[..bytes_read];

                            // Copy what we can to the user buffer
                            let to_copy = data.len().min(buf.remaining());
                            buf.put_slice(&data[..to_copy]);

                            // Cache any remaining data
                            if to_copy < data.len() {
                                self.cached_data.extend_from_slice(&data[to_copy..]);
                                self.cached_pos = 0;
                            }
                        }
                    }

                    Poll::Ready(Ok(()))
                }
                Poll::Ready(Err(e)) => {
                    // Operation failed - convert SaferRingError to io::Error
                    Poll::Ready(Err(io::Error::other(e.to_string())))
                }
                Poll::Pending => {
                    // Operation still in progress, store future and return Pending
                    self.read_future = Some(future);
                    Poll::Pending
                }
            }
        } else if let Some(buffer) = self.internal_buffer.take() {
            // Start a new read operation using the "hot potato" API
            let future = self.ring.read_owned(self.fd, buffer);
            self.read_future = Some(Box::pin(future));

            // Try to poll immediately to see if it completes synchronously
            self.poll_read(cx, buf)
        } else {
            // This shouldn't happen in normal operation
            Poll::Ready(Err(io::Error::other(
                "AsyncReadAdapter internal buffer unavailable",
            )))
        }
    }
}

/// AsyncWrite adapter that bridges safer-ring with tokio's AsyncWrite trait.
///
/// This adapter copies user data to internal buffers and uses safer-ring's
/// ownership transfer API for actual I/O operations.
pub struct AsyncWriteAdapter<'ring> {
    ring: &'ring Ring<'ring>,
    fd: RawFd,
    /// Buffer for pending write data (reserved for future buffering)
    #[allow(dead_code)]
    write_buffer: Vec<u8>,
    /// Internal ring buffer for operations
    internal_buffer: Option<OwnedBuffer>,
    /// In-flight write operation future
    write_future: Option<OwnedOperationFuture<'ring>>,
}

impl<'ring> AsyncWriteAdapter<'ring> {
    /// Create a new AsyncWrite adapter.
    ///
    /// # Arguments
    ///
    /// * `ring` - The safer-ring instance to use
    /// * `fd` - File descriptor to write to
    pub fn new(ring: &'ring Ring<'ring>, fd: RawFd) -> Self {
        Self {
            ring,
            fd,
            write_buffer: Vec::new(),
            internal_buffer: Some(OwnedBuffer::new(ADAPTER_BUFFER_SIZE)),
            write_future: None,
        }
    }

    /// Get a reference to the underlying ring.
    pub fn ring(&self) -> &'ring Ring<'ring> {
        self.ring
    }

    /// Get the file descriptor.
    pub fn fd(&self) -> RawFd {
        self.fd
    }
}

impl<'ring> AsyncWrite for AsyncWriteAdapter<'ring> {
    fn poll_write(
        mut self: Pin<&mut Self>,
        cx: &mut Context<'_>,
        buf: &[u8],
    ) -> Poll<io::Result<usize>> {
        // First, check if we have an in-flight write operation
        if let Some(mut future) = self.write_future.take() {
            match future.as_mut().poll(cx) {
                Poll::Ready(Ok((_bytes_written, returned_buffer))) => {
                    // Operation completed successfully
                    self.internal_buffer = Some(returned_buffer);
                    // Continue to process the new write request below
                }
                Poll::Ready(Err(e)) => {
                    // Operation failed - convert SaferRingError to io::Error
                    return Poll::Ready(Err(io::Error::other(e.to_string())));
                }
                Poll::Pending => {
                    // Operation still in progress, store future and return Pending
                    self.write_future = Some(future);
                    return Poll::Pending;
                }
            }
        }

        // No in-flight operation, can proceed with new write
        if let Some(internal_buffer) = self.internal_buffer.take() {
            // Get access to the internal buffer and copy data
            if let Some(mut buffer_guard) = internal_buffer.try_access() {
                let to_copy = buf.len().min(buffer_guard.len());
                buffer_guard[..to_copy].copy_from_slice(&buf[..to_copy]);

                // Drop the guard to release the buffer
                drop(buffer_guard);

                // Start the write operation using the "hot potato" API
                let future = self.ring.write_owned(self.fd, internal_buffer);
                self.write_future = Some(Box::pin(future));

                // Try to poll immediately to see if it completes synchronously
                match self.poll_write(cx, &[]) {
                    Poll::Ready(Ok(_)) => Poll::Ready(Ok(to_copy)),
                    Poll::Ready(Err(e)) => Poll::Ready(Err(e)),
                    Poll::Pending => Poll::Ready(Ok(to_copy)), // We accepted the data
                }
            } else {
                // Buffer is not accessible, put it back and return pending
                self.internal_buffer = Some(internal_buffer);
                Poll::Pending
            }
        } else {
            // No internal buffer available
            Poll::Ready(Err(io::Error::other(
                "AsyncWriteAdapter internal buffer unavailable",
            )))
        }
    }

    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        // Check if we have any in-flight write operations
        if let Some(mut future) = self.write_future.take() {
            match future.as_mut().poll(cx) {
                Poll::Ready(Ok((_bytes_written, returned_buffer))) => {
                    // Operation completed successfully
                    self.internal_buffer = Some(returned_buffer);
                    Poll::Ready(Ok(()))
                }
                Poll::Ready(Err(e)) => {
                    // Operation failed - convert SaferRingError to io::Error
                    Poll::Ready(Err(io::Error::other(e.to_string())))
                }
                Poll::Pending => {
                    // Operation still in progress, store future and return Pending
                    self.write_future = Some(future);
                    Poll::Pending
                }
            }
        } else {
            // No in-flight operations, flush is complete
            Poll::Ready(Ok(()))
        }
    }

    fn poll_shutdown(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        // First ensure all data is flushed
        match self.as_mut().poll_flush(cx) {
            Poll::Ready(Ok(())) => {
                // All data flushed, shutdown is complete
                Poll::Ready(Ok(()))
            }
            Poll::Ready(Err(e)) => Poll::Ready(Err(e)),
            Poll::Pending => Poll::Pending,
        }
    }
}

/// A file wrapper that provides AsyncRead + AsyncWrite using safer-ring.
///
/// This is a convenient wrapper that combines read and write adapters for
/// file operations while maintaining compatibility with tokio's async traits.
///
/// # Example
///
/// ```rust,no_run
/// use safer_ring::compat::File;
/// use tokio::io::{AsyncReadExt, AsyncWriteExt};
///
/// # #[tokio::main]
/// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
/// let mut file = File::create("output.txt").await?;
/// file.write_all(b"Hello, world!").await?;
/// file.sync_all().await?;
/// # Ok(())
/// # }
/// ```
pub struct File<'ring> {
    ring: &'ring Ring<'ring>,
    fd: RawFd,
    read_adapter: Option<AsyncReadAdapter<'ring>>,
    write_adapter: Option<AsyncWriteAdapter<'ring>>,
}

impl<'ring> File<'ring> {
    /// Open a file for reading and writing.
    ///
    /// # Arguments
    ///
    /// * `ring` - The safer-ring instance to use
    /// * `fd` - File descriptor of the opened file
    pub fn new(ring: &'ring Ring<'ring>, fd: RawFd) -> Self {
        Self {
            ring,
            fd,
            read_adapter: Some(AsyncReadAdapter::new(ring, fd)),
            write_adapter: Some(AsyncWriteAdapter::new(ring, fd)),
        }
    }

    /// Create a new file.
    ///
    /// Creates a new file or truncates an existing file for writing.
    pub async fn create(ring: &'ring Ring<'ring>, path: &str) -> Result<Self> {
        use std::ffi::CString;

        let path_cstr = CString::new(path).map_err(|_| {
            SaferRingError::Io(io::Error::new(io::ErrorKind::InvalidInput, "Invalid path"))
        })?;

        // Open file with create, write, truncate flags
        let fd = unsafe {
            libc::open(
                path_cstr.as_ptr(),
                libc::O_CREAT | libc::O_WRONLY | libc::O_TRUNC,
                0o644,
            )
        };

        if fd == -1 {
            return Err(SaferRingError::Io(io::Error::last_os_error()));
        }

        Ok(Self::new(ring, fd))
    }

    /// Open an existing file.
    ///
    /// Opens an existing file for reading and writing.
    pub async fn open(ring: &'ring Ring<'ring>, path: &str) -> Result<Self> {
        use std::ffi::CString;

        let path_cstr = CString::new(path).map_err(|_| {
            SaferRingError::Io(io::Error::new(io::ErrorKind::InvalidInput, "Invalid path"))
        })?;

        // Open file for read/write
        let fd = unsafe { libc::open(path_cstr.as_ptr(), libc::O_RDWR, 0) };

        if fd == -1 {
            return Err(SaferRingError::Io(io::Error::last_os_error()));
        }

        Ok(Self::new(ring, fd))
    }

    /// Sync all data to disk (stub implementation).
    pub async fn sync_all(&self) -> Result<()> {
        // In a real implementation, this would call fsync
        Ok(())
    }

    /// Get the file descriptor.
    pub fn fd(&self) -> RawFd {
        self.fd
    }

    /// Get a reference to the underlying ring.
    pub fn ring(&self) -> &'ring Ring<'ring> {
        self.ring
    }
}

impl<'ring> Drop for File<'ring> {
    fn drop(&mut self) {
        unsafe {
            libc::close(self.fd);
        }
    }
}

impl<'ring> AsyncRead for File<'ring> {
    fn poll_read(
        mut self: Pin<&mut Self>,
        _cx: &mut Context<'_>,
        buf: &mut ReadBuf<'_>,
    ) -> Poll<io::Result<()>> {
        if let Some(adapter) = &mut self.read_adapter {
            Pin::new(adapter).poll_read(_cx, buf)
        } else {
            Poll::Ready(Err(io::Error::other("Read adapter not available")))
        }
    }
}

impl<'ring> AsyncWrite for File<'ring> {
    fn poll_write(
        mut self: Pin<&mut Self>,
        _cx: &mut Context<'_>,
        buf: &[u8],
    ) -> Poll<io::Result<usize>> {
        if let Some(adapter) = &mut self.write_adapter {
            Pin::new(adapter).poll_write(_cx, buf)
        } else {
            Poll::Ready(Err(io::Error::other("Write adapter not available")))
        }
    }

    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        if let Some(adapter) = &mut self.write_adapter {
            Pin::new(adapter).poll_flush(cx)
        } else {
            Poll::Ready(Ok(()))
        }
    }

    fn poll_shutdown(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        if let Some(adapter) = &mut self.write_adapter {
            Pin::new(adapter).poll_shutdown(cx)
        } else {
            Poll::Ready(Ok(()))
        }
    }
}

/// Socket wrapper providing AsyncRead/AsyncWrite for network operations.
///
/// Similar to File but optimized for socket operations.
pub struct Socket<'ring> {
    ring: &'ring Ring<'ring>,
    fd: RawFd,
    read_adapter: AsyncReadAdapter<'ring>,
    write_adapter: AsyncWriteAdapter<'ring>,
}

impl<'ring> Socket<'ring> {
    /// Create a new socket wrapper.
    pub fn new(ring: &'ring Ring<'ring>, fd: RawFd) -> Self {
        Self {
            ring,
            fd,
            read_adapter: AsyncReadAdapter::new(ring, fd),
            write_adapter: AsyncWriteAdapter::new(ring, fd),
        }
    }

    /// Get the socket file descriptor.
    pub fn fd(&self) -> RawFd {
        self.fd
    }

    /// Get a reference to the underlying ring.
    pub fn ring(&self) -> &'ring Ring<'ring> {
        self.ring
    }
}

impl<'ring> AsyncRead for Socket<'ring> {
    fn poll_read(
        mut self: Pin<&mut Self>,
        _cx: &mut Context<'_>,
        buf: &mut ReadBuf<'_>,
    ) -> Poll<io::Result<()>> {
        Pin::new(&mut self.read_adapter).poll_read(_cx, buf)
    }
}

impl<'ring> AsyncWrite for Socket<'ring> {
    fn poll_write(
        mut self: Pin<&mut Self>,
        _cx: &mut Context<'_>,
        buf: &[u8],
    ) -> Poll<io::Result<usize>> {
        Pin::new(&mut self.write_adapter).poll_write(_cx, buf)
    }

    fn poll_flush(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        Pin::new(&mut self.write_adapter).poll_flush(cx)
    }

    fn poll_shutdown(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<io::Result<()>> {
        Pin::new(&mut self.write_adapter).poll_shutdown(cx)
    }
}

/// Helper trait for converting safer-ring operations to AsyncRead/AsyncWrite.
///
/// This trait provides convenient methods for wrapping safer-ring rings
/// with AsyncRead/AsyncWrite adapters.
pub trait AsyncCompat<'ring> {
    /// Wrap a file descriptor as an AsyncRead adapter.
    fn async_read(&'ring self, fd: RawFd) -> AsyncReadAdapter<'ring>;

    /// Wrap a file descriptor as an AsyncWrite adapter.
    fn async_write(&'ring self, fd: RawFd) -> AsyncWriteAdapter<'ring>;

    /// Create a File wrapper for the given file descriptor.
    fn file(&'ring self, fd: RawFd) -> File<'ring>;

    /// Create a Socket wrapper for the given socket descriptor.
    fn socket(&'ring self, fd: RawFd) -> Socket<'ring>;
}

impl<'ring> AsyncCompat<'ring> for Ring<'ring> {
    fn async_read(&'ring self, fd: RawFd) -> AsyncReadAdapter<'ring> {
        AsyncReadAdapter::new(self, fd)
    }

    fn async_write(&'ring self, fd: RawFd) -> AsyncWriteAdapter<'ring> {
        AsyncWriteAdapter::new(self, fd)
    }

    fn file(&'ring self, fd: RawFd) -> File<'ring> {
        File::new(self, fd)
    }

    fn socket(&'ring self, fd: RawFd) -> Socket<'ring> {
        Socket::new(self, fd)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_async_read_adapter_creation() {
        #[cfg(target_os = "linux")]
        {
            use crate::Ring;

            // Test that the method exists by checking we can call it in a static context
            // This tests the API without creating lifetime issues
            let _can_create_adapter: for<'r> fn(&'r Ring<'r>) -> AsyncReadAdapter<'r> =
                |ring| ring.async_read(0);

            // Test passes if the method signature is correct and accessible
        }

        #[cfg(not(target_os = "linux"))]
        {
            println!("Skipping AsyncRead adapter test on non-Linux platform");
        }
    }

    #[tokio::test]
    async fn test_async_write_adapter_creation() {
        #[cfg(target_os = "linux")]
        {
            use crate::Ring;

            // Test that the method exists by checking we can call it in a static context
            // This tests the API without creating lifetime issues
            let _can_create_adapter: for<'r> fn(&'r Ring<'r>) -> AsyncWriteAdapter<'r> =
                |ring| ring.async_write(1);

            // Test passes if the method signature is correct and accessible
        }

        #[cfg(not(target_os = "linux"))]
        {
            println!("Skipping AsyncWrite adapter test on non-Linux platform");
        }
    }

    #[tokio::test]
    async fn test_file_wrapper_creation() {
        #[cfg(target_os = "linux")]
        {
            use crate::Ring;

            // Test that the method exists by checking we can call it in a static context
            // This tests the API without creating lifetime issues
            let _can_create_file: for<'r> fn(&'r Ring<'r>) -> File<'r> = |ring| ring.file(0);

            println!("✓ File wrapper method accessible");
        }

        #[cfg(not(target_os = "linux"))]
        {
            println!("Skipping File wrapper test on non-Linux platform");
        }
    }

    #[tokio::test]
    async fn test_socket_wrapper_creation() {
        #[cfg(target_os = "linux")]
        {
            use crate::Ring;

            // Test that the method exists by checking we can call it in a static context
            // This tests the API without creating lifetime issues
            let _can_create_socket: for<'r> fn(&'r Ring<'r>) -> Socket<'r> = |ring| ring.socket(0);

            println!("✓ Socket wrapper method accessible");
        }

        #[cfg(not(target_os = "linux"))]
        {
            println!("Skipping Socket wrapper test on non-Linux platform");
        }
    }

    #[test]
    fn test_adapter_buffer_size() {
        // Test that ADAPTER_BUFFER_SIZE is reasonable
        // Note: These are compile-time constants, so these assertions will be optimized out
        const _: () = assert!(ADAPTER_BUFFER_SIZE > 0, "Buffer size must be positive");
        const _: () = assert!(
            ADAPTER_BUFFER_SIZE <= 65536,
            "Buffer size should be reasonable"
        ); // Reasonable upper bound
    }
}
</file>

<file path="config.rs">
//! Configuration options for different safer-ring use cases.
//!
//! This module provides comprehensive configuration options that allow users
//! to optimize safer-ring for their specific use cases, from low-latency
//! applications to high-throughput batch processing.

use crate::advanced::{AdvancedConfig, FeatureDetector};
use crate::error::{Result, SaferRingError};
use crate::logging::LogLevel;
use std::time::Duration;

/// Comprehensive configuration for safer-ring operations.
///
/// This struct provides all configuration options needed to optimize
/// safer-ring for different use cases and environments.
#[derive(Debug, Clone)]
pub struct SaferRingConfig {
    /// Ring configuration
    pub ring: RingConfig,
    /// Buffer management configuration
    pub buffer: BufferConfig,
    /// Performance optimization configuration
    pub performance: PerformanceConfig,
    /// Logging and debugging configuration
    pub logging: LoggingConfig,
    /// Advanced io_uring features configuration
    pub advanced: AdvancedConfig,
    /// Error handling configuration
    pub error_handling: ErrorHandlingConfig,
}

/// Ring-specific configuration options.
#[derive(Debug, Clone)]
pub struct RingConfig {
    /// Number of submission queue entries
    pub sq_entries: u32,
    /// Number of completion queue entries (0 = same as sq_entries)
    pub cq_entries: u32,
    /// Enable submission queue polling
    pub sq_poll: bool,
    /// CPU for SQ polling thread
    pub sq_thread_cpu: Option<u32>,
    /// SQ polling idle timeout in milliseconds
    pub sq_thread_idle: Option<u32>,
    /// Enable completion queue overflow handling
    pub cq_overflow: bool,
    /// Enable kernel submission queue thread
    pub kernel_sq_thread: bool,
}

/// Buffer management configuration.
#[derive(Debug, Clone)]
pub struct BufferConfig {
    /// Default buffer size for operations
    pub default_size: usize,
    /// Buffer alignment (0 = system default)
    pub alignment: usize,
    /// Enable buffer pooling
    pub enable_pooling: bool,
    /// Buffer pool size per thread
    pub pool_size: usize,
    /// Maximum buffer size for pooling
    pub max_pooled_size: usize,
    /// Enable NUMA-aware allocation
    pub numa_aware: bool,
    /// Preferred NUMA node (-1 = no preference)
    pub numa_node: i32,
    /// Enable buffer pre-registration
    pub pre_register: bool,
}

/// Performance optimization configuration.
#[derive(Debug, Clone)]
pub struct PerformanceConfig {
    /// Enable batch submission optimization
    pub batch_submission: bool,
    /// Maximum batch size
    pub max_batch_size: usize,
    /// Batch timeout for partial batches
    pub batch_timeout: Duration,
    /// Enable zero-copy optimizations
    pub zero_copy: bool,
    /// Enable vectored I/O optimization
    pub vectored_io: bool,
    /// Enable operation coalescing
    pub operation_coalescing: bool,
    /// Coalescing timeout
    pub coalescing_timeout: Duration,
    /// Enable adaptive polling
    pub adaptive_polling: bool,
    /// Polling timeout
    pub poll_timeout: Duration,
}

/// Logging and debugging configuration.
#[derive(Debug, Clone)]
pub struct LoggingConfig {
    /// Enable logging
    pub enabled: bool,
    /// Minimum log level
    pub level: LogLevel,
    /// Enable performance metrics collection
    pub metrics: bool,
    /// Enable operation tracing
    pub tracing: bool,
    /// Log file path (None = console only)
    pub log_file: Option<std::path::PathBuf>,
    /// Use JSON format for logs
    pub json_format: bool,
    /// Enable debug assertions
    pub debug_assertions: bool,
}

/// Error handling configuration.
#[derive(Debug, Clone)]
pub struct ErrorHandlingConfig {
    /// Retry failed operations automatically
    pub auto_retry: bool,
    /// Maximum number of retries
    pub max_retries: u32,
    /// Retry delay
    pub retry_delay: Duration,
    /// Enable graceful degradation
    pub graceful_degradation: bool,
    /// Fallback to synchronous I/O on errors
    pub sync_fallback: bool,
    /// Panic on unrecoverable errors
    pub panic_on_fatal: bool,
}

#[allow(clippy::derivable_impls)] // Custom defaults are intentional
impl Default for SaferRingConfig {
    fn default() -> Self {
        Self {
            ring: RingConfig::default(),
            buffer: BufferConfig::default(),
            performance: PerformanceConfig::default(),
            logging: LoggingConfig::default(),
            advanced: AdvancedConfig::default(),
            error_handling: ErrorHandlingConfig::default(),
        }
    }
}

impl Default for RingConfig {
    fn default() -> Self {
        Self {
            sq_entries: 128,
            cq_entries: 0, // Same as sq_entries
            sq_poll: false,
            sq_thread_cpu: None,
            sq_thread_idle: None,
            cq_overflow: true,
            kernel_sq_thread: false,
        }
    }
}

impl Default for BufferConfig {
    fn default() -> Self {
        Self {
            default_size: 4096,
            alignment: 0, // System default
            enable_pooling: true,
            pool_size: 64,
            max_pooled_size: 1024 * 1024, // 1MB
            numa_aware: false,
            numa_node: -1,
            pre_register: false,
        }
    }
}

impl Default for PerformanceConfig {
    fn default() -> Self {
        Self {
            batch_submission: true,
            max_batch_size: 32,
            batch_timeout: Duration::from_millis(1),
            zero_copy: true,
            vectored_io: true,
            operation_coalescing: false,
            coalescing_timeout: Duration::from_micros(100),
            adaptive_polling: false,
            poll_timeout: Duration::from_micros(10),
        }
    }
}

impl Default for LoggingConfig {
    fn default() -> Self {
        Self {
            enabled: false,
            level: LogLevel::Info,
            metrics: false,
            tracing: false,
            log_file: None,
            json_format: false,
            debug_assertions: cfg!(debug_assertions),
        }
    }
}

impl Default for ErrorHandlingConfig {
    fn default() -> Self {
        Self {
            auto_retry: false,
            max_retries: 3,
            retry_delay: Duration::from_millis(10),
            graceful_degradation: true,
            sync_fallback: false,
            panic_on_fatal: true,
        }
    }
}

impl SaferRingConfig {
    /// Create a configuration optimized for low latency applications.
    ///
    /// This configuration prioritizes minimal latency over throughput,
    /// suitable for real-time applications and interactive workloads.
    pub fn low_latency() -> Self {
        Self {
            ring: RingConfig {
                sq_entries: 32,
                cq_entries: 0,
                sq_poll: true,
                sq_thread_cpu: Some(0),
                sq_thread_idle: Some(1),
                cq_overflow: true,
                kernel_sq_thread: true,
            },
            buffer: BufferConfig {
                default_size: 1024,
                alignment: 64, // Cache line aligned
                enable_pooling: true,
                pool_size: 32,
                max_pooled_size: 64 * 1024, // 64KB
                numa_aware: true,
                numa_node: -1,
                pre_register: true,
            },
            performance: PerformanceConfig {
                batch_submission: false, // Immediate submission
                max_batch_size: 1,
                batch_timeout: Duration::from_micros(1),
                zero_copy: true,
                vectored_io: false,
                operation_coalescing: false,
                coalescing_timeout: Duration::ZERO,
                adaptive_polling: true,
                poll_timeout: Duration::from_nanos(100),
            },
            logging: LoggingConfig {
                enabled: false, // Minimal overhead
                level: LogLevel::Error,
                metrics: false,
                tracing: false,
                log_file: None,
                json_format: false,
                debug_assertions: false,
            },
            advanced: AdvancedConfig {
                buffer_selection: true,
                multi_shot: false,
                provided_buffers: true,
                fast_poll: true,
                sq_poll: true,
                sq_thread_cpu: Some(0),
                coop_taskrun: true,
                defer_taskrun: true,
            },
            error_handling: ErrorHandlingConfig {
                auto_retry: false,
                max_retries: 0,
                retry_delay: Duration::ZERO,
                graceful_degradation: false,
                sync_fallback: false,
                panic_on_fatal: true,
            },
        }
    }

    /// Create a configuration optimized for high throughput applications.
    ///
    /// This configuration prioritizes maximum throughput over latency,
    /// suitable for batch processing and data-intensive workloads.
    pub fn high_throughput() -> Self {
        Self {
            ring: RingConfig {
                sq_entries: 1024,
                cq_entries: 2048,
                sq_poll: false,
                sq_thread_cpu: None,
                sq_thread_idle: None,
                cq_overflow: true,
                kernel_sq_thread: false,
            },
            buffer: BufferConfig {
                default_size: 64 * 1024, // 64KB
                alignment: 4096,         // Page aligned
                enable_pooling: true,
                pool_size: 256,
                max_pooled_size: 16 * 1024 * 1024, // 16MB
                numa_aware: true,
                numa_node: -1,
                pre_register: true,
            },
            performance: PerformanceConfig {
                batch_submission: true,
                max_batch_size: 256,
                batch_timeout: Duration::from_millis(10),
                zero_copy: true,
                vectored_io: true,
                operation_coalescing: true,
                coalescing_timeout: Duration::from_millis(1),
                adaptive_polling: false,
                poll_timeout: Duration::from_millis(1),
            },
            logging: LoggingConfig {
                enabled: true,
                level: LogLevel::Info,
                metrics: true,
                tracing: false,
                log_file: None,
                json_format: false,
                debug_assertions: false,
            },
            advanced: AdvancedConfig {
                buffer_selection: true,
                multi_shot: true,
                provided_buffers: true,
                fast_poll: false,
                sq_poll: false,
                sq_thread_cpu: None,
                coop_taskrun: true,
                defer_taskrun: true,
            },
            error_handling: ErrorHandlingConfig {
                auto_retry: true,
                max_retries: 3,
                retry_delay: Duration::from_millis(1),
                graceful_degradation: true,
                sync_fallback: true,
                panic_on_fatal: false,
            },
        }
    }

    /// Create a configuration optimized for development and debugging.
    ///
    /// This configuration enables comprehensive logging and debugging features
    /// at the cost of performance, suitable for development and testing.
    pub fn development() -> Self {
        Self {
            ring: RingConfig {
                sq_entries: 64,
                cq_entries: 0,
                sq_poll: false,
                sq_thread_cpu: None,
                sq_thread_idle: None,
                cq_overflow: true,
                kernel_sq_thread: false,
            },
            buffer: BufferConfig {
                default_size: 4096,
                alignment: 0,
                enable_pooling: true,
                pool_size: 32,
                max_pooled_size: 1024 * 1024,
                numa_aware: false,
                numa_node: -1,
                pre_register: false,
            },
            performance: PerformanceConfig {
                batch_submission: true,
                max_batch_size: 16,
                batch_timeout: Duration::from_millis(1),
                zero_copy: true,
                vectored_io: true,
                operation_coalescing: false,
                coalescing_timeout: Duration::from_millis(1),
                adaptive_polling: false,
                poll_timeout: Duration::from_millis(1),
            },
            logging: LoggingConfig {
                enabled: true,
                level: LogLevel::Debug,
                metrics: true,
                tracing: true,
                log_file: Some("safer-ring.log".into()),
                json_format: false,
                debug_assertions: true,
            },
            advanced: AdvancedConfig::default(),
            error_handling: ErrorHandlingConfig {
                auto_retry: true,
                max_retries: 1,
                retry_delay: Duration::from_millis(10),
                graceful_degradation: true,
                sync_fallback: true,
                panic_on_fatal: false,
            },
        }
    }

    /// Create a configuration optimized for production environments.
    ///
    /// This configuration balances performance and reliability for production
    /// deployments with appropriate logging and error handling.
    pub fn production() -> Self {
        Self {
            ring: RingConfig {
                sq_entries: 256,
                cq_entries: 0,
                sq_poll: false,
                sq_thread_cpu: None,
                sq_thread_idle: None,
                cq_overflow: true,
                kernel_sq_thread: false,
            },
            buffer: BufferConfig {
                default_size: 8192,
                alignment: 0,
                enable_pooling: true,
                pool_size: 128,
                max_pooled_size: 4 * 1024 * 1024, // 4MB
                numa_aware: true,
                numa_node: -1,
                pre_register: false,
            },
            performance: PerformanceConfig {
                batch_submission: true,
                max_batch_size: 64,
                batch_timeout: Duration::from_millis(5),
                zero_copy: true,
                vectored_io: true,
                operation_coalescing: false,
                coalescing_timeout: Duration::from_millis(1),
                adaptive_polling: false,
                poll_timeout: Duration::from_millis(1),
            },
            logging: LoggingConfig {
                enabled: true,
                level: LogLevel::Warn,
                metrics: true,
                tracing: false,
                log_file: Some("/var/log/safer-ring.log".into()),
                json_format: true,
                debug_assertions: false,
            },
            advanced: AdvancedConfig::default(),
            error_handling: ErrorHandlingConfig {
                auto_retry: true,
                max_retries: 3,
                retry_delay: Duration::from_millis(100),
                graceful_degradation: true,
                sync_fallback: true,
                panic_on_fatal: false,
            },
        }
    }

    /// Create an optimal configuration based on the current system.
    ///
    /// This method detects system capabilities and creates a configuration
    /// that takes advantage of available features while maintaining compatibility.
    pub fn auto_detect() -> Result<Self> {
        let detector = FeatureDetector::new()?;
        let cpu_count = num_cpus::get();

        // Adjust buffer pool size based on available memory
        let (pool_size, max_pooled_size) = if let Ok(memory_info) = Self::get_memory_info() {
            let available_mb = memory_info.available / (1024 * 1024);
            if available_mb > 1024 {
                (256, 16 * 1024 * 1024)
            } else if available_mb > 512 {
                (128, 8 * 1024 * 1024)
            } else {
                (64, 1024 * 1024) // Default values
            }
        } else {
            (64, 1024 * 1024) // Default values
        };

        Ok(Self {
            advanced: detector.create_optimal_config(),
            ring: RingConfig {
                sq_entries: (cpu_count * 32).min(1024) as u32,
                ..Default::default()
            },
            buffer: BufferConfig {
                numa_aware: cpu_count > 16,
                pool_size,
                max_pooled_size,
                ..Default::default()
            },
            ..Default::default()
        })
    }

    /// Validate the configuration for consistency and compatibility.
    pub fn validate(&self) -> Result<()> {
        // Validate ring configuration
        if self.ring.sq_entries == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "SQ entries must be greater than 0",
            )));
        }

        if self.ring.sq_entries > 4096 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "SQ entries should not exceed 4096",
            )));
        }

        // Validate buffer configuration
        if self.buffer.default_size == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Default buffer size must be greater than 0",
            )));
        }

        if self.buffer.pool_size == 0 && self.buffer.enable_pooling {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Pool size must be greater than 0 when pooling is enabled",
            )));
        }

        // Validate performance configuration
        if self.performance.max_batch_size == 0 && self.performance.batch_submission {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Max batch size must be greater than 0 when batch submission is enabled",
            )));
        }

        // Validate error handling configuration
        if self.error_handling.auto_retry && self.error_handling.max_retries == 0 {
            return Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Max retries must be greater than 0 when auto retry is enabled",
            )));
        }

        Ok(())
    }

    /// Get system memory information.
    fn get_memory_info() -> Result<MemoryInfo> {
        #[cfg(target_os = "linux")]
        {
            let meminfo = std::fs::read_to_string("/proc/meminfo").map_err(SaferRingError::Io)?;

            let mut total = 0;
            let mut available = 0;

            for line in meminfo.lines() {
                if line.starts_with("MemTotal:") {
                    if let Some(value) = line.split_whitespace().nth(1) {
                        total = value.parse::<u64>().unwrap_or(0) * 1024; // Convert KB to bytes
                    }
                } else if line.starts_with("MemAvailable:") {
                    if let Some(value) = line.split_whitespace().nth(1) {
                        available = value.parse::<u64>().unwrap_or(0) * 1024; // Convert KB to bytes
                    }
                }
            }

            Ok(MemoryInfo { total, available })
        }

        #[cfg(not(target_os = "linux"))]
        {
            // Fallback for non-Linux systems
            Ok(MemoryInfo {
                total: 8 * 1024 * 1024 * 1024,     // 8GB default
                available: 4 * 1024 * 1024 * 1024, // 4GB default
            })
        }
    }
}

/// System memory information.
#[derive(Debug, Clone)]
struct MemoryInfo {
    /// Total system memory in bytes
    #[allow(dead_code)]
    total: u64,
    /// Available system memory in bytes
    available: u64,
}

/// Configuration builder for fluent configuration creation.
#[derive(Debug)]
pub struct ConfigBuilder {
    config: SaferRingConfig,
}

impl ConfigBuilder {
    /// Create a new configuration builder.
    pub fn new() -> Self {
        Self {
            config: SaferRingConfig::default(),
        }
    }

    /// Set ring configuration.
    pub fn ring(mut self, ring: RingConfig) -> Self {
        self.config.ring = ring;
        self
    }

    /// Set buffer configuration.
    pub fn buffer(mut self, buffer: BufferConfig) -> Self {
        self.config.buffer = buffer;
        self
    }

    /// Set performance configuration.
    pub fn performance(mut self, performance: PerformanceConfig) -> Self {
        self.config.performance = performance;
        self
    }

    /// Set logging configuration.
    pub fn logging(mut self, logging: LoggingConfig) -> Self {
        self.config.logging = logging;
        self
    }

    /// Set advanced configuration.
    pub fn advanced(mut self, advanced: AdvancedConfig) -> Self {
        self.config.advanced = advanced;
        self
    }

    /// Set error handling configuration.
    pub fn error_handling(mut self, error_handling: ErrorHandlingConfig) -> Self {
        self.config.error_handling = error_handling;
        self
    }

    /// Build the final configuration.
    pub fn build(self) -> Result<SaferRingConfig> {
        self.config.validate()?;
        Ok(self.config)
    }
}

impl Default for ConfigBuilder {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = SaferRingConfig::default();
        assert!(config.validate().is_ok());
    }

    #[test]
    fn test_low_latency_config() {
        let config = SaferRingConfig::low_latency();
        assert!(config.validate().is_ok());
        assert_eq!(config.ring.sq_entries, 32);
        assert!(config.ring.sq_poll);
        assert!(!config.performance.batch_submission);
    }

    #[test]
    fn test_high_throughput_config() {
        let config = SaferRingConfig::high_throughput();
        assert!(config.validate().is_ok());
        assert_eq!(config.ring.sq_entries, 1024);
        assert!(config.performance.batch_submission);
        assert_eq!(config.performance.max_batch_size, 256);
    }

    #[test]
    fn test_development_config() {
        let config = SaferRingConfig::development();
        assert!(config.validate().is_ok());
        assert!(config.logging.enabled);
        assert_eq!(config.logging.level, LogLevel::Debug);
        assert!(config.logging.tracing);
    }

    #[test]
    fn test_production_config() {
        let config = SaferRingConfig::production();
        assert!(config.validate().is_ok());
        assert!(config.logging.enabled);
        assert_eq!(config.logging.level, LogLevel::Warn);
        assert!(config.logging.json_format);
    }

    #[test]
    fn test_config_validation() {
        let mut config = SaferRingConfig::default();

        // Valid config should pass
        assert!(config.validate().is_ok());

        // Invalid SQ entries should fail
        config.ring.sq_entries = 0;
        assert!(config.validate().is_err());

        config.ring.sq_entries = 128;
        config.buffer.default_size = 0;
        assert!(config.validate().is_err());
    }

    #[test]
    fn test_config_builder() {
        let config = ConfigBuilder::new()
            .ring(RingConfig {
                sq_entries: 64,
                ..Default::default()
            })
            .buffer(BufferConfig {
                default_size: 8192,
                ..Default::default()
            })
            .build()
            .unwrap();

        assert_eq!(config.ring.sq_entries, 64);
        assert_eq!(config.buffer.default_size, 8192);
    }

    #[test]
    fn test_auto_detect_config() {
        // This test may fail on systems without io_uring support
        if let Ok(config) = SaferRingConfig::auto_detect() {
            assert!(config.validate().is_ok());
            assert!(config.ring.sq_entries > 0);
        }
    }
}
</file>

<file path="error.rs">
//! Error types and handling for safer-ring operations.
//!
//! This module provides a comprehensive error type that covers all possible
//! failure modes in safer-ring operations, with proper error chaining and
//! platform-specific handling.

use static_assertions;
use thiserror::Error;

/// Result type alias for safer-ring operations.
///
/// This type alias simplifies function signatures throughout the crate by
/// providing a consistent error type while allowing different success types.
pub type Result<T> = std::result::Result<T, SaferRingError>;

/// Comprehensive error type for safer-ring operations.
///
/// This enum covers all possible error conditions that can occur during
/// safer-ring operations, from memory safety violations to underlying
/// system errors. Each variant provides specific context about the failure.
///
/// # Design Notes
///
/// - Uses `thiserror` for automatic `Error` trait implementation
/// - Provides automatic conversion from common error types via `#[from]`
/// - Platform-specific variants are conditionally compiled
/// - All variants are `Send + Sync` for use in async contexts
#[derive(Debug, Error)]
pub enum SaferRingError {
    /// Buffer is still in flight and cannot be accessed.
    ///
    /// This error occurs when attempting to access or drop a buffer
    /// that is currently being used by an in-flight io_uring operation.
    /// The buffer must remain pinned until the operation completes.
    #[error("Buffer still in flight")]
    BufferInFlight,

    /// Operation is not yet completed.
    ///
    /// This error occurs when attempting to extract results from an
    /// operation that hasn't finished yet. Use polling or await the
    /// operation's future to wait for completion.
    #[error("Operation not completed")]
    OperationPending,

    /// Ring has operations in flight and cannot be dropped.
    ///
    /// This error occurs when attempting to drop a Ring that still has
    /// pending operations. All operations must complete before the ring
    /// can be safely destroyed to prevent use-after-free bugs.
    #[error("Ring has {count} operations in flight")]
    OperationsInFlight {
        /// Number of operations still in flight
        count: usize,
    },

    /// Invalid operation state transition.
    ///
    /// This error occurs when attempting to transition an operation to
    /// an invalid state (e.g., submitting an already-submitted operation).
    /// The type system should prevent most of these at compile time.
    #[error("Invalid operation state transition")]
    InvalidStateTransition,

    /// Resource is not registered.
    ///
    /// This error occurs when attempting to use a file descriptor or
    /// buffer that hasn't been registered with the ring, when registration
    /// is required for the operation.
    #[error("Resource not registered")]
    NotRegistered,

    /// Buffer pool is empty.
    ///
    /// This error occurs when requesting a buffer from an empty pool.
    /// Consider increasing pool size or implementing fallback allocation.
    #[error("Buffer pool is empty")]
    PoolEmpty,

    /// Buffer pool mutex is poisoned.
    ///
    /// This error occurs when a thread panics while holding the pool's mutex,
    /// leaving it in a poisoned state. The pool cannot be safely used after this.
    #[error("Buffer pool mutex is poisoned")]
    PoolPoisoned,

    /// Standard I/O error.
    ///
    /// This wraps standard library I/O errors, which can occur during
    /// file operations or when io_uring falls back to synchronous I/O.
    #[error("I/O error: {0}")]
    Io(#[from] std::io::Error),
}

// Ensure our error type can be safely sent between threads
// This is important for async runtimes that may move futures between threads
static_assertions::assert_impl_all!(SaferRingError: Send, Sync);

#[cfg(test)]
mod tests {
    use super::*;
    use std::error::Error;
    use std::io::{Error as IoError, ErrorKind};

    /// Test error message formatting for all variants
    mod error_messages {
        use super::*;

        #[test]
        fn buffer_in_flight() {
            let error = SaferRingError::BufferInFlight;
            assert_eq!(error.to_string(), "Buffer still in flight");
        }

        #[test]
        fn operation_pending() {
            let error = SaferRingError::OperationPending;
            assert_eq!(error.to_string(), "Operation not completed");
        }

        #[test]
        fn operations_in_flight() {
            let error = SaferRingError::OperationsInFlight { count: 5 };
            assert_eq!(error.to_string(), "Ring has 5 operations in flight");
        }

        #[test]
        fn invalid_state_transition() {
            let error = SaferRingError::InvalidStateTransition;
            assert_eq!(error.to_string(), "Invalid operation state transition");
        }

        #[test]
        fn not_registered() {
            let error = SaferRingError::NotRegistered;
            assert_eq!(error.to_string(), "Resource not registered");
        }

        #[test]
        fn pool_empty() {
            let error = SaferRingError::PoolEmpty;
            assert_eq!(error.to_string(), "Buffer pool is empty");
        }
    }

    /// Test error conversion and chaining
    mod error_conversion {
        use super::*;

        #[test]
        fn io_error_conversion() {
            let io_error = IoError::new(ErrorKind::PermissionDenied, "Access denied");
            let safer_ring_error = SaferRingError::from(io_error);

            // Verify the conversion worked correctly
            let SaferRingError::Io(ref e) = safer_ring_error else {
                panic!("Expected Io error variant");
            };

            assert_eq!(e.kind(), ErrorKind::PermissionDenied);
            assert!(e.to_string().contains("Access denied"));
            assert!(safer_ring_error.to_string().contains("I/O error"));
        }

        #[cfg(target_os = "linux")]
        #[test]
        #[ignore] // Skip this test as SaferRingError::IoUring variant doesn't exist
        fn io_uring_error_conversion() {
            // TODO: Implement IoUring error variant if needed
            // This test is disabled until the error variant is added
        }
    }

    /// Test error trait implementations
    mod error_traits {
        use super::*;

        #[test]
        fn implements_error_trait() {
            let error = SaferRingError::BufferInFlight;

            // Verify it implements std::error::Error
            let _: &dyn std::error::Error = &error;

            // Simple errors should have no source
            assert!(error.source().is_none());
        }

        #[test]
        fn preserves_error_source() {
            let io_error = IoError::new(ErrorKind::NotFound, "File not found");
            let safer_ring_error = SaferRingError::from(io_error);

            // Verify the source is preserved
            assert!(safer_ring_error.source().is_some());

            let source = safer_ring_error.source().unwrap();
            let io_err = source.downcast_ref::<IoError>().unwrap();
            assert_eq!(io_err.kind(), ErrorKind::NotFound);
        }

        #[test]
        fn debug_formatting() {
            let error = SaferRingError::OperationsInFlight { count: 3 };
            let debug_str = format!("{:?}", error);

            assert!(debug_str.contains("OperationsInFlight"));
            assert!(debug_str.contains("count: 3"));
        }
    }

    /// Test the Result type alias
    mod result_alias {
        use super::*;

        #[test]
        fn success_case() {
            fn returns_success() -> Result<i32> {
                Ok(42)
            }

            assert_eq!(returns_success().unwrap(), 42);
        }

        #[test]
        fn error_case() {
            fn returns_error() -> Result<i32> {
                Err(SaferRingError::BufferInFlight)
            }

            assert!(returns_error().is_err());
            match returns_error() {
                Err(SaferRingError::BufferInFlight) => {}
                _ => panic!("Expected BufferInFlight error"),
            }
        }
    }
}
</file>

<file path="lib.rs">
//! # Safer-Ring: Safe io_uring for Rust
//!
//! A comprehensive, safe Rust wrapper around io_uring that provides zero-cost abstractions
//! while preventing common memory safety issues. The library uses Rust's type system,
//! lifetime management, and pinning to ensure that buffers remain valid during asynchronous
//! I/O operations, eliminating use-after-free bugs and data races.
//!
//! ## Key Features
//!
//! ### Safety Guarantees
//! - **Memory Safety**: Compile-time guarantees that buffers outlive their operations
//! - **Type Safety**: State machines prevent operations in invalid states
//! - **Lifetime Safety**: Automatic enforcement of buffer and operation lifetimes
//! - **Thread Safety**: Safe sharing of resources across async tasks
//!
//! ### Performance Optimizations
//! - **Zero-Cost Abstractions**: No runtime overhead compared to raw io_uring
//! - **Batch Operations**: Submit multiple operations efficiently with dependency support
//! - **Buffer Pooling**: Efficient buffer reuse to minimize allocations
//! - **Advanced Features**: Support for buffer selection, multi-shot operations, and more
//!
//! ### Developer Experience
//! - **Async/Await**: Seamless integration with Rust's async ecosystem
//! - **Comprehensive Logging**: Structured logging and performance metrics
//! - **Flexible Configuration**: Optimized presets for different use cases
//! - **Graceful Degradation**: Automatic fallback for older kernel versions
//!
//! ## Quick Start
//!
//! ### Recommended: Ownership Transfer API
//!
//! ```rust,no_run
//! use safer_ring::{Ring, OwnedBuffer};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Create a new ring with 32 entries
//! let mut ring = Ring::new(32)?;
//!
//! // Create a buffer - ownership will be transferred during I/O
//! let buffer = OwnedBuffer::new(1024);
//!
//! // Safe read with ownership transfer ("hot potato" pattern)
//! let (bytes_read, buffer) = ring.read_owned(0, buffer).await?;
//! println!("Read {} bytes", bytes_read);
//!
//! // Buffer is safely returned and can be reused  
//! let (bytes_written, _buffer) = ring.write_owned(1, buffer).await?;
//! println!("Wrote {} bytes", bytes_written);
//!
//! # Ok(())
//! # }
//! ```
//!
//! ### Alternative: Pin-based API (Advanced)
//!
//! ```rust,no_run
//! use safer_ring::{Ring, PinnedBuffer};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! let ring = Ring::new(32)?;
//! let mut buffer = PinnedBuffer::with_capacity(1024);
//!
//! // Lower-level pin-based API for advanced use cases
//! let (bytes_read, buffer) = ring.read(0, buffer.as_mut_slice()).await?;
//! println!("Read {} bytes", bytes_read);
//!
//! # Ok(())
//! # }
//! ```
//!
//! ### High-Performance Batch Operations
//!
//! For high-throughput applications, submit multiple operations in a single batch:
//!
//! ```rust,no_run
//! use safer_ring::{Ring, Batch, Operation, PinnedBuffer, BatchConfig};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Note: Batch operations currently require careful lifetime management
//! // See examples/async_demo.rs for working patterns
//! let ring = Ring::new(128)?;
//! let mut batch = Batch::new();
//!
//! // Prepare multiple buffers
//! let mut read_buffer = PinnedBuffer::with_capacity(4096);
//! let mut write_buffer = PinnedBuffer::from_slice(b"Hello, world!");
//!
//! // Add operations to the batch
//! batch.add_operation(Operation::read().fd(0).buffer(read_buffer.as_mut_slice()))?;
//! batch.add_operation(Operation::write().fd(1).buffer(write_buffer.as_mut_slice()))?;
//!
//! // Submit all operations at once  
//! let results = ring.submit_batch(batch).await?;
//! println!("Batch completed: {} operations", results.results.len());
//!
//! # Ok(())
//! # }
//! ```
//!
//! > **Note**: Batch operations are fully implemented but have some API ergonomics
//! > limitations. See `examples/async_demo.rs` for working usage patterns.
//!
//! ### Network Server Example
//!
//! ```rust,no_run
//! use safer_ring::{Ring, PinnedBuffer, BufferPool};
//! use std::os::unix::io::RawFd;
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! let ring = Ring::new(256)?;
//! let buffer_pool = BufferPool::new(100, 4096)?;
//! let listening_fd: RawFd = 3; // Assume we have a listening socket
//!
//! loop {
//!     // Accept a new connection
//!     let client_fd = ring.accept(listening_fd).await?;
//!     
//!     // Get a buffer from the pool
//!     let buffer = buffer_pool.get().await?;
//!     
//!     // Read data from the client
//!     let (bytes_read, buffer) = ring.recv(client_fd, buffer.as_mut_slice()).await?;
//!     
//!     // Echo the data back
//!     let (bytes_written, _buffer) = ring.send(client_fd, buffer.as_mut_slice()).await?;
//!     
//!     println!("Echoed {} bytes", bytes_written);
//!     // Buffer is automatically returned to pool when dropped
//! }
//! # }
//! ```
//!
//! ## Configuration and Optimization
//!
//! Safer-ring provides pre-configured setups for different use cases:
//!
//! ```rust,no_run
//! use safer_ring::{Ring, SaferRingConfig};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Low-latency configuration for real-time applications
//! let config = SaferRingConfig::low_latency();
//! let ring = Ring::with_config(config)?;
//!
//! // High-throughput configuration for batch processing
//! let config = SaferRingConfig::high_throughput();
//! let ring = Ring::with_config(config)?;
//!
//! // Auto-detect optimal configuration for current system
//! let config = SaferRingConfig::auto_detect()?;
//! let ring = Ring::with_config(config)?;
//!
//! # Ok(())
//! # }
//! ```
//!
//! ## Advanced Features
//!
//! ### Buffer Selection and Provided Buffers
//!
//! ```rust,no_run
//! use safer_ring::{Ring, BufferGroup, AdvancedConfig};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Create a buffer group for kernel buffer selection
//! let mut buffer_group = BufferGroup::new(1, 64, 4096)?;
//!
//! // Configure ring with advanced features
//! let mut config = AdvancedConfig::default();
//! config.buffer_selection = true;
//! config.provided_buffers = true;
//!
//! let ring = Ring::with_advanced_config(config)?;
//! // Use buffer selection for zero-copy reads
//! # Ok(())
//! # }
//! ```
//!
//! ### Comprehensive Logging and Metrics
//!
//! ```rust,no_run
//! use safer_ring::{Ring, SaferRingConfig, LogLevel};
//!
//! # #[tokio::main]
//! # async fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Enable detailed logging and metrics
//! let mut config = SaferRingConfig::development();
//! config.logging.enabled = true;
//! config.logging.level = LogLevel::Debug;
//! config.logging.metrics = true;
//!
//! let ring = Ring::with_config(config)?;
//!
//! // Operations are automatically logged with timing information
//! let mut buffer = safer_ring::PinnedBuffer::with_capacity(1024);
//! let (bytes_read, _) = ring.read(0, buffer.as_mut_slice()).await?;
//!
//! # Ok(())
//! # }
//! ```
//!
//! ## Platform Support
//!
//! - **Linux**: Full io_uring support with all advanced features
//! - **Other platforms**: Graceful degradation with stub implementations for testing
//!
//! ## Minimum Kernel Requirements
//!
//! - **Basic functionality**: Linux 5.1+
//! - **Advanced features**: Linux 5.19+ (buffer selection, multi-shot operations)
//! - **Optimal performance**: Linux 6.0+ (cooperative task running, defer taskrun)
//!
//! The library automatically detects available features and gracefully degrades
//! functionality on older kernels while maintaining API compatibility.
//!
//! ## Security Considerations
//!
//! ### File Descriptor Responsibility
//!
//! **⚠️ CRITICAL SECURITY NOTICE**: This library accepts raw file descriptors (`RawFd`)
//! from user code and does **NOT** perform any validation, permission checks, or access
//! control. The application is **entirely responsible** for ensuring file descriptor security.
//!
//! ### Security Responsibilities
//!
//! **The calling application must ensure that all file descriptors:**
//! - Are valid and owned by the current process
//! - Have appropriate permissions for the intended operation (read/write/accept)
//! - Are not subject to race conditions from concurrent access
//! - Point to intended resources (files, sockets, devices)
//! - Have been properly authenticated and authorized
//! - Are not being used maliciously by untrusted code
//!
//! ### Potential Security Risks
//!
//! **Using invalid, unauthorized, or malicious file descriptors can result in:**
//! - Reading from or writing to unintended files, sockets, or devices
//! - Information disclosure or data corruption
//! - Privilege escalation or unauthorized system access
//! - Buffer overflow attacks or memory corruption (from network data)
//! - Denial of service or system instability
//!
//! ### Security Best Practices
//!
//! **Always implement these security controls at the application level:**
//! - Validate file descriptors at security boundaries
//! - Use proper access control and permission checks
//! - Implement input validation for all received data
//! - Consider using sandboxing or privilege isolation
//! - Apply principle of least privilege for file access
//! - Use secure network protocols and authentication
//! - Monitor and log suspicious file descriptor usage
//!
//! ### Data Validation
//!
//! **For network operations, the application must:**
//! - Validate all received data before processing
//! - Implement proper input sanitization and bounds checking  
//! - Use secure parsing for untrusted input data
//! - Consider data confidentiality and integrity requirements
//! - Protect against injection attacks and protocol exploitation
//!
//! This library provides **memory safety** and **async safety** but does **NOT** provide
//! **security boundaries** or **access control**. Security must be implemented at the
//! application layer.

#![deny(unsafe_op_in_unsafe_fn)]
#![warn(missing_docs, rust_2018_idioms)]
#![cfg_attr(docsrs, feature(doc_cfg))]

// Core modules - fundamental building blocks for safe io_uring operations
pub mod backend; // Backend abstraction for io_uring and epoll
pub mod buffer;
pub mod error;
pub mod operation;
pub mod ownership; // Buffer ownership management for safety
pub mod ring;
pub mod runtime; // Runtime detection and fallback system
pub mod safety; // Cancellation safety and orphaned operation tracking

// Advanced features - performance optimizations and convenience APIs
pub mod advanced; // Advanced io_uring features (buffer selection, multi-shot, etc.)
pub mod compat; // AsyncRead/AsyncWrite compatibility adapters
pub mod config; // Configuration options for different use cases
pub mod future; // async/await integration
pub mod logging; // Comprehensive logging and debugging support
pub mod perf; // Performance profiling and optimization utilities
pub mod pool; // Buffer pooling for reduced allocations
pub mod registry; // FD/buffer registration for kernel optimization

// Re-exports for convenience - commonly used types at crate root
pub use advanced::{AdvancedConfig, BufferGroup, FeatureDetector, MultiShotConfig};
pub use buffer::PinnedBuffer;
pub use compat::{AsyncCompat, AsyncReadAdapter, AsyncWriteAdapter, File, Socket}; // Async compatibility
pub use config::{
    BufferConfig, ConfigBuilder, ErrorHandlingConfig, LoggingConfig, PerformanceConfig, RingConfig,
    SaferRingConfig,
};
pub use error::{Result, SaferRingError};
pub use logging::{LogLevel, Logger, PerformanceMetrics};
pub use operation::{Operation, OperationState};
pub use ownership::{BufferOwnership, OwnedBuffer, SafeBuffer}; // Core ownership types
pub use pool::{BufferPool, PooledBuffer};
pub use registry::{FixedFile, RegisteredBufferSlot, Registry};
pub use ring::{Batch, BatchConfig, BatchResult, CompletionResult, OperationResult, Ring};
pub use runtime::{get_environment_info, is_io_uring_available, Backend, EnvironmentInfo, Runtime}; // Runtime system
pub use safety::{OrphanTracker, SafeOperation, SafeOperationFuture, SubmissionId}; // Cancellation safety

// Type aliases for common patterns - reduces verbosity in user code
/// Future type for read operations that can be awaited.
pub type ReadFuture<'ring, 'buf> = future::ReadFuture<'ring, 'buf>;
/// Future type for write operations that can be awaited.
pub type WriteFuture<'ring, 'buf> = future::WriteFuture<'ring, 'buf>;
/// Future type for accept operations that can be awaited.
pub type AcceptFuture<'ring> = future::AcceptFuture<'ring>;
/// Future type for send operations that can be awaited.
pub type SendFuture<'ring, 'buf> = future::SendFuture<'ring, 'buf>;
/// Future type for receive operations that can be awaited.
pub type RecvFuture<'ring, 'buf> = future::RecvFuture<'ring, 'buf>;
/// Future type for batch operations that can be awaited.
pub type BatchFuture<'ring> = future::BatchFuture<'ring>;
/// Standalone future type for batch operations that doesn't hold Ring references.
pub type StandaloneBatchFuture = future::StandaloneBatchFuture;
</file>

<file path="logging.rs">
//! Comprehensive logging and debugging support for safer-ring.
//!
//! This module provides structured logging, performance metrics, and debugging
//! utilities to help diagnose issues and optimize performance in safer-ring applications.

use crate::error::{Result, SaferRingError};
use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};

/// Log level for safer-ring operations.
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum LogLevel {
    /// Trace-level logging (very verbose)
    Trace = 0,
    /// Debug-level logging
    Debug = 1,
    /// Info-level logging
    Info = 2,
    /// Warning-level logging
    Warn = 3,
    /// Error-level logging
    Error = 4,
}

impl std::fmt::Display for LogLevel {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            LogLevel::Trace => write!(f, "TRACE"),
            LogLevel::Debug => write!(f, "DEBUG"),
            LogLevel::Info => write!(f, "INFO"),
            LogLevel::Warn => write!(f, "WARN"),
            LogLevel::Error => write!(f, "ERROR"),
        }
    }
}

/// Log entry containing structured information about safer-ring operations.
#[derive(Debug, Clone)]
pub struct LogEntry {
    /// Timestamp when the log entry was created
    pub timestamp: SystemTime,
    /// Log level
    pub level: LogLevel,
    /// Component that generated the log
    pub component: String,
    /// Operation ID if applicable
    pub operation_id: Option<u64>,
    /// File descriptor if applicable
    pub fd: Option<i32>,
    /// Message content
    pub message: String,
    /// Additional structured data
    pub metadata: HashMap<String, String>,
    /// Duration if this is a timing log
    pub duration: Option<Duration>,
}

impl LogEntry {
    /// Create a new log entry.
    pub fn new(level: LogLevel, component: &str, message: &str) -> Self {
        Self {
            timestamp: SystemTime::now(),
            level,
            component: component.to_string(),
            operation_id: None,
            fd: None,
            message: message.to_string(),
            metadata: HashMap::new(),
            duration: None,
        }
    }

    /// Add operation ID to the log entry.
    pub fn with_operation_id(mut self, operation_id: u64) -> Self {
        self.operation_id = Some(operation_id);
        self
    }

    /// Add file descriptor to the log entry.
    pub fn with_fd(mut self, fd: i32) -> Self {
        self.fd = Some(fd);
        self
    }

    /// Add metadata to the log entry.
    pub fn with_metadata(mut self, key: &str, value: &str) -> Self {
        self.metadata.insert(key.to_string(), value.to_string());
        self
    }

    /// Add duration to the log entry.
    pub fn with_duration(mut self, duration: Duration) -> Self {
        self.duration = Some(duration);
        self
    }

    /// Format the log entry as a human-readable string.
    pub fn format(&self) -> String {
        let timestamp = self
            .timestamp
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis();

        let mut parts = vec![
            format!("[{}]", timestamp),
            format!("{}", self.level),
            format!("{}", self.component),
        ];

        if let Some(op_id) = self.operation_id {
            parts.push(format!("op:{}", op_id));
        }

        if let Some(fd) = self.fd {
            parts.push(format!("fd:{}", fd));
        }

        parts.push(self.message.clone());

        if let Some(duration) = self.duration {
            parts.push(format!("duration:{}μs", duration.as_micros()));
        }

        if !self.metadata.is_empty() {
            let metadata_str = self
                .metadata
                .iter()
                .map(|(k, v)| format!("{}:{}", k, v))
                .collect::<Vec<_>>()
                .join(",");
            parts.push(format!("metadata:{{{}}}", metadata_str));
        }

        parts.join(" ")
    }

    /// Format the log entry as JSON.
    pub fn format_json(&self) -> String {
        let timestamp = self
            .timestamp
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis();

        let mut json_parts = vec![
            format!("\"timestamp\":{}", timestamp),
            format!("\"level\":\"{}\"", self.level),
            format!("\"component\":\"{}\"", self.component),
            format!("\"message\":\"{}\"", self.message.replace('"', "\\\"")),
        ];

        if let Some(op_id) = self.operation_id {
            json_parts.push(format!("\"operation_id\":{}", op_id));
        }

        if let Some(fd) = self.fd {
            json_parts.push(format!("\"fd\":{}", fd));
        }

        if let Some(duration) = self.duration {
            json_parts.push(format!("\"duration_us\":{}", duration.as_micros()));
        }

        if !self.metadata.is_empty() {
            let metadata_json = self
                .metadata
                .iter()
                .map(|(k, v)| format!("\"{}\":\"{}\"", k, v.replace('"', "\\\"")))
                .collect::<Vec<_>>()
                .join(",");
            json_parts.push(format!("\"metadata\":{{{}}}", metadata_json));
        }

        format!("{{{}}}", json_parts.join(","))
    }
}

/// Trait for log output destinations.
pub trait LogOutput: Send + Sync {
    /// Write a log entry to the output.
    fn write(&self, entry: &LogEntry) -> Result<()>;

    /// Flush any buffered output.
    fn flush(&self) -> Result<()>;
}

/// Console log output that writes to stderr.
#[derive(Debug)]
pub struct ConsoleOutput {
    /// Whether to use JSON format
    json_format: bool,
}

impl ConsoleOutput {
    /// Create a new console output with text format.
    pub fn new() -> Self {
        Self { json_format: false }
    }

    /// Create a new console output with JSON format.
    pub fn new_json() -> Self {
        Self { json_format: true }
    }
}

impl Default for ConsoleOutput {
    fn default() -> Self {
        Self::new()
    }
}

impl LogOutput for ConsoleOutput {
    fn write(&self, entry: &LogEntry) -> Result<()> {
        let formatted = if self.json_format {
            entry.format_json()
        } else {
            entry.format()
        };

        eprintln!("{}", formatted);
        Ok(())
    }

    fn flush(&self) -> Result<()> {
        use std::io::Write;
        std::io::stderr().flush().map_err(SaferRingError::Io)?;
        Ok(())
    }
}

/// File log output that writes to a file.
#[derive(Debug)]
pub struct FileOutput {
    /// Path to the log file
    path: std::path::PathBuf,
    /// Whether to use JSON format
    json_format: bool,
}

impl FileOutput {
    /// Create a new file output.
    pub fn new<P: AsRef<std::path::Path>>(path: P) -> Self {
        Self {
            path: path.as_ref().to_path_buf(),
            json_format: false,
        }
    }

    /// Create a new file output with JSON format.
    pub fn new_json<P: AsRef<std::path::Path>>(path: P) -> Self {
        Self {
            path: path.as_ref().to_path_buf(),
            json_format: true,
        }
    }
}

impl LogOutput for FileOutput {
    fn write(&self, entry: &LogEntry) -> Result<()> {
        use std::io::Write;

        let formatted = if self.json_format {
            entry.format_json()
        } else {
            entry.format()
        };

        let mut file = std::fs::OpenOptions::new()
            .create(true)
            .append(true)
            .open(&self.path)
            .map_err(SaferRingError::Io)?;

        writeln!(file, "{}", formatted).map_err(SaferRingError::Io)?;
        Ok(())
    }

    fn flush(&self) -> Result<()> {
        // File is opened and closed for each write, so no explicit flush needed
        Ok(())
    }
}

/// Central logger for safer-ring operations.
pub struct Logger {
    /// Minimum log level to output
    min_level: LogLevel,
    /// Output destinations
    outputs: Vec<Box<dyn LogOutput>>,
    /// Performance metrics
    metrics: Arc<Mutex<PerformanceMetrics>>,
}

impl Logger {
    /// Create a new logger with console output.
    pub fn new() -> Self {
        Self {
            min_level: LogLevel::Info,
            outputs: vec![Box::new(ConsoleOutput::new())],
            metrics: Arc::new(Mutex::new(PerformanceMetrics::new())),
        }
    }

    /// Set the minimum log level.
    pub fn set_level(&mut self, level: LogLevel) {
        self.min_level = level;
    }

    /// Add an output destination.
    pub fn add_output(&mut self, output: Box<dyn LogOutput>) {
        self.outputs.push(output);
    }

    /// Log a message at the specified level.
    pub fn log(&self, level: LogLevel, component: &str, message: &str) {
        if level >= self.min_level {
            let entry = LogEntry::new(level, component, message);
            self.write_entry(&entry);
        }
    }

    /// Log a message with operation context.
    pub fn log_operation(
        &self,
        level: LogLevel,
        component: &str,
        operation_id: u64,
        fd: Option<i32>,
        message: &str,
    ) {
        if level >= self.min_level {
            let mut entry =
                LogEntry::new(level, component, message).with_operation_id(operation_id);

            if let Some(fd) = fd {
                entry = entry.with_fd(fd);
            }

            self.write_entry(&entry);
        }
    }

    /// Log a timing measurement.
    pub fn log_timing(&self, component: &str, operation: &str, duration: Duration) {
        if LogLevel::Debug >= self.min_level {
            let entry = LogEntry::new(
                LogLevel::Debug,
                component,
                &format!("{} completed", operation),
            )
            .with_duration(duration);
            self.write_entry(&entry);

            // Update performance metrics
            if let Ok(mut metrics) = self.metrics.lock() {
                metrics.record_operation(operation, duration);
            }
        }
    }

    /// Log an error with context.
    pub fn log_error(&self, component: &str, error: &SaferRingError, context: &str) {
        let message = format!("{}: {}", context, error);
        let entry = LogEntry::new(LogLevel::Error, component, &message);
        self.write_entry(&entry);
    }

    /// Write a log entry to all outputs.
    fn write_entry(&self, entry: &LogEntry) {
        for output in &self.outputs {
            if let Err(e) = output.write(entry) {
                eprintln!("Failed to write log entry: {}", e);
            }
        }
    }

    /// Flush all outputs.
    pub fn flush(&self) {
        for output in &self.outputs {
            if let Err(e) = output.flush() {
                eprintln!("Failed to flush log output: {}", e);
            }
        }
    }

    /// Get performance metrics.
    pub fn get_metrics(&self) -> Result<PerformanceMetrics> {
        self.metrics.lock().map(|m| m.clone()).map_err(|_| {
            SaferRingError::Io(std::io::Error::other("Failed to acquire metrics lock"))
        })
    }

    /// Reset performance metrics.
    pub fn reset_metrics(&self) -> Result<()> {
        self.metrics.lock().map(|mut m| m.reset()).map_err(|_| {
            SaferRingError::Io(std::io::Error::other("Failed to acquire metrics lock"))
        })
    }
}

impl Default for Logger {
    fn default() -> Self {
        Self::new()
    }
}

/// Performance metrics for safer-ring operations.
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    /// Operation counts by type
    operation_counts: HashMap<String, u64>,
    /// Total duration by operation type
    operation_durations: HashMap<String, Duration>,
    /// Minimum duration by operation type
    min_durations: HashMap<String, Duration>,
    /// Maximum duration by operation type
    max_durations: HashMap<String, Duration>,
    /// Start time for metrics collection
    start_time: Instant,
}

impl PerformanceMetrics {
    /// Create new performance metrics.
    pub fn new() -> Self {
        Self {
            operation_counts: HashMap::new(),
            operation_durations: HashMap::new(),
            min_durations: HashMap::new(),
            max_durations: HashMap::new(),
            start_time: Instant::now(),
        }
    }

    /// Record an operation timing.
    pub fn record_operation(&mut self, operation: &str, duration: Duration) {
        let count = self
            .operation_counts
            .entry(operation.to_string())
            .or_insert(0);
        *count += 1;

        let total_duration = self
            .operation_durations
            .entry(operation.to_string())
            .or_insert(Duration::ZERO);
        *total_duration += duration;

        let min_duration = self
            .min_durations
            .entry(operation.to_string())
            .or_insert(duration);
        if duration < *min_duration {
            *min_duration = duration;
        }

        let max_duration = self
            .max_durations
            .entry(operation.to_string())
            .or_insert(duration);
        if duration > *max_duration {
            *max_duration = duration;
        }
    }

    /// Get the count for a specific operation type.
    pub fn get_count(&self, operation: &str) -> u64 {
        self.operation_counts.get(operation).copied().unwrap_or(0)
    }

    /// Get the average duration for a specific operation type.
    pub fn get_average_duration(&self, operation: &str) -> Option<Duration> {
        let count = self.get_count(operation);
        if count == 0 {
            return None;
        }

        self.operation_durations
            .get(operation)
            .map(|total| *total / count as u32)
    }

    /// Get the minimum duration for a specific operation type.
    pub fn get_min_duration(&self, operation: &str) -> Option<Duration> {
        self.min_durations.get(operation).copied()
    }

    /// Get the maximum duration for a specific operation type.
    pub fn get_max_duration(&self, operation: &str) -> Option<Duration> {
        self.max_durations.get(operation).copied()
    }

    /// Get all operation types.
    pub fn get_operation_types(&self) -> Vec<String> {
        self.operation_counts.keys().cloned().collect()
    }

    /// Get total operations across all types.
    pub fn get_total_operations(&self) -> u64 {
        self.operation_counts.values().sum()
    }

    /// Get the duration since metrics collection started.
    pub fn get_collection_duration(&self) -> Duration {
        self.start_time.elapsed()
    }

    /// Reset all metrics.
    pub fn reset(&mut self) {
        self.operation_counts.clear();
        self.operation_durations.clear();
        self.min_durations.clear();
        self.max_durations.clear();
        self.start_time = Instant::now();
    }

    /// Generate a summary report.
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        report.push_str("=== Safer-Ring Performance Metrics ===\n");
        report.push_str(&format!(
            "Collection Duration: {:?}\n",
            self.get_collection_duration()
        ));
        report.push_str(&format!(
            "Total Operations: {}\n\n",
            self.get_total_operations()
        ));

        for operation in self.get_operation_types() {
            report.push_str(&format!("Operation: {}\n", operation));
            report.push_str(&format!("  Count: {}\n", self.get_count(&operation)));

            if let Some(avg) = self.get_average_duration(&operation) {
                report.push_str(&format!("  Average Duration: {:?}\n", avg));
            }

            if let Some(min) = self.get_min_duration(&operation) {
                report.push_str(&format!("  Min Duration: {:?}\n", min));
            }

            if let Some(max) = self.get_max_duration(&operation) {
                report.push_str(&format!("  Max Duration: {:?}\n", max));
            }

            report.push('\n');
        }

        report
    }
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self::new()
    }
}

/// Global logger instance.
static GLOBAL_LOGGER: std::sync::OnceLock<Arc<Mutex<Logger>>> = std::sync::OnceLock::new();

/// Initialize the global logger.
pub fn init_logger() -> Arc<Mutex<Logger>> {
    GLOBAL_LOGGER
        .get_or_init(|| Arc::new(Mutex::new(Logger::new())))
        .clone()
}

/// Log a message using the global logger.
pub fn log(level: LogLevel, component: &str, message: &str) {
    if let Some(logger) = GLOBAL_LOGGER.get() {
        if let Ok(logger) = logger.lock() {
            logger.log(level, component, message);
        }
    }
}

/// Log an operation using the global logger.
pub fn log_operation(
    level: LogLevel,
    component: &str,
    operation_id: u64,
    fd: Option<i32>,
    message: &str,
) {
    if let Some(logger) = GLOBAL_LOGGER.get() {
        if let Ok(logger) = logger.lock() {
            logger.log_operation(level, component, operation_id, fd, message);
        }
    }
}

/// Log timing using the global logger.
pub fn log_timing(component: &str, operation: &str, duration: Duration) {
    if let Some(logger) = GLOBAL_LOGGER.get() {
        if let Ok(logger) = logger.lock() {
            logger.log_timing(component, operation, duration);
        }
    }
}

/// Convenience macros for logging.
///
/// Log a trace-level message using the global logger.
#[macro_export]
macro_rules! log_trace {
    ($component:expr, $($arg:tt)*) => {
        $crate::logging::log($crate::logging::LogLevel::Trace, $component, &format!($($arg)*))
    };
}

/// Log a debug-level message using the global logger.
#[macro_export]
macro_rules! log_debug {
    ($component:expr, $($arg:tt)*) => {
        $crate::logging::log($crate::logging::LogLevel::Debug, $component, &format!($($arg)*))
    };
}

/// Log an info-level message using the global logger.
#[macro_export]
macro_rules! log_info {
    ($component:expr, $($arg:tt)*) => {
        $crate::logging::log($crate::logging::LogLevel::Info, $component, &format!($($arg)*))
    };
}

/// Log a warning-level message using the global logger.
#[macro_export]
macro_rules! log_warn {
    ($component:expr, $($arg:tt)*) => {
        $crate::logging::log($crate::logging::LogLevel::Warn, $component, &format!($($arg)*))
    };
}

/// Log an error-level message using the global logger.
#[macro_export]
macro_rules! log_error {
    ($component:expr, $($arg:tt)*) => {
        $crate::logging::log($crate::logging::LogLevel::Error, $component, &format!($($arg)*))
    };
}

#[cfg(test)]
mod tests {
    use super::*;
    // Arc import removed as unused

    #[test]
    fn test_log_entry_creation() {
        let entry = LogEntry::new(LogLevel::Info, "test", "test message")
            .with_operation_id(123)
            .with_fd(4)
            .with_metadata("key", "value")
            .with_duration(Duration::from_millis(10));

        assert_eq!(entry.level, LogLevel::Info);
        assert_eq!(entry.component, "test");
        assert_eq!(entry.message, "test message");
        assert_eq!(entry.operation_id, Some(123));
        assert_eq!(entry.fd, Some(4));
        assert_eq!(entry.metadata.get("key"), Some(&"value".to_string()));
        assert_eq!(entry.duration, Some(Duration::from_millis(10)));
    }

    #[test]
    fn test_log_entry_formatting() {
        let entry = LogEntry::new(LogLevel::Info, "test", "test message");
        let formatted = entry.format();

        assert!(formatted.contains("INFO"));
        assert!(formatted.contains("test"));
        assert!(formatted.contains("test message"));
    }

    #[test]
    fn test_log_entry_json_formatting() {
        let entry = LogEntry::new(LogLevel::Info, "test", "test message");
        let json = entry.format_json();

        assert!(json.contains("\"level\":\"INFO\""));
        assert!(json.contains("\"component\":\"test\""));
        assert!(json.contains("\"message\":\"test message\""));
    }

    #[test]
    fn test_logger_creation() {
        let logger = Logger::new();
        assert_eq!(logger.min_level, LogLevel::Info);
        assert_eq!(logger.outputs.len(), 1);
    }

    #[test]
    fn test_performance_metrics() {
        let mut metrics = PerformanceMetrics::new();

        metrics.record_operation("read", Duration::from_millis(10));
        metrics.record_operation("read", Duration::from_millis(20));
        metrics.record_operation("write", Duration::from_millis(15));

        assert_eq!(metrics.get_count("read"), 2);
        assert_eq!(metrics.get_count("write"), 1);
        assert_eq!(metrics.get_total_operations(), 3);

        assert_eq!(
            metrics.get_average_duration("read"),
            Some(Duration::from_millis(15))
        );
        assert_eq!(
            metrics.get_min_duration("read"),
            Some(Duration::from_millis(10))
        );
        assert_eq!(
            metrics.get_max_duration("read"),
            Some(Duration::from_millis(20))
        );
    }

    #[test]
    fn test_global_logger() {
        let _logger = init_logger();

        log(LogLevel::Info, "test", "test message");
        log_operation(LogLevel::Debug, "test", 123, Some(4), "operation message");
        log_timing("test", "read", Duration::from_millis(10));
    }
}
</file>

<file path="ownership.rs">
//! Buffer ownership management for safe io_uring operations.
//!
//! This module implements the core safety mechanism of safer-ring: explicit buffer ownership
//! tracking. When a buffer is used in an io_uring operation, ownership is transferred to the
//! kernel for the duration of the operation, preventing use-after-free bugs and data races.
//!
//! # Core Principles
//!
//! 1. **Ownership Transfer**: Buffers are explicitly owned by either userspace or kernel
//! 2. **Cancellation Safety**: Dropped futures leave buffers with kernel until completion
//! 3. **Memory Safety**: No access to buffers while kernel owns them
//! 4. **Hot Potato Pattern**: Buffers are given and returned explicitly
//!
//! # Example
//!
//! ```rust,no_run
//! use safer_ring::ownership::OwnedBuffer;
//!
//! # fn example() -> Result<(), Box<dyn std::error::Error>> {
//! // Create a buffer that can be safely transferred to kernel
//! let buffer = OwnedBuffer::new(1024);
//!
//! // Buffer can be accessed when owned by userspace
//! if let Some(mut guard) = buffer.try_access() {
//!     guard[0] = 42; // Safe to access
//! }
//!
//! // When used in io_uring operations, kernel takes ownership
//! // buffer.give_to_kernel(operation_id)?;
//! // No access possible until kernel returns ownership
//! # Ok(())
//! # }
//! ```

use std::ops::{Deref, DerefMut};
use std::sync::{Arc, Mutex};

use crate::error::{Result, SaferRingError};

/// Buffer ownership states during io_uring operations.
///
/// This enum tracks the explicit ownership of buffers between userspace and kernel,
/// ensuring memory safety during asynchronous operations.
#[derive(Debug)]
pub enum BufferOwnership {
    /// Buffer is owned by userspace and can be safely accessed.
    User(Box<[u8]>),
    /// Buffer is owned by kernel for an ongoing operation.
    /// The buffer is preserved along with the submission ID for tracking.
    Kernel(Box<[u8]>, u64),
    /// Buffer ownership is being transferred back from kernel.
    /// Temporary state during completion processing.
    Returning,
}

/// A handle to a buffer that can be safely transferred between userspace and kernel.
///
/// This is the fundamental abstraction that makes io_uring safe. It ensures that:
/// - Buffers cannot be accessed while owned by the kernel
/// - Kernel operations cannot use freed buffers
/// - Cancellation cannot cause use-after-free bugs
///
/// # Lifetime Safety
///
/// The buffer handle maintains memory safety through explicit ownership tracking.
/// When an operation is cancelled (future dropped), the buffer remains with the
/// kernel until the operation completes, at which point ownership is returned.
#[derive(Debug)]
pub struct OwnedBuffer {
    inner: Arc<Mutex<BufferOwnership>>,
    size: usize,
    generation: u64, // For debugging and lifecycle tracking
}

impl OwnedBuffer {
    /// Create a new owned buffer with the specified size.
    ///
    /// The buffer is initially owned by userspace and can be accessed immediately.
    ///
    /// # Arguments
    ///
    /// * `size` - Size of the buffer in bytes
    ///
    /// # Example
    ///
    /// ```rust
    /// use safer_ring::ownership::OwnedBuffer;
    ///
    /// let buffer = OwnedBuffer::new(4096);
    /// println!("Created buffer of {} bytes", buffer.size());
    /// ```
    pub fn new(size: usize) -> Self {
        let buffer = vec![0u8; size].into_boxed_slice();
        Self {
            inner: Arc::new(Mutex::new(BufferOwnership::User(buffer))),
            size,
            generation: 0, // TODO: Use atomic counter for unique generations
        }
    }

    /// Create a new owned buffer from existing data.
    ///
    /// Takes ownership of the provided data and makes it available for io_uring operations.
    ///
    /// # Arguments
    ///
    /// * `data` - Data to take ownership of
    ///
    /// # Example
    ///
    /// ```rust
    /// use safer_ring::ownership::OwnedBuffer;
    ///
    /// let data = b"Hello, world!";
    /// let buffer = OwnedBuffer::from_slice(data);
    /// ```
    pub fn from_slice(data: &[u8]) -> Self {
        let buffer = data.to_vec().into_boxed_slice();
        let size = buffer.len();
        Self {
            inner: Arc::new(Mutex::new(BufferOwnership::User(buffer))),
            size,
            generation: 0,
        }
    }

    /// Get the size of the buffer in bytes.
    ///
    /// This returns the allocated size regardless of current ownership state.
    pub fn size(&self) -> usize {
        self.size
    }

    /// Get the generation counter for debugging.
    ///
    /// Each buffer has a unique generation ID for lifecycle tracking.
    pub fn generation(&self) -> u64 {
        self.generation
    }

    /// Try to get exclusive access to the buffer.
    ///
    /// Returns `Some(BufferAccessGuard)` if the buffer is currently owned by userspace,
    /// or `None` if the kernel currently owns it.
    ///
    /// The guard provides RAII access to the buffer data and automatically returns
    /// ownership to the buffer when dropped.
    ///
    /// # Example
    ///
    /// ```rust
    /// use safer_ring::ownership::OwnedBuffer;
    ///
    /// let mut buffer = OwnedBuffer::new(1024);
    ///
    /// if let Some(mut guard) = buffer.try_access() {
    ///     guard[0] = 42;
    ///     guard[1] = 24;
    /// } else {
    ///     println!("Buffer is currently owned by kernel");
    /// }
    /// ```
    pub fn try_access(&self) -> Option<BufferAccessGuard> {
        let mut ownership = self.inner.lock().unwrap();
        match &mut *ownership {
            BufferOwnership::User(ref mut buf) => {
                // Temporarily take ownership for the guard
                let buffer = std::mem::replace(buf, Box::new([]));
                *ownership = BufferOwnership::Returning; // Mark as transitioning
                Some(BufferAccessGuard {
                    buffer,
                    ownership: self.inner.clone(),
                })
            }
            BufferOwnership::Kernel(_, _) => None, // Kernel owns it
            BufferOwnership::Returning => None,    // In transition
        }
    }

    /// Transfer ownership to the kernel for an io_uring operation.
    ///
    /// This method is called internally when submitting operations. It marks the buffer
    /// as owned by the kernel and returns the raw buffer pointer for the operation.
    ///
    /// # Arguments
    ///
    /// * `submission_id` - Unique ID for the operation taking ownership
    ///
    /// # Returns
    ///
    /// Returns the raw buffer pointer and size for the io_uring operation.
    ///
    /// # Errors
    ///
    /// Returns an error if the buffer is not currently owned by userspace.
    pub fn give_to_kernel(&self, submission_id: u64) -> Result<(*mut u8, usize)> {
        let mut ownership = self.inner.lock().unwrap();
        match &mut *ownership {
            BufferOwnership::User(buf) => {
                let ptr = buf.as_mut_ptr();
                let len = buf.len();
                // Move buffer to kernel ownership while preserving the actual buffer
                let buffer = std::mem::replace(buf, Box::new([]));
                *ownership = BufferOwnership::Kernel(buffer, submission_id);
                Ok((ptr, len))
            }
            BufferOwnership::Kernel(_, existing_id) => {
                Err(SaferRingError::Io(std::io::Error::new(
                    std::io::ErrorKind::WouldBlock,
                    format!("Buffer already owned by kernel (operation {})", existing_id),
                )))
            }
            BufferOwnership::Returning => Err(SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::WouldBlock,
                "Buffer ownership is currently transitioning",
            ))),
        }
    }

    /// Return ownership from kernel after operation completion.
    ///
    /// This method is called internally when an io_uring operation completes.
    /// It transfers ownership back to userspace and makes the buffer accessible again.
    ///
    /// # Arguments
    ///
    /// * `submission_id` - ID of the completed operation
    ///
    /// # Panics
    ///
    /// Panics if the buffer is not currently owned by the kernel or if the
    /// submission ID doesn't match.
    pub fn return_from_kernel(&self, submission_id: u64) {
        let mut ownership = self.inner.lock().unwrap();
        match &mut *ownership {
            BufferOwnership::Kernel(buffer, id) if *id == submission_id => {
                // Move buffer back to user ownership
                let buffer = std::mem::replace(buffer, Box::new([]));
                *ownership = BufferOwnership::User(buffer);
            }
            BufferOwnership::Kernel(_, id) => {
                panic!(
                    "Buffer owned by operation {} but tried to return from operation {}",
                    id, submission_id
                );
            }
            _ => {
                panic!("Tried to return buffer that isn't owned by kernel");
            }
        }
    }

    /// Check if the buffer is currently owned by userspace.
    ///
    /// This is useful for debugging and assertions.
    pub fn is_user_owned(&self) -> bool {
        let ownership = self.inner.lock().unwrap();
        matches!(*ownership, BufferOwnership::User(_))
    }

    /// Check if the buffer is currently owned by the kernel.
    ///
    /// Returns the submission ID if owned by kernel, None otherwise.
    pub fn kernel_owner(&self) -> Option<u64> {
        let ownership = self.inner.lock().unwrap();
        match *ownership {
            BufferOwnership::Kernel(_, id) => Some(id),
            _ => None,
        }
    }

    /// Clone the buffer handle.
    ///
    /// Both handles refer to the same underlying buffer with shared ownership tracking.
    /// This is useful for tracking buffers across multiple contexts.
    pub fn clone_handle(&self) -> Self {
        Self {
            inner: self.inner.clone(),
            size: self.size,
            generation: self.generation,
        }
    }

    /// Get raw pointer and length for safe operations.
    ///
    /// This method provides access to the buffer's raw pointer and length
    /// for use in safe operations where ownership is explicitly managed
    /// through the SafeOperation tracking system.
    ///
    /// # Safety
    ///
    /// The returned pointer is only valid while the buffer exists and
    /// should only be used with proper ownership tracking.
    pub fn as_ptr_and_len(&self) -> (*mut u8, usize) {
        let ownership = self.inner.lock().unwrap();
        match &*ownership {
            BufferOwnership::User(buf) => (buf.as_ptr() as *mut u8, buf.len()),
            BufferOwnership::Kernel(_, _) => (std::ptr::null_mut(), 0),
            BufferOwnership::Returning => (std::ptr::null_mut(), 0),
        }
    }
}

/// RAII guard for safe buffer access.
///
/// This guard provides temporary exclusive access to buffer data while ensuring
/// that ownership is properly returned when the guard is dropped.
///
/// The guard implements `Deref` and `DerefMut` for convenient access to the
/// underlying buffer data.
pub struct BufferAccessGuard {
    buffer: Box<[u8]>,
    ownership: Arc<Mutex<BufferOwnership>>,
}

impl BufferAccessGuard {
    /// Get the size of the buffer.
    pub fn len(&self) -> usize {
        self.buffer.len()
    }

    /// Check if the buffer is empty.
    pub fn is_empty(&self) -> bool {
        self.buffer.is_empty()
    }

    /// Get a raw pointer to the buffer data.
    ///
    /// # Safety
    ///
    /// The pointer is valid only while the guard exists and should not be
    /// stored beyond the guard's lifetime.
    pub fn as_ptr(&self) -> *const u8 {
        self.buffer.as_ptr()
    }

    /// Get a mutable raw pointer to the buffer data.
    ///
    /// # Safety
    ///
    /// The pointer is valid only while the guard exists and should not be
    /// stored beyond the guard's lifetime.
    pub fn as_mut_ptr(&mut self) -> *mut u8 {
        self.buffer.as_mut_ptr()
    }
}

impl Drop for BufferAccessGuard {
    fn drop(&mut self) {
        // Return the buffer to user ownership
        let buffer = std::mem::replace(&mut self.buffer, Box::new([]));
        let mut ownership = self.ownership.lock().unwrap();
        *ownership = BufferOwnership::User(buffer);
    }
}

impl Deref for BufferAccessGuard {
    type Target = [u8];

    fn deref(&self) -> &[u8] {
        &self.buffer
    }
}

impl DerefMut for BufferAccessGuard {
    fn deref_mut(&mut self) -> &mut [u8] {
        &mut self.buffer
    }
}

/// Marker trait for types that can be safely used as io_uring buffers.
///
/// This trait is automatically implemented for `OwnedBuffer` and ensures that
/// only safe buffer types can be used with io_uring operations.
pub trait SafeBuffer {
    /// Get the size of the buffer in bytes.
    fn size(&self) -> usize;

    /// Transfer ownership to the kernel and get raw buffer info.
    fn give_to_kernel(&self, submission_id: u64) -> Result<(*mut u8, usize)>;

    /// Return ownership from the kernel after operation completion.
    fn return_from_kernel(&self, submission_id: u64);
}

impl SafeBuffer for OwnedBuffer {
    fn size(&self) -> usize {
        self.size()
    }

    fn give_to_kernel(&self, submission_id: u64) -> Result<(*mut u8, usize)> {
        self.give_to_kernel(submission_id)
    }

    fn return_from_kernel(&self, submission_id: u64) {
        self.return_from_kernel(submission_id)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_owned_buffer_creation() {
        let buffer = OwnedBuffer::new(1024);
        assert_eq!(buffer.size(), 1024);
        assert!(buffer.is_user_owned());
        assert_eq!(buffer.kernel_owner(), None);
    }

    #[test]
    fn test_buffer_access_guard() {
        let buffer = OwnedBuffer::new(1024);

        {
            let mut guard = buffer.try_access().unwrap();
            assert_eq!(guard.len(), 1024);
            guard[0] = 42;
            guard[1] = 24;
        } // Guard dropped here

        // Buffer should be accessible again
        let guard = buffer.try_access().unwrap();
        assert_eq!(guard[0], 42);
        assert_eq!(guard[1], 24);
    }

    #[test]
    fn test_kernel_ownership_transfer() {
        let buffer = OwnedBuffer::new(1024);

        // Give to kernel
        let (ptr, size) = buffer.give_to_kernel(123).unwrap();
        assert!(!ptr.is_null());
        assert_eq!(size, 1024);
        assert!(!buffer.is_user_owned());
        assert_eq!(buffer.kernel_owner(), Some(123));

        // Should not be accessible while kernel owns it
        assert!(buffer.try_access().is_none());

        // Should fail to give to kernel again
        assert!(buffer.give_to_kernel(456).is_err());
    }

    #[test]
    fn test_return_from_kernel() {
        let buffer = OwnedBuffer::new(1024);

        // Give to kernel and then return
        let (_ptr, _size) = buffer.give_to_kernel(123).unwrap();

        // Return from kernel - buffer is preserved internally
        buffer.return_from_kernel(123);

        // Should be accessible again
        assert!(buffer.is_user_owned());
        assert!(buffer.try_access().is_some());
    }

    #[test]
    #[should_panic(
        expected = "Buffer owned by operation 123 but tried to return from operation 456"
    )]
    fn test_mismatched_submission_id_panic() {
        let buffer = OwnedBuffer::new(1024);
        let (_ptr, _size) = buffer.give_to_kernel(123).unwrap();

        // Return from kernel with wrong ID - should panic
        buffer.return_from_kernel(456); // Wrong ID - should panic
    }

    #[test]
    fn test_buffer_from_slice() {
        let data = b"Hello, world!";
        let buffer = OwnedBuffer::from_slice(data);

        assert_eq!(buffer.size(), data.len());
        let guard = buffer.try_access().unwrap();
        assert_eq!(&*guard, data);
    }

    #[test]
    fn test_clone_handle() {
        let buffer = OwnedBuffer::new(1024);
        let cloned = buffer.clone_handle();

        // Both handles should refer to the same buffer
        assert_eq!(buffer.size(), cloned.size());
        assert_eq!(buffer.generation(), cloned.generation());

        // Accessing through one handle should affect the other
        buffer.give_to_kernel(123).unwrap();
        assert!(!cloned.is_user_owned());
        assert_eq!(cloned.kernel_owner(), Some(123));
    }
}
</file>

<file path="perf.rs">
//! Performance profiling and optimization utilities.

use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

/// Performance counter for tracking operation metrics.
#[derive(Debug)]
pub struct PerfCounter {
    /// Total number of operations
    count: AtomicU64,
    /// Total time spent in operations (nanoseconds)
    total_time_ns: AtomicU64,
    /// Minimum operation time (nanoseconds)
    min_time_ns: AtomicU64,
    /// Maximum operation time (nanoseconds)
    max_time_ns: AtomicU64,
}

impl PerfCounter {
    /// Create a new performance counter.
    pub fn new() -> Self {
        Self {
            count: AtomicU64::new(0),
            total_time_ns: AtomicU64::new(0),
            min_time_ns: AtomicU64::new(u64::MAX),
            max_time_ns: AtomicU64::new(0),
        }
    }

    /// Record an operation duration.
    pub fn record(&self, duration: Duration) {
        let nanos = duration.as_nanos() as u64;

        self.count.fetch_add(1, Ordering::Relaxed);
        self.total_time_ns.fetch_add(nanos, Ordering::Relaxed);

        // Update min (with compare-and-swap loop)
        let mut current_min = self.min_time_ns.load(Ordering::Relaxed);
        while nanos < current_min {
            match self.min_time_ns.compare_exchange_weak(
                current_min,
                nanos,
                Ordering::Relaxed,
                Ordering::Relaxed,
            ) {
                Ok(_) => break,
                Err(x) => current_min = x,
            }
        }

        // Update max (with compare-and-swap loop)
        let mut current_max = self.max_time_ns.load(Ordering::Relaxed);
        while nanos > current_max {
            match self.max_time_ns.compare_exchange_weak(
                current_max,
                nanos,
                Ordering::Relaxed,
                Ordering::Relaxed,
            ) {
                Ok(_) => break,
                Err(x) => current_max = x,
            }
        }
    }

    /// Get performance statistics.
    pub fn stats(&self) -> PerfStats {
        let count = self.count.load(Ordering::Relaxed);
        let total_ns = self.total_time_ns.load(Ordering::Relaxed);
        let min_ns = self.min_time_ns.load(Ordering::Relaxed);
        let max_ns = self.max_time_ns.load(Ordering::Relaxed);

        let avg_ns = if count > 0 { total_ns / count } else { 0 };

        PerfStats {
            count,
            total_time: Duration::from_nanos(total_ns),
            avg_time: Duration::from_nanos(avg_ns),
            min_time: if min_ns == u64::MAX {
                Duration::ZERO
            } else {
                Duration::from_nanos(min_ns)
            },
            max_time: Duration::from_nanos(max_ns),
        }
    }

    /// Reset all counters.
    pub fn reset(&self) {
        self.count.store(0, Ordering::Relaxed);
        self.total_time_ns.store(0, Ordering::Relaxed);
        self.min_time_ns.store(u64::MAX, Ordering::Relaxed);
        self.max_time_ns.store(0, Ordering::Relaxed);
    }
}

impl Default for PerfCounter {
    fn default() -> Self {
        Self::new()
    }
}

/// Performance statistics snapshot.
#[derive(Debug, Clone)]
pub struct PerfStats {
    /// Number of operations recorded
    pub count: u64,
    /// Total time across all operations
    pub total_time: Duration,
    /// Average time per operation
    pub avg_time: Duration,
    /// Minimum operation time
    pub min_time: Duration,
    /// Maximum operation time
    pub max_time: Duration,
}

impl PerfStats {
    /// Calculate operations per second.
    pub fn ops_per_sec(&self) -> f64 {
        if self.total_time.is_zero() {
            0.0
        } else {
            self.count as f64 / self.total_time.as_secs_f64()
        }
    }

    /// Calculate throughput in bytes per second.
    pub fn throughput_bps(&self, bytes_per_op: u64) -> f64 {
        self.ops_per_sec() * bytes_per_op as f64
    }
}

/// RAII timer for automatic performance measurement.
pub struct PerfTimer<'a> {
    counter: &'a PerfCounter,
    start: Instant,
}

impl<'a> PerfTimer<'a> {
    /// Start timing an operation.
    pub fn new(counter: &'a PerfCounter) -> Self {
        Self {
            counter,
            start: Instant::now(),
        }
    }
}

impl<'a> Drop for PerfTimer<'a> {
    fn drop(&mut self) {
        let duration = self.start.elapsed();
        self.counter.record(duration);
    }
}

/// Memory usage tracker.
#[derive(Debug)]
pub struct MemoryTracker {
    /// Current allocated bytes
    allocated: AtomicUsize,
    /// Peak allocated bytes
    peak: AtomicUsize,
    /// Total allocations
    total_allocs: AtomicU64,
    /// Total deallocations
    total_deallocs: AtomicU64,
}

impl MemoryTracker {
    /// Create a new memory tracker.
    pub fn new() -> Self {
        Self {
            allocated: AtomicUsize::new(0),
            peak: AtomicUsize::new(0),
            total_allocs: AtomicU64::new(0),
            total_deallocs: AtomicU64::new(0),
        }
    }

    /// Record an allocation.
    pub fn record_alloc(&self, size: usize) {
        let new_allocated = self.allocated.fetch_add(size, Ordering::Relaxed) + size;
        self.total_allocs.fetch_add(1, Ordering::Relaxed);

        // Update peak
        let mut current_peak = self.peak.load(Ordering::Relaxed);
        while new_allocated > current_peak {
            match self.peak.compare_exchange_weak(
                current_peak,
                new_allocated,
                Ordering::Relaxed,
                Ordering::Relaxed,
            ) {
                Ok(_) => break,
                Err(x) => current_peak = x,
            }
        }
    }

    /// Record a deallocation.
    pub fn record_dealloc(&self, size: usize) {
        self.allocated.fetch_sub(size, Ordering::Relaxed);
        self.total_deallocs.fetch_add(1, Ordering::Relaxed);
    }

    /// Get current memory usage.
    pub fn current_usage(&self) -> usize {
        self.allocated.load(Ordering::Relaxed)
    }

    /// Get peak memory usage.
    pub fn peak_usage(&self) -> usize {
        self.peak.load(Ordering::Relaxed)
    }

    /// Get memory statistics.
    pub fn stats(&self) -> MemoryStats {
        MemoryStats {
            current: self.allocated.load(Ordering::Relaxed),
            peak: self.peak.load(Ordering::Relaxed),
            total_allocs: self.total_allocs.load(Ordering::Relaxed),
            total_deallocs: self.total_deallocs.load(Ordering::Relaxed),
        }
    }

    /// Reset all counters.
    pub fn reset(&self) {
        self.allocated.store(0, Ordering::Relaxed);
        self.peak.store(0, Ordering::Relaxed);
        self.total_allocs.store(0, Ordering::Relaxed);
        self.total_deallocs.store(0, Ordering::Relaxed);
    }
}

impl Default for MemoryTracker {
    fn default() -> Self {
        Self::new()
    }
}

/// Memory usage statistics.
#[derive(Debug, Clone)]
pub struct MemoryStats {
    /// Current allocated bytes
    pub current: usize,
    /// Peak allocated bytes
    pub peak: usize,
    /// Total number of allocations
    pub total_allocs: u64,
    /// Total number of deallocations
    pub total_deallocs: u64,
}

impl MemoryStats {
    /// Calculate allocation rate (allocs per second).
    pub fn alloc_rate(&self, duration: Duration) -> f64 {
        if duration.is_zero() {
            0.0
        } else {
            self.total_allocs as f64 / duration.as_secs_f64()
        }
    }

    /// Calculate average allocation size.
    pub fn avg_alloc_size(&self) -> f64 {
        if self.total_allocs > 0 {
            self.peak as f64 / self.total_allocs as f64
        } else {
            0.0
        }
    }
}

/// Global performance registry for collecting metrics across the library.
pub struct PerfRegistry {
    counters: std::collections::HashMap<String, Arc<PerfCounter>>,
    memory_tracker: Arc<MemoryTracker>,
}

impl PerfRegistry {
    /// Create a new performance registry.
    pub fn new() -> Self {
        Self {
            counters: std::collections::HashMap::new(),
            memory_tracker: Arc::new(MemoryTracker::new()),
        }
    }

    /// Get or create a performance counter.
    pub fn counter(&mut self, name: &str) -> Arc<PerfCounter> {
        self.counters
            .entry(name.to_string())
            .or_insert_with(|| Arc::new(PerfCounter::new()))
            .clone()
    }

    /// Get the memory tracker.
    pub fn memory_tracker(&self) -> Arc<MemoryTracker> {
        self.memory_tracker.clone()
    }

    /// Get all counter statistics.
    pub fn all_stats(&self) -> std::collections::HashMap<String, PerfStats> {
        self.counters
            .iter()
            .map(|(name, counter)| (name.clone(), counter.stats()))
            .collect()
    }

    /// Reset all counters.
    pub fn reset_all(&self) {
        for counter in self.counters.values() {
            counter.reset();
        }
        self.memory_tracker.reset();
    }
}

impl Default for PerfRegistry {
    fn default() -> Self {
        Self::new()
    }
}

/// Macro for easy performance timing.
#[macro_export]
macro_rules! time_operation {
    ($counter:expr, $operation:expr) => {{
        let _timer = $crate::perf::PerfTimer::new($counter);
        $operation
    }};
}

/// Macro for timing async operations.
#[macro_export]
macro_rules! time_async_operation {
    ($counter:expr, $operation:expr) => {{
        let start = std::time::Instant::now();
        let result = $operation.await;
        $counter.record(start.elapsed());
        result
    }};
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_perf_counter() {
        let counter = PerfCounter::new();

        counter.record(Duration::from_millis(10));
        counter.record(Duration::from_millis(20));
        counter.record(Duration::from_millis(5));

        let stats = counter.stats();
        assert_eq!(stats.count, 3);
        assert_eq!(stats.min_time, Duration::from_millis(5));
        assert_eq!(stats.max_time, Duration::from_millis(20));
        assert!(stats.avg_time >= Duration::from_millis(11));
        assert!(stats.avg_time <= Duration::from_millis(12));
    }

    #[test]
    fn test_perf_timer() {
        let counter = PerfCounter::new();

        {
            let _timer = PerfTimer::new(&counter);
            thread::sleep(Duration::from_millis(10));
        }

        let stats = counter.stats();
        assert_eq!(stats.count, 1);
        assert!(stats.total_time >= Duration::from_millis(9));
    }

    #[test]
    fn test_memory_tracker() {
        let tracker = MemoryTracker::new();

        tracker.record_alloc(1024);
        assert_eq!(tracker.current_usage(), 1024);
        assert_eq!(tracker.peak_usage(), 1024);

        tracker.record_alloc(2048);
        assert_eq!(tracker.current_usage(), 3072);
        assert_eq!(tracker.peak_usage(), 3072);

        tracker.record_dealloc(1024);
        assert_eq!(tracker.current_usage(), 2048);
        assert_eq!(tracker.peak_usage(), 3072); // Peak doesn't decrease
    }

    #[test]
    fn test_perf_registry() {
        let mut registry = PerfRegistry::new();

        let counter1 = registry.counter("test1");
        let counter2 = registry.counter("test2");

        counter1.record(Duration::from_millis(10));
        counter2.record(Duration::from_millis(20));

        let all_stats = registry.all_stats();
        assert_eq!(all_stats.len(), 2);
        assert!(all_stats.contains_key("test1"));
        assert!(all_stats.contains_key("test2"));
    }

    #[test]
    fn test_concurrent_perf_counter() {
        let counter = Arc::new(PerfCounter::new());
        let mut handles = vec![];

        for _ in 0..10 {
            let counter_clone = counter.clone();
            handles.push(thread::spawn(move || {
                for _ in 0..100 {
                    counter_clone.record(Duration::from_nanos(1000));
                }
            }));
        }

        for handle in handles {
            handle.join().unwrap();
        }

        let stats = counter.stats();
        assert_eq!(stats.count, 1000);
    }
}
</file>

<file path="runtime.rs">
//! Runtime detection and fallback system for safer-ring.
//!
//! This module provides runtime detection of io_uring availability and automatic
//! fallback to alternative implementations when io_uring is not available. This is
//! particularly important in cloud environments like Docker, Kubernetes (GKE, EKS),
//! and serverless platforms where io_uring is often disabled by default.
//!
//! # Architecture
//!
//! The runtime uses a backend abstraction that can switch between:
//! - **IoUringBackend**: Full io_uring implementation (Linux 5.1+)
//! - **EpollBackend**: Traditional epoll-based fallback (all Linux)
//! - **StubBackend**: No-op implementation for non-Linux platforms
//!
//! # Example
//!
//! ```rust,no_run
//! use safer_ring::runtime::{Runtime, Backend};
//!
//! # fn main() -> Result<(), Box<dyn std::error::Error>> {
//! // Automatically detect best available backend
//! let runtime = Runtime::auto_detect()?;
//!
//! match runtime.backend() {
//!     Backend::IoUring => println!("Using high-performance io_uring"),
//!     Backend::Epoll => println!("Using epoll fallback"),
//!     Backend::Stub => println!("Using stub implementation"),
//! }
//!
//! // Check if we're in a restricted environment
//! if runtime.is_cloud_environment() {
//!     println!("Detected cloud environment, see docs for optimization tips");
//! }
//! # Ok(())
//! # }
//! ```

use std::fs;
use std::io;
use std::path::Path;

use crate::error::{Result, SaferRingError};

/// Available runtime backends for IO operations.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Backend {
    /// High-performance io_uring backend (Linux 5.1+)
    IoUring,
    /// Traditional epoll-based backend (all Linux)
    Epoll,
    /// Stub implementation for non-Linux platforms
    Stub,
}

impl Backend {
    /// Get a human-readable description of the backend.
    pub fn description(&self) -> &'static str {
        match self {
            Backend::IoUring => "High-performance io_uring backend",
            Backend::Epoll => "Traditional epoll-based backend",
            Backend::Stub => "Stub implementation for non-Linux platforms",
        }
    }

    /// Check if this backend supports advanced features.
    pub fn supports_advanced_features(&self) -> bool {
        matches!(self, Backend::IoUring)
    }

    /// Get expected performance multiplier compared to epoll baseline.
    pub fn performance_multiplier(&self) -> f32 {
        match self {
            Backend::IoUring => 3.0, // 3x performance improvement
            Backend::Epoll => 1.0,   // Baseline
            Backend::Stub => 0.1,    // Minimal performance
        }
    }
}

/// Runtime environment with automatic backend detection and fallback.
///
/// The runtime automatically detects the best available backend and provides
/// information about the current environment for optimization guidance.
#[derive(Debug)]
pub struct Runtime {
    backend: Backend,
    environment: EnvironmentInfo,
}

impl Runtime {
    /// Create a new runtime with automatic backend detection.
    ///
    /// This method probes the system for io_uring availability and selects
    /// the best available backend. If io_uring is not available, it falls
    /// back to epoll (on Linux) or stub implementation (on other platforms).
    ///
    /// # Returns
    ///
    /// A runtime configured with the optimal backend for the current environment.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::runtime::Runtime;
    ///
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let runtime = Runtime::auto_detect()?;
    /// println!("Using backend: {}", runtime.backend().description());
    /// # Ok(())
    /// # }
    /// ```
    pub fn auto_detect() -> Result<Self> {
        let environment = EnvironmentInfo::detect();
        let backend = Self::select_best_backend(&environment)?;

        // Log warnings for restricted environments
        if environment.is_cloud_environment() && backend != Backend::IoUring {
            eprintln!("WARNING: io_uring not available in cloud environment");
            eprintln!("Performance may be degraded. See documentation for configuration tips:");
            eprintln!("- Docker: Add --cap-add SYS_ADMIN or use --privileged");
            eprintln!("- Kubernetes: Set privileged: true or configure seccomp/apparmor");
            eprintln!("- Cloud Run/Lambda: Consider using Cloud Functions with custom runtimes");
        }

        Ok(Self {
            backend,
            environment,
        })
    }

    /// Create a runtime with a specific backend.
    ///
    /// This bypasses automatic detection and forces the use of a specific backend.
    /// Use this when you want to test fallback behavior or have specific requirements.
    ///
    /// # Arguments
    ///
    /// * `backend` - The backend to use
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use safer_ring::runtime::{Runtime, Backend};
    ///
    /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// // Force epoll backend for testing
    /// let runtime = Runtime::with_backend(Backend::Epoll)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn with_backend(backend: Backend) -> Result<Self> {
        let environment = EnvironmentInfo::detect();

        // Validate that the requested backend is available
        match backend {
            Backend::IoUring => {
                if !Self::is_io_uring_available() {
                    return Err(SaferRingError::Io(io::Error::new(
                        io::ErrorKind::Unsupported,
                        "io_uring backend requested but not available on this system",
                    )));
                }
            }
            Backend::Epoll => {
                #[cfg(not(target_os = "linux"))]
                {
                    return Err(SaferRingError::Io(io::Error::new(
                        io::ErrorKind::Unsupported,
                        "epoll backend only available on Linux",
                    )));
                }
            }
            Backend::Stub => {
                // Stub backend is always available
            }
        }

        Ok(Self {
            backend,
            environment,
        })
    }

    /// Get the active backend.
    pub fn backend(&self) -> Backend {
        self.backend
    }

    /// Get environment information.
    pub fn environment(&self) -> &EnvironmentInfo {
        &self.environment
    }

    /// Check if running in a cloud environment.
    pub fn is_cloud_environment(&self) -> bool {
        self.environment.is_cloud_environment()
    }

    /// Get performance guidance for the current environment.
    pub fn performance_guidance(&self) -> Vec<&'static str> {
        let mut guidance = Vec::new();

        match self.backend {
            Backend::IoUring => {
                guidance.push("✓ Using high-performance io_uring backend");
                if self.environment.container_runtime.is_some() {
                    guidance
                        .push("Consider tuning container security settings for better performance");
                }
            }
            Backend::Epoll => {
                guidance.push("⚠ Using epoll fallback - performance may be limited");
                if self.is_cloud_environment() {
                    guidance
                        .push("Check cloud platform documentation for enabling io_uring support");
                }
            }
            Backend::Stub => {
                guidance.push("⚠ Using stub implementation - limited functionality");
                guidance.push("Consider running on Linux for better performance");
            }
        }

        if let Some(container) = &self.environment.container_runtime {
            match container.as_str() {
                "docker" => {
                    guidance.push("Docker detected: Add --cap-add SYS_ADMIN for io_uring support");
                }
                "containerd" | "cri-o" => {
                    guidance.push(
                        "Kubernetes detected: Configure privileged pods or custom seccomp profiles",
                    );
                }
                _ => {}
            }
        }

        guidance
    }

    /// Select the best available backend for the current environment.
    fn select_best_backend(_environment: &EnvironmentInfo) -> Result<Backend> {
        // Check platform first
        #[cfg(not(target_os = "linux"))]
        {
            Ok(Backend::Stub)
        }

        #[cfg(target_os = "linux")]
        {
            // Try io_uring first
            if Self::is_io_uring_available() {
                // Additional checks for restricted environments
                if _environment.is_cloud_environment() {
                    // In cloud environments, io_uring might be restricted
                    if let Some(restriction) = Self::check_io_uring_restrictions() {
                        eprintln!("io_uring restricted: {}", restriction);
                        return Ok(Backend::Epoll);
                    }
                }
                return Ok(Backend::IoUring);
            }

            // Fall back to epoll
            Ok(Backend::Epoll)
        }
    }

    /// Check if io_uring is available on the system.
    #[cfg(target_os = "linux")]
    fn is_io_uring_available() -> bool {
        // Try to create a minimal io_uring instance
        match io_uring::IoUring::new(1) {
            Ok(_) => true,
            Err(_) => false,
        }
    }

    /// Check if io_uring is available (always false on non-Linux).
    #[cfg(not(target_os = "linux"))]
    fn is_io_uring_available() -> bool {
        false
    }

    /// Check for io_uring restrictions in the current environment.
    #[cfg(target_os = "linux")]
    #[allow(dead_code)]
    fn check_io_uring_restrictions() -> Option<String> {
        // Check seccomp restrictions
        if let Ok(status) = fs::read_to_string("/proc/self/status") {
            if status.contains("Seccomp:") && !status.contains("Seccomp:\t0") {
                return Some("seccomp profile may restrict io_uring system calls".to_string());
            }
        }

        // Check AppArmor restrictions
        if Path::new("/proc/self/attr/current").exists() {
            if let Ok(apparmor) = fs::read_to_string("/proc/self/attr/current") {
                if !apparmor.trim().is_empty() && apparmor.trim() != "unconfined" {
                    return Some("AppArmor profile may restrict io_uring".to_string());
                }
            }
        }

        // Check for container indicators that might restrict io_uring
        if Path::new("/.dockerenv").exists() {
            return Some("Docker environment detected - io_uring may be restricted".to_string());
        }

        None
    }

    /// Check for io_uring restrictions (no-op on non-Linux).
    #[cfg(not(target_os = "linux"))]
    #[allow(dead_code)]
    fn check_io_uring_restrictions() -> Option<String> {
        None
    }
}

/// Information about the runtime environment.
///
/// Collects information about the system environment to help guide
/// performance optimization and provide helpful warnings.
#[derive(Debug)]
pub struct EnvironmentInfo {
    /// Detected container runtime (docker, containerd, etc.)
    pub container_runtime: Option<String>,
    /// Whether running in Kubernetes
    pub kubernetes: bool,
    /// Whether running in a cloud serverless environment
    pub serverless: bool,
    /// Kernel version for Linux systems
    pub kernel_version: Option<String>,
    /// Available CPU count
    pub cpu_count: usize,
}

impl EnvironmentInfo {
    /// Detect current environment information.
    pub fn detect() -> Self {
        Self {
            container_runtime: Self::detect_container_runtime(),
            kubernetes: Self::detect_kubernetes(),
            serverless: Self::detect_serverless(),
            kernel_version: Self::detect_kernel_version(),
            cpu_count: Self::detect_cpu_count(),
        }
    }

    /// Check if running in any kind of cloud environment.
    pub fn is_cloud_environment(&self) -> bool {
        self.container_runtime.is_some() || self.kubernetes || self.serverless
    }

    /// Detect container runtime.
    fn detect_container_runtime() -> Option<String> {
        // Check for Docker
        if Path::new("/.dockerenv").exists() {
            return Some("docker".to_string());
        }

        // Check for other container indicators
        if let Ok(cgroup) = fs::read_to_string("/proc/1/cgroup") {
            if cgroup.contains("docker") {
                return Some("docker".to_string());
            }
            if cgroup.contains("containerd") {
                return Some("containerd".to_string());
            }
            if cgroup.contains("cri-o") {
                return Some("cri-o".to_string());
            }
        }

        None
    }

    /// Detect Kubernetes environment.
    fn detect_kubernetes() -> bool {
        std::env::var("KUBERNETES_SERVICE_HOST").is_ok()
            || Path::new("/var/run/secrets/kubernetes.io").exists()
    }

    /// Detect serverless environment.
    fn detect_serverless() -> bool {
        // AWS Lambda
        std::env::var("AWS_LAMBDA_FUNCTION_NAME").is_ok() ||
        // Google Cloud Functions
        std::env::var("FUNCTION_NAME").is_ok() ||
        // Azure Functions
        std::env::var("AZURE_FUNCTIONS_ENVIRONMENT").is_ok() ||
        // Cloud Run
        std::env::var("K_SERVICE").is_ok()
    }

    /// Detect kernel version on Linux.
    #[cfg(target_os = "linux")]
    fn detect_kernel_version() -> Option<String> {
        fs::read_to_string("/proc/version")
            .ok()
            .and_then(|v| v.split_whitespace().nth(2).map(|s| s.to_string()))
    }

    /// Detect kernel version (none on non-Linux).
    #[cfg(not(target_os = "linux"))]
    fn detect_kernel_version() -> Option<String> {
        None
    }

    /// Detect CPU count.
    fn detect_cpu_count() -> usize {
        std::thread::available_parallelism()
            .map(|p| p.get())
            .unwrap_or(1)
    }
}

/// Check if io_uring is available in the current environment.
///
/// This is a convenience function that creates a minimal runtime to test availability.
///
/// # Example
///
/// ```rust,no_run
/// use safer_ring::runtime::is_io_uring_available;
///
/// if is_io_uring_available() {
///     println!("io_uring is available!");
/// } else {
///     println!("io_uring is not available, will use fallback");
/// }
/// ```
pub fn is_io_uring_available() -> bool {
    Runtime::is_io_uring_available()
}

/// Get environment information for the current system.
///
/// # Example
///
/// ```rust,no_run
/// use safer_ring::runtime::get_environment_info;
///
/// let env = get_environment_info();
/// if env.is_cloud_environment() {
///     println!("Running in cloud environment");
/// }
/// println!("CPU count: {}", env.cpu_count);
/// ```
pub fn get_environment_info() -> EnvironmentInfo {
    EnvironmentInfo::detect()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_backend_properties() {
        assert_eq!(
            Backend::IoUring.description(),
            "High-performance io_uring backend"
        );
        assert_eq!(
            Backend::Epoll.description(),
            "Traditional epoll-based backend"
        );
        assert_eq!(
            Backend::Stub.description(),
            "Stub implementation for non-Linux platforms"
        );

        assert!(Backend::IoUring.supports_advanced_features());
        assert!(!Backend::Epoll.supports_advanced_features());
        assert!(!Backend::Stub.supports_advanced_features());

        assert_eq!(Backend::IoUring.performance_multiplier(), 3.0);
        assert_eq!(Backend::Epoll.performance_multiplier(), 1.0);
        assert_eq!(Backend::Stub.performance_multiplier(), 0.1);
    }

    #[test]
    fn test_runtime_auto_detect() {
        let runtime = Runtime::auto_detect().unwrap();

        // Should have detected some backend
        match runtime.backend() {
            Backend::IoUring | Backend::Epoll | Backend::Stub => {}
        }

        // Environment should be detected
        let env = runtime.environment();
        assert!(env.cpu_count > 0);
    }

    #[test]
    fn test_environment_detection() {
        let env = EnvironmentInfo::detect();

        // Should detect CPU count
        assert!(env.cpu_count > 0);

        // Cloud environment detection should not panic
        let _ = env.is_cloud_environment();
    }

    #[test]
    fn test_performance_guidance() {
        let runtime = Runtime::auto_detect().unwrap();
        let guidance = runtime.performance_guidance();

        // Should provide at least one guidance point
        assert!(!guidance.is_empty());

        // Each guidance should be non-empty
        for guide in guidance {
            assert!(!guide.is_empty());
        }
    }

    #[cfg(target_os = "linux")]
    #[test]
    fn test_stub_backend_on_non_linux_request() {
        // On Linux, requesting stub should work
        let runtime = Runtime::with_backend(Backend::Stub).unwrap();
        assert_eq!(runtime.backend(), Backend::Stub);
    }

    #[cfg(not(target_os = "linux"))]
    #[test]
    fn test_epoll_backend_fails_on_non_linux() {
        // On non-Linux, requesting epoll should fail
        let result = Runtime::with_backend(Backend::Epoll);
        assert!(result.is_err());
    }

    #[test]
    fn test_is_io_uring_available() {
        // Should not panic regardless of availability
        let _ = is_io_uring_available();
    }

    #[test]
    fn test_get_environment_info() {
        let env = get_environment_info();
        assert!(env.cpu_count > 0);
    }
}
</file>

<file path="safety.rs">
//! Cancellation safety mechanisms for io_uring operations.
//!
//! This module implements the core safety feature that makes safer-ring truly safe:
//! proper handling of cancelled futures and orphaned operations. When a future is
//! dropped before completion, the kernel may still be using the buffer, so we track
//! these "orphaned" operations and safely handle their completion.
//!
//! # Core Safety Principle
//!
//! When an io_uring operation future is dropped (cancelled):
//! 1. The buffer ownership remains with the kernel
//! 2. The operation is marked as "orphaned"
//! 3. When the operation completes, the buffer is safely returned
//! 4. No use-after-free or double-free can occur
//!
//! # Example
//!
//! ```rust,no_run
//! use safer_ring::safety::SafeOperation;
//! use safer_ring::ownership::OwnedBuffer;
//!
//! # async fn example() -> Result<(), Box<dyn std::error::Error>> {
//! let buffer = OwnedBuffer::new(1024);
//!
//! // Create a safe operation
//! let operation = SafeOperation::new(buffer, 123);
//!
//! // If this future is dropped, the buffer stays with kernel
//! let _future = operation.into_future();
//! // drop(_future); // Safe - buffer ownership tracked
//!
//! # Ok(())
//! # }
//! ```

use std::collections::HashMap;
use std::pin::Pin;
#[cfg(test)]
use std::sync::Arc;
use std::sync::{Mutex, Weak};
use std::task::{Context, Poll};

use crate::error::{Result, SaferRingError};
use crate::ownership::OwnedBuffer;

/// A submission ID for tracking operations.
pub type SubmissionId = u64;

/// Trait for checking completion of operations.
///
/// This trait allows SafeOperationFuture to check for completions
/// without holding a direct reference to the Ring.
pub trait CompletionChecker {
    /// Try to complete a specific operation by its submission ID.
    ///
    /// Returns:
    /// - `Ok(Some(result))` if the operation completed with the given result
    /// - `Ok(None)` if the operation is still pending
    /// - `Err(e)` if there was an error checking completion
    fn try_complete_safe_operation(
        &self,
        submission_id: SubmissionId,
    ) -> Result<Option<std::io::Result<i32>>>;
}

/// An operation that can be safely cancelled without causing memory safety issues.
///
/// When a `SafeOperation` is dropped before completion, the buffer ownership
/// remains with the kernel until the operation actually completes. This prevents
/// use-after-free bugs that can occur with raw io_uring usage.
///
/// The operation is tied to a specific ring via the orphan tracker, ensuring
/// that cancelled operations are properly handled when the ring processes completions.
pub struct SafeOperation {
    submission_id: SubmissionId,
    buffer: Option<OwnedBuffer>,
    orphan_tracker: Weak<Mutex<OrphanTracker>>,
    completed: bool,
}

impl SafeOperation {
    /// Create a new safe operation.
    ///
    /// # Arguments
    ///
    /// * `buffer` - The buffer to use for the operation
    /// * `submission_id` - Unique ID for tracking the operation
    /// * `orphan_tracker` - Weak reference to the ring's orphan tracker
    ///
    /// # Returns
    ///
    /// A new safe operation that can be cancelled without memory safety issues.
    pub fn new(
        buffer: OwnedBuffer,
        submission_id: SubmissionId,
        orphan_tracker: Weak<Mutex<OrphanTracker>>,
    ) -> Self {
        Self {
            submission_id,
            buffer: Some(buffer),
            orphan_tracker,
            completed: false,
        }
    }

    /// Create a failed safe operation.
    ///
    /// This is used when submission fails but we still need to return the buffer
    /// to the user in a failed state.
    ///
    /// # Arguments
    ///
    /// * `buffer` - The buffer to return to the user
    /// * `submission_id` - Unique ID that was assigned (but not used)
    /// * `orphan_tracker` - Weak reference to the ring's orphan tracker
    ///
    /// # Returns
    ///
    /// A safe operation that will immediately fail when polled.
    pub fn failed(
        buffer: OwnedBuffer,
        submission_id: SubmissionId,
        orphan_tracker: Weak<Mutex<OrphanTracker>>,
    ) -> Self {
        Self {
            submission_id,
            buffer: Some(buffer),
            orphan_tracker,
            completed: true, // Mark as completed so it fails immediately
        }
    }

    /// Get the submission ID for this operation.
    pub fn submission_id(&self) -> SubmissionId {
        self.submission_id
    }

    /// Check if the operation has completed.
    pub fn is_completed(&self) -> bool {
        self.completed
    }

    /// Mark the operation as completed and return the buffer.
    ///
    /// This should only be called when the operation has actually completed
    /// and the kernel has finished using the buffer.
    ///
    /// # Returns
    ///
    /// The buffer that was used for the operation.
    pub fn complete(mut self) -> Result<OwnedBuffer> {
        self.completed = true;
        // We need to move the buffer out before drop runs
        self.buffer.take().ok_or_else(|| {
            SaferRingError::Io(std::io::Error::other("Operation buffer already taken"))
        })
    }

    /// Convert this operation into a future that can be awaited.
    ///
    /// The returned future will resolve when the operation completes.
    ///
    /// # Arguments
    ///
    /// * `ring` - Ring reference for checking operation completion
    pub(crate) fn into_future<'ring>(
        self,
        ring: &'ring dyn CompletionChecker,
        waker_registry: std::sync::Arc<crate::future::WakerRegistry>,
    ) -> SafeOperationFuture<'ring> {
        SafeOperationFuture {
            operation: Some(self),
            ring,
            waker_registry,
        }
    }

    /// Get the buffer size for debugging.
    pub fn buffer_size(&self) -> Option<usize> {
        self.buffer.as_ref().map(|b| b.size())
    }

    /// Get buffer pointer and size for operation submission.
    ///
    /// Returns (ptr, size) tuple for the buffer by transferring ownership to kernel.
    pub fn buffer_info(&self) -> Result<(*mut u8, usize)> {
        if let Some(buffer) = &self.buffer {
            buffer.give_to_kernel(self.submission_id)
        } else {
            Ok((std::ptr::null_mut(), 0))
        }
    }
}

impl Drop for SafeOperation {
    fn drop(&mut self) {
        if !self.completed && self.buffer.is_some() {
            // Operation was cancelled - register as orphaned
            if let Some(tracker) = self.orphan_tracker.upgrade() {
                if let Ok(mut tracker) = tracker.lock() {
                    if let Some(buffer) = &self.buffer {
                        tracker.register_orphan(self.submission_id, buffer.clone_handle());
                    }
                }
            }
        }
    }
}

/// Future representing a safe io_uring operation.
///
/// This future resolves to `(bytes_transferred, buffer)` when the operation completes.
/// If the future is dropped before completion, the operation becomes orphaned and
/// the buffer is safely handled by the orphan tracking system.
pub struct SafeOperationFuture<'ring> {
    operation: Option<SafeOperation>,
    ring: &'ring dyn CompletionChecker,
    waker_registry: std::sync::Arc<crate::future::WakerRegistry>,
}

impl<'ring> std::future::Future for SafeOperationFuture<'ring> {
    type Output = Result<(usize, OwnedBuffer)>;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        if let Some(mut operation) = self.operation.take() {
            // If operation was marked as failed during creation, return error immediately
            if operation.completed && operation.buffer.is_some() {
                let _buffer = operation.buffer.take().unwrap();
                return Poll::Ready(Err(SaferRingError::Io(std::io::Error::other(
                    "Operation failed during submission",
                ))));
            }

            // Check if the operation has completed
            match self
                .ring
                .try_complete_safe_operation(operation.submission_id)
            {
                Ok(Some(completion_result)) => {
                    // Operation completed - extract the buffer and return result
                    operation.completed = true;
                    let buffer = operation.buffer.take().ok_or_else(|| {
                        SaferRingError::Io(std::io::Error::other(
                            "Operation buffer missing after completion",
                        ))
                    })?;

                    let bytes_transferred = completion_result.map_err(SaferRingError::Io)?;
                    Poll::Ready(Ok((bytes_transferred as usize, buffer)))
                }
                Ok(None) => {
                    // Operation still pending - store operation back and register waker
                    let submission_id = operation.submission_id;
                    self.operation = Some(operation);

                    // Register the waker so it gets notified when the operation completes
                    self.waker_registry
                        .register_waker(submission_id, cx.waker().clone());

                    Poll::Pending
                }
                Err(e) => {
                    // Error checking for completion
                    Poll::Ready(Err(e))
                }
            }
        } else {
            // Future was already completed or operation was taken
            Poll::Ready(Err(SaferRingError::Io(std::io::Error::other(
                "Operation future polled after completion",
            ))))
        }
    }
}

/// Future representing a safe accept operation.
///
/// This future resolves to `(bytes_transferred, buffer)` when the accept completes,
/// but for accept operations, the useful result is extracted from the completion.
pub struct SafeAcceptFuture<'ring> {
    operation: Option<SafeOperation>,
    ring: &'ring dyn CompletionChecker,
    waker_registry: std::sync::Arc<crate::future::WakerRegistry>,
}

impl<'ring> SafeAcceptFuture<'ring> {
    /// Create a new safe accept future.
    pub(crate) fn new(
        operation: SafeOperation,
        ring: &'ring dyn CompletionChecker,
        waker_registry: std::sync::Arc<crate::future::WakerRegistry>,
    ) -> Self {
        Self {
            operation: Some(operation),
            ring,
            waker_registry,
        }
    }
}

impl<'ring> std::future::Future for SafeAcceptFuture<'ring> {
    type Output = Result<(usize, OwnedBuffer)>;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {
        if let Some(mut operation) = self.operation.take() {
            // If operation was marked as failed during creation, return error immediately
            if operation.completed && operation.buffer.is_some() {
                let _buffer = operation.buffer.take().unwrap();
                return Poll::Ready(Err(SaferRingError::Io(std::io::Error::other(
                    "Accept operation failed during submission",
                ))));
            }

            // Check if the operation has completed
            match self
                .ring
                .try_complete_safe_operation(operation.submission_id)
            {
                Ok(Some(completion_result)) => {
                    // Operation completed - extract the buffer and return result
                    operation.completed = true;
                    let buffer = operation.buffer.take().ok_or_else(|| {
                        SaferRingError::Io(std::io::Error::other(
                            "Accept operation buffer missing after completion",
                        ))
                    })?;

                    let bytes_transferred = completion_result.map_err(SaferRingError::Io)?;
                    Poll::Ready(Ok((bytes_transferred as usize, buffer)))
                }
                Ok(None) => {
                    // Operation still pending - store operation back and register waker
                    let submission_id = operation.submission_id;
                    self.operation = Some(operation);

                    // Register the waker so it gets notified when the operation completes
                    self.waker_registry
                        .register_waker(submission_id, cx.waker().clone());

                    Poll::Pending
                }
                Err(e) => {
                    // Error checking for completion
                    Poll::Ready(Err(e))
                }
            }
        } else {
            // Future was already completed or operation was taken
            Poll::Ready(Err(SaferRingError::Io(std::io::Error::other(
                "Accept future polled after completion",
            ))))
        }
    }
}

/// Tracks orphaned operations whose futures were dropped before completion.
///
/// The orphan tracker maintains a mapping from submission IDs to buffer handles
/// for operations that were cancelled. When these operations complete, the
/// tracker ensures the buffers are properly cleaned up.
///
/// This is a critical safety component that prevents memory leaks and ensures
/// that cancelled operations don't cause issues when they eventually complete.
#[derive(Debug)]
pub struct OrphanTracker {
    /// Map from submission ID to orphaned buffer handle
    orphaned_operations: HashMap<SubmissionId, OwnedBuffer>,
    /// Counter for generating unique submission IDs
    next_submission_id: SubmissionId,
}

impl OrphanTracker {
    /// Create a new orphan tracker.
    pub fn new() -> Self {
        Self {
            orphaned_operations: HashMap::new(),
            next_submission_id: 1, // Start at 1, 0 reserved for invalid
        }
    }

    /// Generate a new unique submission ID.
    pub fn next_submission_id(&mut self) -> SubmissionId {
        let id = self.next_submission_id;
        self.next_submission_id = self.next_submission_id.wrapping_add(1);
        id
    }

    /// Register an orphaned operation.
    ///
    /// Called when a `SafeOperation` is dropped before completion.
    /// The buffer handle is stored until the operation actually completes.
    ///
    /// # Arguments
    ///
    /// * `submission_id` - ID of the orphaned operation
    /// * `buffer` - Buffer handle for the operation
    pub fn register_orphan(&mut self, submission_id: SubmissionId, buffer: OwnedBuffer) {
        self.orphaned_operations.insert(submission_id, buffer);
    }

    /// Process a completed operation, handling both active and orphaned operations.
    ///
    /// If the operation was orphaned, this cleans up the buffer handle.
    /// If the operation was active, this returns information for waking the future.
    ///
    /// # Arguments
    ///
    /// * `submission_id` - ID of the completed operation
    /// * `result` - Result of the operation (bytes transferred or error)
    ///
    /// # Returns
    ///
    /// - `Some(buffer)` if this was an orphaned operation
    /// - `None` if this was an active operation (should wake the future)
    pub fn handle_completion(
        &mut self,
        submission_id: SubmissionId,
        result: std::io::Result<i32>,
    ) -> Option<(OwnedBuffer, std::io::Result<i32>)> {
        self.orphaned_operations
            .remove(&submission_id)
            .map(|buffer| (buffer, result))
    }

    /// Get the number of currently orphaned operations.
    ///
    /// Useful for debugging and monitoring.
    pub fn orphan_count(&self) -> usize {
        self.orphaned_operations.len()
    }

    /// Check if an operation is orphaned.
    pub fn is_orphaned(&self, submission_id: SubmissionId) -> bool {
        self.orphaned_operations.contains_key(&submission_id)
    }

    /// Clean up all orphaned operations.
    ///
    /// This should be called when the ring is being dropped to ensure
    /// all buffers are properly released.
    ///
    /// # Returns
    ///
    /// The number of orphaned operations that were cleaned up.
    pub fn cleanup_all_orphans(&mut self) -> usize {
        let count = self.orphaned_operations.len();
        self.orphaned_operations.clear();
        count
    }
}

impl Default for OrphanTracker {
    fn default() -> Self {
        Self::new()
    }
}

/// Builder for safe operations with validation.
///
/// Provides a safe way to construct `SafeOperation` instances with proper
/// validation and error handling.
pub struct SafeOperationBuilder {
    buffer: Option<OwnedBuffer>,
    submission_id: Option<SubmissionId>,
    orphan_tracker: Option<Weak<Mutex<OrphanTracker>>>,
}

impl SafeOperationBuilder {
    /// Create a new operation builder.
    pub fn new() -> Self {
        Self {
            buffer: None,
            submission_id: None,
            orphan_tracker: None,
        }
    }

    /// Set the buffer for the operation.
    pub fn buffer(mut self, buffer: OwnedBuffer) -> Self {
        self.buffer = Some(buffer);
        self
    }

    /// Set the submission ID for the operation.
    pub fn submission_id(mut self, id: SubmissionId) -> Self {
        self.submission_id = Some(id);
        self
    }

    /// Set the orphan tracker for the operation.
    pub fn orphan_tracker(mut self, tracker: Weak<Mutex<OrphanTracker>>) -> Self {
        self.orphan_tracker = Some(tracker);
        self
    }

    /// Build the safe operation.
    ///
    /// # Errors
    ///
    /// Returns an error if required fields are not set.
    pub fn build(self) -> Result<SafeOperation> {
        let buffer = self.buffer.ok_or_else(|| {
            SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Buffer is required for safe operation",
            ))
        })?;

        let submission_id = self.submission_id.ok_or_else(|| {
            SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Submission ID is required for safe operation",
            ))
        })?;

        let orphan_tracker = self.orphan_tracker.ok_or_else(|| {
            SaferRingError::Io(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                "Orphan tracker is required for safe operation",
            ))
        })?;

        Ok(SafeOperation::new(buffer, submission_id, orphan_tracker))
    }
}

impl Default for SafeOperationBuilder {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_orphan_tracker_creation() {
        let tracker = OrphanTracker::new();
        assert_eq!(tracker.orphan_count(), 0);
    }

    #[test]
    fn test_submission_id_generation() {
        let mut tracker = OrphanTracker::new();
        let id1 = tracker.next_submission_id();
        let id2 = tracker.next_submission_id();
        assert_ne!(id1, id2);
        assert_eq!(id1, 1);
        assert_eq!(id2, 2);
    }

    #[test]
    fn test_orphan_registration() {
        let mut tracker = OrphanTracker::new();
        let buffer = OwnedBuffer::new(1024);
        let submission_id = 123;

        tracker.register_orphan(submission_id, buffer);
        assert_eq!(tracker.orphan_count(), 1);
        assert!(tracker.is_orphaned(submission_id));
    }

    #[test]
    fn test_orphan_completion_handling() {
        let mut tracker = OrphanTracker::new();
        let buffer = OwnedBuffer::new(1024);
        let submission_id = 123;

        // Register orphan
        tracker.register_orphan(submission_id, buffer);
        assert_eq!(tracker.orphan_count(), 1);

        // Handle completion
        let result = Ok(100); // 100 bytes transferred
        let completed = tracker.handle_completion(submission_id, result);

        assert!(completed.is_some());
        assert_eq!(tracker.orphan_count(), 0);
        assert!(!tracker.is_orphaned(submission_id));

        if let Some((buffer, result)) = completed {
            assert_eq!(buffer.size(), 1024);
            assert_eq!(result.unwrap(), 100);
        }
    }

    #[test]
    fn test_active_operation_completion() {
        let mut tracker = OrphanTracker::new();
        let submission_id = 456;

        // Handle completion of non-orphaned operation
        let result = Ok(50);
        let completed = tracker.handle_completion(submission_id, result);

        assert!(completed.is_none()); // Active operation, not orphaned
    }

    #[test]
    fn test_cleanup_all_orphans() {
        let mut tracker = OrphanTracker::new();

        // Register multiple orphans
        for i in 1..=5 {
            let buffer = OwnedBuffer::new(1024);
            tracker.register_orphan(i, buffer);
        }

        assert_eq!(tracker.orphan_count(), 5);

        let cleaned_up = tracker.cleanup_all_orphans();
        assert_eq!(cleaned_up, 5);
        assert_eq!(tracker.orphan_count(), 0);
    }

    #[test]
    fn test_safe_operation_creation() {
        let tracker = Arc::new(Mutex::new(OrphanTracker::new()));
        let buffer = OwnedBuffer::new(1024);
        let submission_id = 789;

        let operation = SafeOperation::new(buffer, submission_id, Arc::downgrade(&tracker));

        assert_eq!(operation.submission_id(), submission_id);
        assert!(!operation.is_completed());
        assert_eq!(operation.buffer_size(), Some(1024));
    }

    #[test]
    fn test_safe_operation_completion() {
        let tracker = Arc::new(Mutex::new(OrphanTracker::new()));
        let buffer = OwnedBuffer::new(512);
        let submission_id = 999;

        let operation = SafeOperation::new(buffer, submission_id, Arc::downgrade(&tracker));

        let returned_buffer = operation.complete().unwrap();
        assert_eq!(returned_buffer.size(), 512);

        // No orphan should be registered since operation completed normally
        let tracker_guard = tracker.lock().unwrap();
        assert_eq!(tracker_guard.orphan_count(), 0);
    }

    #[test]
    fn test_safe_operation_drop_registers_orphan() {
        let tracker = Arc::new(Mutex::new(OrphanTracker::new()));
        let buffer = OwnedBuffer::new(256);
        let submission_id = 111;

        {
            let _operation = SafeOperation::new(buffer, submission_id, Arc::downgrade(&tracker));
            // operation is dropped here without completion
        }

        // Should have registered as orphan
        let tracker_guard = tracker.lock().unwrap();
        assert_eq!(tracker_guard.orphan_count(), 1);
        assert!(tracker_guard.is_orphaned(submission_id));
    }

    #[test]
    fn test_safe_operation_builder() {
        let tracker = Arc::new(Mutex::new(OrphanTracker::new()));
        let buffer = OwnedBuffer::new(1024);

        let operation = SafeOperationBuilder::new()
            .buffer(buffer)
            .submission_id(42)
            .orphan_tracker(Arc::downgrade(&tracker))
            .build()
            .unwrap();

        assert_eq!(operation.submission_id(), 42);
        assert_eq!(operation.buffer_size(), Some(1024));
    }

    #[test]
    fn test_safe_operation_builder_missing_fields() {
        let result = SafeOperationBuilder::new()
            .submission_id(42)
            // Missing buffer and tracker
            .build();

        assert!(result.is_err());
    }

    #[test]
    fn test_submission_id_wrapping() {
        let mut tracker = OrphanTracker::new();
        tracker.next_submission_id = u64::MAX;

        let id1 = tracker.next_submission_id();
        let id2 = tracker.next_submission_id();

        assert_eq!(id1, u64::MAX);
        assert_eq!(id2, 0); // Should wrap around
    }
}
</file>

</files>
